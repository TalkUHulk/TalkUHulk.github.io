{"title":"无监督对比学习(Contrastive LearningOC)","uid":"84b6109cde20e5bfc02c6af7734d88cb","slug":"无监督对比学习-Contrastive-LearningOC","date":"2021-11-02T03:39:11.000Z","updated":"2021-11-02T12:08:17.592Z","comments":true,"path":"api/articles/无监督对比学习-Contrastive-LearningOC.json","keywords":null,"cover":[],"content":"<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/update7/article/details/110957600\">推荐阅读</a></p></blockquote>\n<h3 id=\"对比学习\">对比学习</h3>\n<p>原理: 输入N个图片，用不同的数据增强方法为每个图片生成两个view，分别对它们编码得到y和y'。我们对上下两批表示两两计算cosine，得到NxN的矩阵，每一行的对角线位置代表y和y'的相似度，其余代表y和N-1个负例的相似度。</p>\n<p><img src=\"/images/contrastive/cl.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>对每一行做softmax分类，采用交叉熵损失作为loss，就得到对比学习的损失了：</p>\n<p><span class=\"math display\">\\[L_y=-log\\frac{exp(y*y&#39;/\\tau)}{\\sum{exp(y*y&#39;/\\tau)}}\\]</span></p>\n<p>其中<span class=\"math inline\">\\(\\tau\\)</span>是可调节的系数。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>比较粗暴的优化方向就是增加view难度、增加更多负例(batch)、提升encoder表现</p></blockquote>\n<h3 id=\"moco系列\">MoCo系列</h3>\n<p>既然对比是在正负例之间进行的，那负例越多，这个任务就越难，于是一个优化方向就是增加负例。 纯粹的增大batch size是不行的，总会受到GPU内存限制。一个可行的办法就是增加memory bank，把之前编码好的样本存储起来，计算loss的时候一起作为负例</p>\n<p><img src=\"/images/contrastive/memory_bank.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>memory bank存在的问题：右侧存储好的编码都是之前的编码器计算的，而左侧的编码器缺一直在更新，所以会有两侧不一致的情况，影响目标优化。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>虽然可以用最新的左侧encoder更新编码再放入memory bank，但这依然避免不了memory bank中表示不一致的情况，</p></blockquote>\n<h4 id=\"mocov1\">MoCoV1</h4>\n<ul>\n<li>核心：解决新旧候选样本编码不一致的问题</li>\n<li>方法：延续memory bank的思想，使用动量的方式更新encoder参数</li>\n</ul>\n<p><img src=\"/images/contrastive/moco.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>如上三种方式： (a) end to end: 负样本数量会受到batch_size大小的限制，从而限制影响模型的性能； (b) memory bank: 内存需求较大, 且会有两侧不一致的情况； (c) MoCo: 增加momentum encoder，将dictionary作为一个动态进出的队列，目标是构建一个大的且能在训练过程中保持一致性的dictionary，作者用该队列维护最近几个mini-batch中样本特征表示，并将队列作为所有样本采样的子集，对于负样例的encoder参数<span class=\"math inline\">\\({\\theta}_k\\)</span>, 采用Momentum update方法, 复制正例encoder的参数<span class=\"math inline\">\\({\\theta}_q\\)</span>, 公式为：</p>\n<p><span class=\"math display\">\\[{\\theta}_k{\\leftarrow}m{\\theta}+(1-m){\\theta}\\ \\ 公式1\\]</span></p>\n<p>m ∈ [0, 1) is a momentum coefficient;</p>\n<ul>\n<li>步骤:</li>\n</ul>\n<p>对于每个batch x：</p>\n<ol type=\"1\">\n<li><p>随机增强出<span class=\"math inline\">\\({\\theta}_q\\)</span>, <span class=\"math inline\">\\({\\theta}_k\\)</span>两种view</p></li>\n<li><p>分别用<span class=\"math inline\">\\(f_q\\)</span>,<span class=\"math inline\">\\(f_k\\)</span>对输入进行编码得到归一化的q和k，并去掉k的梯度更新</p></li>\n<li><p>将q和k一一对应相乘得到正例的cosine（Nx1），再将q和队列中存储的K个负样本相乘（NxK），拼接起来的到 Nx(1+K) 大小的矩阵，这时第一个元素就是正例，直接计算交叉熵损失，更新<span class=\"math inline\">\\(f_q\\)</span>的参数</p></li>\n<li><p>动量更新<span class=\"math inline\">\\(f_k\\)</span>的参数：公式1</p></li>\n<li><p>将k加入队列，把队首的旧编码出队，负例最多时有65536个.</p></li>\n</ol>\n<p>这样每次入队的新编码都是上一步更新后的编码器输出，以很低的速度慢慢迭代，与旧编码尽量保持一致。实验发现，m=0.999时比m=0.9好上很多。</p>\n<ul>\n<li>数据增强方法:</li>\n</ul>\n<p>a 224×224-pixel crop is taken from a randomly resized image, and then undergoes random color jittering, random horizontal flip, and random grayscale con- version</p>\n<h4 id=\"mocov2\">MoCoV2</h4>\n<p>改进: * 改进了数据增强方法, 增加使用blur augmentation来进行增强 * 训练时在encoder的表示上增加了相同的非线性层 * 学习率采用SimCLR的cosine衰减</p>\n<p><img src=\"/images/contrastive/mocov2.jpg\" width=\"75%\" height=\"75%\"></p>\n<h3 id=\"simclr系列\">SimClr系列</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>与MoCo相比，SimCLR关注的重点是正负样例的构建方式，同时SimCLR还探究了非线性层在对比学习中的作用，并分析了batch_size大小、训练轮数等超参数对对比学习的影响</p></blockquote>\n<h4 id=\"simclr-v1\">SimCLR-V1</h4>\n<p><img src=\"/images/contrastive/simclrv1.jpg\" width=\"75%\" height=\"75%\"></p>\n<ol type=\"1\">\n<li><p>探究了不同的数据增强组合方式，选取了最优的;(数据增强对对比学习效果提升有明显作用，并且多种数据增强的组合效果更好；数据增强对对比学习的提升比对有监督学习的提升高)</p></li>\n<li><p>在encoder之后增加了一个非线性映射。<strong>研究发现encoder编码后的会保留和数据增强变换相关的信息，而非线性层的作用就是去掉这些信息，让表示回归数据的本质</strong>。注意非线性层只在无监督训练时用，在迁移到其他任务时不使用</p></li>\n<li><p>计算loss时多加了负例。以前都是拿右侧数据的N-1个作为负例，SimCLR将左侧的N-1个也加入了进来，总计2(N-1)个负例。</p></li>\n</ol>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>SimCLR不采用memory bank，而是用更大的batch size，最多的时候bsz为8192，有16382个负例</p></blockquote>\n<h4 id=\"simclr-v2\">SimCLR-V2</h4>\n<ol type=\"1\">\n<li><p>采用更深但维度略小的encoder，从 ResNet-50 (4×) 改到了 ResNet-152 (3×+SK)，在1%的监督数据下提升了29个点</p></li>\n<li><p>采用更深的3层MLP，并在迁移到下游任务时保留第一层（以前是完全舍弃），在1%的监督数据下提升了14个点</p></li>\n<li><p>参考了MoCo使用memory，但由于batch已经足够大了，只有1%左右的提升</p></li>\n</ol>\n<p><img src=\"/images/contrastive/simclrv2.jpg\" width=\"75%\" height=\"75%\"></p>\n<h3 id=\"seed\">SEED</h3>\n<p>(SEED Self-supervised Distillation For Visual Representation)[https://arxiv.org/abs/2101.04731]</p>\n<p>对比自监督学习方法在大模型训练方面表现出了很大进展，然这些方法在小模型上的表现并不好,作者推测，与大模型相比，小模型因为参数量比较小，无法有效地学习到大量数据的特征表示；</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>We conjecture that this is because smaller models with fewer parameters cannot effectively learn instance level discriminative representation with large amount of data.</p></blockquote>\n<p>因此，作者借鉴了蒸馏的方法，在实例相似性分布的基础上进行知识蒸馏。 类似MoCo，作者维护一个实例队列以保存老师模型的编码输出，对于新样本，我们计算它与队列中所有样本的相似性得分。我们希望：学生模型与老师模型的相似性得分分布尽可能相似，这就构成了老师模型与老师模型的相似性得分分布的交叉熵</p>\n<p>结构如下：</p>\n<p><img src=\"/images/contrastive/seed.jpg\" width=\"75%\" height=\"75%\"></p>\n","feature":true,"text":" 推荐阅读 对比学习 原理: 输入N个图片，用不同的数据增强方法为每个图片生成两个view，分别对它们编码得到y和y'。我们对上下两批表示两两计算cosine，得到NxN的矩阵，每一行的对角线位置代表y和y'的相似度，其余代表y和N-1个负例的相似度。 对每一行做softmax分...","link":"","photos":[],"count_time":{"symbolsCount":"2.8k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"work summary","slug":"work-summary","count":2,"path":"api/tags/work-summary.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0\"><span class=\"toc-text\">对比学习</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#moco%E7%B3%BB%E5%88%97\"><span class=\"toc-text\">MoCo系列</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#mocov1\"><span class=\"toc-text\">MoCoV1</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#mocov2\"><span class=\"toc-text\">MoCoV2</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#simclr%E7%B3%BB%E5%88%97\"><span class=\"toc-text\">SimClr系列</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#simclr-v1\"><span class=\"toc-text\">SimCLR-V1</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#simclr-v2\"><span class=\"toc-text\">SimCLR-V2</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#seed\"><span class=\"toc-text\">SEED</span></a></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"StyelGan及其应用","uid":"48031087686b5c5ecd7460e246ad1434","slug":"StyelGan及其应用","date":"2021-10-30T03:52:16.000Z","updated":"2021-11-02T03:26:04.399Z","comments":true,"path":"api/articles/StyelGan及其应用.json","keywords":null,"cover":[],"text":" 对项目realworld-stylegan2-encoder相关技术的总结，欢迎star～ The demo of different style with age edit. StyleGan 个人认为，效果好的主要两点是： 1. Mapping Network对隐藏空间(l...","link":"","photos":[],"count_time":{"symbolsCount":"14k","symbolsTime":"13 mins."},"categories":[],"tags":[{"name":"work summary","slug":"work-summary","count":2,"path":"api/tags/work-summary.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"feature":true}}