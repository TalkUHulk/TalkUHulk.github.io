{"title":"FCOS学习笔记","uid":"7f399d762217f0410e81da356daa491f","slug":"FCOS学习笔记","date":"2021-09-13T08:19:35.000Z","updated":"2021-11-12T08:18:20.485Z","comments":true,"path":"api/articles/FCOS学习笔记.json","keywords":null,"cover":[],"content":"<h3 id=\"fcos学习笔记\">FCOS学习笔记</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>笔记来源：<a href=\"https://blog.csdn.net/WZZ18191171661/article/details/89258086\">FCOS算法详解</a> <a href=\"https://zhuanlan.zhihu.com/p/339023466\">FCOS论文精读——看这一篇就够了</a></p></blockquote>\n<p>FCOS是一个基于FCN的per-pixel、anchor free的one-stage目标检测算法，论文全:<a href=\"https://arxiv.org/pdf/1904.01355.pdf\">《FCOS: Fully Convolutional One-Stage Object Detection》</a></p>\n<p>Anchor-based不足：</p>\n<ol type=\"1\">\n<li><p>anchor会引入很多需要优化的超参数， 比如anchor number、anchor size、anchor ratio等；</p></li>\n<li><p>为了保证算法效果，需要很多的anchors，存在正负样本类别不均衡问题；</p></li>\n<li><p>在训练的时候，需要计算所有anchor box同ground truth boxes的IoU，计算量较大；</p></li>\n</ol>\n<p>FCOS优势：</p>\n<ol type=\"1\">\n<li><p>因为输出是pixel-based预测，所以可以复用semantic segmentation方向的相关tricks；</p></li>\n<li><p>可以修改FCOS的输出分支，用于解决instance segmentation和keypoint detection任务；</p></li>\n</ol>\n<img src=\"/images/FCOS/arch.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nFCOS网络结构\n</p>\n<h4 id=\"实现细节\">实现细节</h4>\n<h5 id=\"与anchor-base对比\">与Anchor Base对比</h5>\n<p>对于基于anchors的目标检测算法而言，我们将输入的图片送入backbone网络之后，会获得最终的feature_map，比如说是17x17x256；然后我们会在该feature_map上的每一位置上使用预先定义好的anchors。而FCOS的改动点就在这里，它是<u><strong>直接在feature_map上的每一点进行回归操作</strong></u>。</p>\n<p>具体的实施思路如下所示： 1. 我们可以将feature_map中的每一个点(x,y)映射回原始的输入图片中: <span class=\"math display\"><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -1.552ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"20.85ex\" height=\"4.081ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -1118 9215.6 1804\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(389,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(667,0)\"><g data-mml-node=\"mi\" transform=\"translate(235.5,676)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-686)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><rect width=\"700\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"mo\" transform=\"translate(1607,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2107.2,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3107.4,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3679.4,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4148.4,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4593.1,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mfrac\" transform=\"translate(4871.1,0)\"><g data-mml-node=\"mi\" transform=\"translate(235.5,676)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(220,-686)\"><path data-c=\"32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path></g><rect width=\"700\" height=\"60\" x=\"120\" y=\"220\"></rect></g><g data-mml-node=\"mo\" transform=\"translate(5811.1,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(6311.3,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7311.6,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7801.6,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8270.6,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8548.6,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8826.6,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container></span></p>\n<p>其中: s为步长，(x,y)为改点对应feature map上的坐标.</p>\n<ol start=\"2\" type=\"1\">\n<li><p>如果这个映射回原始输入的点在相应的GT的bbox范围之内，而且类别标签对应，我们将其作为训练的正样本块，否则将其作为正样本块；</p></li>\n<li><p>回归的目标是(l,t,r,b)，即中心点做bbox的left、top、right和bottom之间的距离，具体如下图所示：</p>\n<p><img src=\"/images/FCOS/regress.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>如果一个位置在多个bbox的内部的话，如右图，针对这样样本文中采样的方法是直接<strong>选择择面积最小的边界框作为其回归目标</strong>。由于网络中FPN的存在，导致这样的模糊样本的数量大大减少。</p></li>\n<li><p>如果这个位置(x,y)和一个bbox关联的话，该位置处的训练回归目标可制定为:其中(x1,y1)和(x2,y2)分别表示bbox的左上角和右下角坐标值。</p>\n<p><img src=\"/images/FCOS/f1.jpg\" width=\"30%\" height=\"30%\"></p>\n<p>由于FCOS可以通过这样方式获得很多正样本块，使用这样的正样本块进行回归操作，因此获得了比较好的性能提升，而原始的基于anchor的算法需要通过计算预设的anchor和对应的GT之间的IOU值，当该IOU值大于设定的阈值时才将其看做正样本块。</p></li>\n</ol>\n<h5 id=\"loss\">Loss</h5>\n<p><img src=\"/images/FCOS/loss.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>loss函数如上图所示，包含两部分，Lcls表示分类loss，本文使用的是Focal_loss；Lreg表示回归loss，本文使用的是IOU loss。</p>\n<h5 id=\"center-ness分支\">center-ness分支</h5>\n<p>Center-ness表示的是(x,y)距目标中心的标准化后的距离，为了制止过多的低质量离目标中心远的检测框而设计。</p>\n<p><img src=\"/images/FCOS/centerness.jpg\" width=\"75%\" height=\"75%\"></p>\n<p><img src=\"/images/FCOS/centerness_2.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>如上图，红色到蓝色表示center-ness从1到0，因为center-ness是在0-1之间，所以用的BCE loss，这个loss会一起加到上面我们提到的loss function中。在测试时，检测框的排序分数由center-ness乘上分类的分数。如果还有低质量的框，最后可用NMS来剔除。</p>\n","text":"FCOS学习笔记 笔记来源：FCOS算法详解 FCOS论文精读——看这一篇就够了 FCOS是一个基于FCN的per-pixel、anchor free的one-stage目标检测算法，论文全:《FCOS: Fully Convolutional One-Stage Object ...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#fcos%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">FCOS学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82\"><span class=\"toc-text\">实现细节</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E4%B8%8Eanchor-base%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">与Anchor Base对比</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#loss\"><span class=\"toc-text\">Loss</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#center-ness%E5%88%86%E6%94%AF\"><span class=\"toc-text\">center-ness分支</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Faster RCNN 记录","uid":"06a101cf6ba6fad0463c3458164de1c3","slug":"Faster-RCNN-记录","date":"2021-10-11T07:47:29.000Z","updated":"2021-11-11T10:17:18.071Z","comments":true,"path":"api/articles/Faster-RCNN-记录.json","keywords":null,"cover":[],"text":" 参考来源： https://zhuanlan.zhihu.com/p/31426458 https://zhuanlan.zhihu.com/p/86403390 Faster RCNN基本结构 Faster RCNN其实可以分为4个主要内容： 特征提取：Faster RCNN...","link":"","photos":[],"count_time":{"symbolsCount":"13k","symbolsTime":"12 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}},"next_post":{"title":"YOLO-V5学习笔记","uid":"57d3aa7cdcc56700d35ee7aa4e8c6558","slug":"YOLO-V5学习笔记","date":"2021-09-09T07:42:37.000Z","updated":"2021-11-12T03:49:31.818Z","comments":true,"path":"api/articles/YOLO-V5学习笔记.json","keywords":null,"cover":[],"text":"YOLO-V5学习笔记 知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380 网络结构 Yolov5s网络结构(来源见水印) 如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、N...","link":"","photos":[],"count_time":{"symbolsCount":"3.2k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}}}