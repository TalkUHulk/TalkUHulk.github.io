{"title":"FCOS学习笔记","uid":"7f399d762217f0410e81da356daa491f","slug":"FCOS学习笔记","date":"2021-09-13T08:19:35.000Z","updated":"2021-10-18T10:08:34.332Z","comments":true,"path":"api/articles/FCOS学习笔记.json","keywords":null,"cover":[],"content":"<h3 id=\"fcos学习笔记\">FCOS学习笔记</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>笔记来源：https://blog.csdn.net/WZZ18191171661/article/details/89258086 https://zhuanlan.zhihu.com/p/339023466</p></blockquote>\n<p>FCOS是一个基于FCN的per-pixel、anchor free的one-stage目标检测算法，论文全:<a href=\"https://arxiv.org/pdf/1904.01355.pdf\">《FCOS: Fully Convolutional One-Stage Object Detection》</a></p>\n<p>Anchor-based不足：</p>\n<ol type=\"1\">\n<li>anchor会引入很多需要优化的超参数， 比如anchor number、anchor size、anchor ratio等；</li>\n<li>为了保证算法效果，需要很多的anchors，存在正负样本类别不均衡问题；</li>\n<li>在训练的时候，需要计算所有anchor box同ground truth boxes的IoU，计算量较大；</li>\n</ol>\n<p>FCOS优势： 1. 因为输出是pixel-based预测，所以可以复用semantic segmentation方向的相关tricks； 2. 可以修改FCOS的输出分支，用于解决instance segmentation和keypoint detection任务；</p>\n<img src=\"/images/FCOS/arch.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nFCOS网络结构\n</p>\n<h4 id=\"实现细节\">实现细节</h4>\n<h5 id=\"与anchor-base对比\">与Anchor Base对比</h5>\n<p>对于基于anchors的目标检测算法而言，我们将输入的图片送入backbone网络之后，会获得最终的feature_map，比如说是17x17x256；然后我们会在该feature_map上的每一位置上使用预先定义好的anchors。而FCOS的改动点就在这里，它是<u><strong>直接在feature_map上的每一点进行回归操作</strong></u>。</p>\n<p>具体的实施思路如下所示： 1. 我们可以将feature_map中的每一个点(x,y)映射回原始的输入图片中: (⌊s/2⌋ + xs, ⌊s/2⌋ + ys) 其中: s为步长，(x,y)为改点对应feature map上的坐标.</p>\n<ol start=\"2\" type=\"1\">\n<li><p>如果这个映射回原始输入的点在相应的GT的bbox范围之内，而且类别标签对应，我们将其作为训练的正样本块，否则将其作为正样本块；</p></li>\n<li><p>回归的目标是(l,t,r,b)，即中心点做bbox的left、top、right和bottom之间的距离，具体如下图所示：</p>\n<p><img src=\"/images/FCOS/regress.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>如果一个位置在多个bbox的内部的话，如右图，针对这样样本文中采样的方法是直接<strong>选择择面积最小的边界框作为其回归目标</strong>。由于网络中FPN的存在，导致这样的模糊样本的数量大大减少。</p></li>\n<li><p>如果这个位置(x,y)和一个bbox关联的话，该位置处的训练回归目标可制定为:其中(x1,y1)和(x2,y2)分别表示bbox的左上角和右下角坐标值。</p>\n<p><img src=\"/images/FCOS/f1.jpg\" width=\"30%\" height=\"30%\"></p>\n<p>由于FCOS可以通过这样方式获得很多正样本块，使用这样的正样本块进行回归操作，因此获得了比较好的性能提升，而原始的基于anchor的算法需要通过计算预设的anchor和对应的GT之间的IOU值，当该IOU值大于设定的阈值时才将其看做正样本块。</p></li>\n</ol>\n<h5 id=\"loss\">Loss</h5>\n<p><img src=\"/images/FCOS/loss.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>loss函数如上图所示，包含两部分，Lcls表示分类loss，本文使用的是Focal_loss；Lreg表示回归loss，本文使用的是IOU loss。</p>\n<h5 id=\"center-ness分支\">center-ness分支</h5>\n<p>Center-ness表示的是(x,y)距目标中心的标准化后的距离，为了制止过多的低质量离目标中心远的检测框而设计。</p>\n<p><img src=\"/images/FCOS/centerness.jpg\" width=\"75%\" height=\"75%\"></p>\n<p><img src=\"/images/FCOS/centerness_2.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>如上图，红色到蓝色表示center-ness从1到0，因为center-ness是在0-1之间，所以用的BCE loss，这个loss会一起加到上面我们提到的loss function中。在测试时，检测框的排序分数由center-ness乘上分类的分数。如果还有低质量的框，最后可用NMS来剔除。</p>\n","text":"FCOS学习笔记 笔记来源：https://blog.csdn.net/WZZ18191171661/article/details/89258086 https://zhuanlan.zhihu.com/p/339023466 FCOS是一个基于FCN的per-pixel、an...","link":"","photos":[],"count_time":{"symbolsCount":"1.6k","symbolsTime":"1 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#fcos%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">FCOS学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E7%8E%B0%E7%BB%86%E8%8A%82\"><span class=\"toc-text\">实现细节</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E4%B8%8Eanchor-base%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">与Anchor Base对比</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#loss\"><span class=\"toc-text\">Loss</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#center-ness%E5%88%86%E6%94%AF\"><span class=\"toc-text\">center-ness分支</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Faster RCNN 记录","uid":"06a101cf6ba6fad0463c3458164de1c3","slug":"Faster-RCNN-记录","date":"2021-10-11T07:47:29.000Z","updated":"2021-11-11T10:17:18.071Z","comments":true,"path":"api/articles/Faster-RCNN-记录.json","keywords":null,"cover":[],"text":" 参考来源： https://zhuanlan.zhihu.com/p/31426458 https://zhuanlan.zhihu.com/p/86403390 Faster RCNN基本结构 Faster RCNN其实可以分为4个主要内容： 特征提取：Faster RCNN...","link":"","photos":[],"count_time":{"symbolsCount":"13k","symbolsTime":"12 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}},"next_post":{"title":"YOLO-V5学习笔记","uid":"57d3aa7cdcc56700d35ee7aa4e8c6558","slug":"YOLO-V5学习笔记","date":"2021-09-09T07:42:37.000Z","updated":"2021-10-12T07:12:51.837Z","comments":true,"path":"api/articles/YOLO-V5学习笔记.json","keywords":null,"cover":[],"text":"YOLO-V5学习笔记 知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380 网络结构 Yolov5s网络结构(来源见水印) 如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、N...","link":"","photos":[],"count_time":{"symbolsCount":"2.1k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":5,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}}}