{"title":"手撕代码","uid":"66e6fbbf30cdfd5fb293d5ee17ed3935","slug":"手撕代码","date":"2021-10-19T03:41:08.000Z","updated":"2021-12-03T03:40:57.089Z","comments":true,"path":"api/articles/手撕代码.json","keywords":null,"cover":"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Ftu.bobopic.com%2Ftupian%2F2018%2F10%2F13%2Fdaimahexianshiqitupian2.jpg&refer=http%3A%2F%2Ftu.bobopic.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1639557632&t=16e78740bad6f4737756098f6ced691e","content":"<h4 id=\"iou\">1. IOU</h4>\n<h5 id=\"python\">python</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def bb_intersection_over_union(boxA, boxB):\n    boxA = [int(x) for x in boxA]\n    boxB = [int(x) for x in boxB]\n\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n\n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n    \n    iou = interArea / float(boxAArea + boxBArea - interArea)\n\n    return iou<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"c\">c++</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;algorithm&gt;\nusing namespace std;\n\ntypedef struct Bbox\n{\n    int x1;\n    int y1;\n    int x2;\n    int y2;\n    float score;\n}Bbox;\n\nfloat iou(Bbox box1,Bbox box2)\n{\n    max_x = max(box1.x1,box2.x1);  // 找出左上角坐标哪个大\n    min_x = min(box1.x2,box2.x2);  // 找出右上角坐标哪个小\n    max_y = max(box1.y1,box2.y1);\n    min_y = min(box1.y2,box2.y2);\n    if(min_x&lt;=max_x || min_y&lt;=max_y) // 如果没有重叠\n        return 0;\n    float over_area = (min_x - max_x) * (min_y - max_y);  // 计算重叠面积\n    float area_a = (box1.x2 - boxa.x1) * (box1.y2 - boxa.y1);\n    float area_b = (box2.x2 - boxb.x1) * (box2.y2 - boxb.y1);\n    float iou = over_area / (area_a + area_b - over_area);\n    return iou;\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"nms\">2. NMS</h4>\n<h5 id=\"python-1\">python</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def nms(det, thresh):\n    x1 = det[..., 0]\n    y1 = det[..., 1]\n    x2 = det[..., 2]\n    y2 = det[..., 3]\n    scores = det[..., 4]\n    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n    order = np.argsort(scores)[::-1]  # Returns the indices that would sort an array.\n    keep = []\n    while order.size &gt; 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(x2[i], x2[order[1:]])\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n        inter = w * h\n        union = area[i] + area[order[1:]] - inter\n        iou = inter / union\n        next_i = np.where(iou &lt;= thresh)[0]  # 只有条件 (condition)，没有x和y，则输出满足条件 (即非0) 元素的坐标\n        order = order[next_i + 1]\n    return keep<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"c-1\">c++</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">/*\n  将bbx按照confidence从高到低排序\n*/\nbool sort_score(Bbox box1,Bbox box2)\n{\n    return (box1.score &gt; box2.score);\n}\n/*\n(1) 获取当前目标类别下所有bbx的信息\n(2) 将bbx按照confidence从高到低排序,并记录当前confidence最大的bbx\n(3) 计算最大confidence对应的bbx与剩下所有的bbx的IOU,移除所有大于IOU阈值的bbx\n(4) 对剩下的bbx，循环执行(2)和(3)直到所有的bbx均满足要求（即不能再移除bbx）\n*/\nvector&lt;Bbox&gt; nms(vector&lt;Bbox&gt;&amp;vec_boxs, float threshold)\n{\n    vector&lt;Bbox&gt;  res;\n    while(vec_boxs.size() &gt; 0)\n    {\n        sort(vec_boxs.begin(),vec_boxs.end(),cmp);\n        res.push_back(vec_boxs[0]);\n        for(int i =1;i &lt;vec_boxs.size();i++)\n        {\n            float iou_value =iou(vec_boxs[0],vec_boxs[i]);\n            if (iou_value &gt;threshold)\n            {\n                vec_boxs.erase(find(vec.begin(),vec.end(),vec_boxs[i]));\n            }\n        }\n        vec_boxs.erase(find(vec.begin(),vec.end(),vec_boxs[0]));  // res 已经保存，所以可以将最大的删除了\n \n    }\n    return res;\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"卷积\">3. 卷积</h4>\n<h5 id=\"python-2\">python</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def conv_naive(x, c_out, ksize=3, padding=0, stride=1):\n    b, c_in, h, w = x.shape\n    kernel = np.random.rand(c_out, c_in, ksize, ksize)\n    out_height = (h - ksize + 2 * padding) // stride + 1\n    out_width = (w - ksize + 2 * padding) // stride + 1\n\n    out_x = np.random.rand(b, c_out, out_height,  out_width)\n    if padding &gt; 0:\n        pad_x = np.zeros((b, c_in, h + 2 * padding, w + 2 * padding))\n        pad_x[..., padding:-padding, padding:-padding] = x\n    else:\n        pad_x = x\n\n    for y in range(out_height):\n        for x in range(out_width):\n            roi = pad_x[..., y * stride:y * stride + ksize, x * stride: x * stride + ksize]\n            conv = np.tile(np.expand_dims(roi, axis=1), (1, c_out, 1, 1, 1)) * kernel\n            # conv = np.repeat(np.expand_dims(roi, axis=1), axis=1, repeats=c_out) * kernel\n            out_x[..., y, x] = np.squeeze(np.sum(conv, axis=(2, 3, 4), keepdims=True), axis=(2, 3, 4))\n\n    return out_x<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"c-2\">c++</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">/二维卷积的实现\n#include&lt;cassert&gt;\n#include&lt;vector&gt;\n\n\nvoid conv2(int** filter, int **mat, int** res, const int filter_rows, const int filter_cols, const int mat_rows, const int mat_cols);//指针数组版本\nstd::vector&lt;std::vector&lt;int&gt; &gt; conv2(std::vector&lt;std::vector&lt;int&gt; &gt; filter, std::vector&lt;std::vector&lt;int&gt; &gt; mat);//向量版本\n\n\nint main(void)\n{\n    return 0;\n}//main\n\nvoid conv2(int** filter, int **mat, int** res, const int filter_rows, const int filter_cols, const int mat_rows, const int mat_cols)\n{\n    assert(filter_cols &lt; mat_cols &amp;&amp; filter_rows &lt; mat_rows);\n    for(int i = 0; i &lt; mat_rows - 1; ++i)\n        for (int j = 0; j &lt; mat_cols - 1; ++j)\n        {\n            int tmp = 0;\n            for (int m = 0; m &lt; filter_rows; ++m)\n                for (int n = 0; n &lt; filter_cols; ++n)\n                    if(0 &lt;= i -m  &amp;&amp; i - m &lt; mat_rows &amp;&amp; 0 &lt;= j - n &amp;&amp; j - n &lt; mat_cols)\n                        tmp += filter[m][n] * mat[i - m][j - n];//卷积公式\n\n            res[i][j] = tmp;\n        }\n}\n\nstd::vector&lt;std::vector&lt;int&gt; &gt; conv2(std::vector&lt;std::vector&lt;int&gt; &gt; filter, std::vector&lt;std::vector&lt;int&gt; &gt; mat )//向量版本\n{\n    const int filter_rows = filter.size();\n    const int filter_cols = filter[0].size();\n\n    const int mat_rows = mat.size();\n    const int mat_cols = mat[0].size();\n\n    assert(filter_cols &lt; mat_cols &amp;&amp; filter_rows &lt; mat_rows);\n    std::vector&lt;std::vector&lt;int&gt; &gt; res(mat_rows, std::vector&lt;int&gt;(mat_cols, 0));\n\n    for (int i = 0; i &lt; mat_rows - 1; ++i)\n        for (int j = 0; j &lt; mat_cols - 1; ++j)\n        {\n            int tmp = 0;\n            for (int m = 0; m &lt; filter_rows; ++m)\n                for (int n = 0; n &lt; filter_cols; ++n)\n                    if (0 &lt;= i - m &amp;&amp; i - m &lt; mat_rows &amp;&amp; 0 &lt;= j - n &amp;&amp; j - n &lt; mat_cols)\n                        tmp += filter[m][n] * mat[i - m][j - n];//卷积公式\n\n            res[i][j] = tmp;\n        }\n    return res;\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"pooling\">4. Pooling</h4>\n<h5 id=\"maxpooling\">maxpooling</h5>\n<h6 id=\"版本1简单版\">版本1(简单版)</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def max_pooling(x, kernel_size=2, stride=2):\n    b, c_in, h, w = x.shape\n    ow = (w - kernel_size) // stride + 1\n    oh = (h - kernel_size) // stride + 1\n\n    out = np.zeros([b, c_in, oh, ow])\n    x_input = x\n    for y in range(oh):\n        for x in range(ow):\n            roi = x_input[..., y * stride: y * stride + kernel_size, x * stride: x * stride + kernel_size]\n            max_val = np.squeeze(np.max(roi, axis=(2, 3), keepdims=True), axis=(2, 3))\n            out[..., y, x] = max_val\n    return out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h6 id=\"版本2反向传播\">版本2(反向传播)</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import numpy as np\nimport torch\nclass MaxPooling2D:\n    def __init__(self, kernel_size=(2, 2), stride=2):\n        self.kernel_size = kernel_size\n        self.w_height = kernel_size[0]\n        self.w_width = kernel_size[1]\n\n        self.stride = stride\n\n        self.x = None\n        self.in_height = None\n        self.in_width = None\n\n        self.out_height = None\n        self.out_width = None\n\n        self.arg_max = None\n\n    def __call__(self, x):\n        self.x = x\n        self.in_height = np.shape(x)[0]\n        self.in_width = np.shape(x)[1]\n\n        self.out_height = int((self.in_height - self.w_height) / self.stride) + 1\n        self.out_width = int((self.in_width - self.w_width) / self.stride) + 1\n\n        out = np.zeros((self.out_height, self.out_width))\n        self.arg_max = np.zeros_like(out, dtype=np.int32)\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                out[i, j] = np.max(x[start_i: end_i, start_j: end_j])\n                self.arg_max[i, j] = np.argmax(x[start_i: end_i, start_j: end_j])\n        self.arg_max = self.arg_max\n        return out\n\n    def backward(self, d_loss):\n        dx = np.zeros_like(self.x)\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                index = np.unravel_index(self.arg_max[i, j], self.kernel_size)\n                dx[start_i:end_i, start_j:end_j][index] = d_loss[i, j] #\n        return dx<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>test</li>\n</ul>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">np.set_printoptions(precision=8, suppress=True, linewidth=120)\nx_numpy = np.random.random((1, 1, 6, 9))\nx_tensor = torch.tensor(x_numpy, requires_grad=True)\n\nmax_pool_tensor = torch.nn.MaxPool2d((2, 2), 2)\nmax_pool_numpy = MaxPooling2D((2, 2), stride=2)\n\nout_numpy = max_pool_numpy(x_numpy[0, 0])\nout_tensor = max_pool_tensor(x_tensor)\n\nd_loss_numpy = np.random.random(out_tensor.shape)\nd_loss_tensor = torch.tensor(d_loss_numpy, requires_grad=True)\nout_tensor.backward(d_loss_tensor)\n\ndx_numpy = max_pool_numpy.backward(d_loss_numpy[0, 0])\ndx_tensor = x_tensor.grad\n# print('input \\n', x_numpy)\nprint(\"out_numpy \\n\", out_numpy)\nprint(\"out_tensor \\n\", out_tensor.data.numpy())\n\nprint(\"dx_numpy \\n\", dx_numpy)\nprint(\"dx_tensor \\n\", dx_tensor.data.numpy())<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def pooling(feature_map, size=2, stride=2):\n    channel=feature_map.shape[0]\n    height=feature_map.shape[1]\n    width=feature_map.shape[2]\n    padding_height=np.uint16(round((height-size+1)/stride))\n    padding_width=np.uint16(round((width-size+1)/stride))\n    print(padding_height,padding_width)\n\n    pool_out = np.zeros((channel,padding_height,padding_width),dtype=np.uint8)\n    \n    for map_num in range(channel):  \n        out_height = 0  \n        for r in np.arange(0,height, stride):  \n            out_width = 0  \n            for c in np.arange(0, width, stride):  \n                pool_out[map_num,out_height, out_width] = np.max(feature_map[map_num,r:r+size,c:c+size])  \n                out_width=out_width+1\n            out_height=out_height+1\n    return pool_out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"avg-pooling\">avg-pooling</h5>\n<h6 id=\"版本1简单版-1\">版本1(简单版)</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def avg_pooling(x, kernel_size=2, stride=2):\n    b, c_in, h, w = x.shape\n    ow = (w - kernel_size) // stride + 1\n    oh = (h - kernel_size) // stride + 1\n\n    out = np.zeros([b, c_in, oh, ow])\n    x_input = x\n    for y in range(oh):\n        for x in range(ow):\n            roi = x_input[..., y * stride: y * stride + kernel_size, x * stride: x * stride + kernel_size]\n            max_val = np.average(roi, axis=(2, 3))\n            out[..., y, x] = max_val\n    return out<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h6 id=\"版本2反向传播-1\">版本2(反向传播)</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import numpy as np\nimport torch\n\nclass AvgPooling2D:\n    def __init__(self, kernel_size=(2, 2), stride=2):\n        self.stride = stride\n        self.kernel_size = kernel_size\n        self.w_height = kernel_size[0]\n        self.w_width = kernel_size[1]\n\n    def __call__(self, x):\n        self.x = x\n        self.in_height = x.shape[0]\n        self.in_width = x.shape[1]\n\n        self.out_height = int((self.in_height - self.w_height) / self.stride) + 1\n        self.out_width = int((self.in_width - self.w_width) / self.stride) + 1\n        out = np.zeros((self.out_height, self.out_width))\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                out[i, j] = np.mean(x[start_i: end_i, start_j: end_j])\n        return out\n\n    def backward(self, d_loss):\n        dx = np.zeros_like(self.x)\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                dx[start_i: end_i, start_j: end_j] = d_loss[i, j] / (self.w_width * self.w_height)\n        return dx\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>test</li>\n</ul>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">np.set_printoptions(precision=8, suppress=True, linewidth=120)\nx_numpy = np.random.random((1, 1, 6, 9))\nx_tensor = torch.tensor(x_numpy, requires_grad=True)\n\navg_pool_tensor = torch.nn.AvgPool2d((2, 2), 2)\navg_pool_numpy = AvgPooling2D((2, 2), stride=2)\n\nout_numpy = avg_pool_numpy(x_numpy[0, 0])\nout_tensor = avg_pool_tensor(x_tensor)\n\nd_loss_numpy = np.random.random(out_tensor.shape)\nd_loss_tensor = torch.tensor(d_loss_numpy, requires_grad=True)\nout_tensor.backward(d_loss_tensor)\n\ndx_numpy = avg_pool_numpy.backward(d_loss_numpy[0, 0])\ndx_tensor = x_tensor.grad\n# print('input \\n', x_numpy)\nprint(\"out_numpy \\n\", out_numpy)\nprint(\"out_tensor \\n\", out_tensor.data.numpy())\n\nprint(\"dx_numpy \\n\", dx_numpy)\nprint(\"dx_tensor \\n\", dx_tensor.data.numpy())<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"map\">5. mAP</h4>\n<h5 id=\"python-3\">python</h5>\n<h5 id=\"c-3\">c++</h5>\n<h4 id=\"softnms\">6. softnms</h4>\n<h5 id=\"python-4\">python</h5>\n<h6 id=\"版本1\">版本1</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\"># soft_nms操作，这里假设boxes是无序(未按score做降序)的，所以每轮soft_nms迭代都需要类似冒泡排序操作，选择当前top-1 bbox做NMS\n# Nt：计算IoU的阈值，IoU &gt; Nt，对应bbox的score权重就要降低\n# threshold：降权后通过threshold进一步剔除低权重bbox\ndef cpu_soft_nms(boxes, sigma=0.5, Nt=0.3, threshold=0.001, method=0):\n    N = boxes.shape[0]\n    for i in range(N):\n        maxscore = boxes[i, 4]  # 获取当前index下的bbox\n        maxpos = i\n\n        tx1 = boxes[i, 0]\n        ty1 = boxes[i, 1]\n        tx2 = boxes[i, 2]\n        ty2 = boxes[i, 3]\n        ts = boxes[i, 4]\n\n        pos = i + 1  # 下面操作就很常规了，找到当前index i之后所有bboxes中，score最大的bbox，并将之赋值给maxscore、maxpos\n        while pos &lt; N:\n            if maxscore &lt; boxes[pos, 4]:\n                maxscore = boxes[pos, 4]\n                maxpos = pos\n            pos = pos + 1\n\n        # 下面操作更简单，想想我们最开始学C语言，a、b两变量如何交换\n        # add max box as a detection\n        boxes[i, 0] = boxes[maxpos, 0]  # maxpos内的信息，放到index i处，也是当前需要处理的bbox\n        boxes[i, 1] = boxes[maxpos, 1]\n        boxes[i, 2] = boxes[maxpos, 2]\n        boxes[i, 3] = boxes[maxpos, 3]\n        boxes[i, 4] = boxes[maxpos, 4]\n\n        # swap ith box with position of max box\n        boxes[maxpos, 0] = tx1  # 别忘了tx1中可是保存了boxes[i,0]备份的\n        boxes[maxpos, 1] = ty1\n        boxes[maxpos, 2] = tx2\n        boxes[maxpos, 3] = ty2\n        boxes[maxpos, 4] = ts\n\n        tx1 = boxes[i, 0]  # 此时tx1就保存的maxpos位置的bbox信息了\n        ty1 = boxes[i, 1]\n        tx2 = boxes[i, 2]\n        ty2 = boxes[i, 3]\n        ts = boxes[i, 4]\n\n        pos = i + 1\n        # NMS iterations, note that N changes if detection boxes fall below threshold，N值是动态变化的\n        while pos &lt; N:  # 向后做NMS比较\n            x1 = boxes[pos, 0]  # 当前位置的bbox\n            y1 = boxes[pos, 1]\n            x2 = boxes[pos, 2]\n            y2 = boxes[pos, 3]\n            s = boxes[pos, 4]\n\n            area = (x2 - x1 + 1) * (y2 - y1 + 1)  # pos下box的面积\n            iw = (min(tx2, x2) - max(tx1, x1) + 1)  # 计算Insection的宽iw，如果iw &lt; 0，说明没相交，可以直接忽略了\n            if iw &gt; 0:\n                ih = (min(ty2, y2) - max(ty1, y1) + 1)  # 计算Insection的宽ih，如果ih &lt; 0，说明没相交，可以直接忽略了\n                if ih &gt; 0:\n                    ua = float((tx2 - tx1 + 1) * (ty2 - ty1 + 1) + area - iw * ih)  # U的面积\n                    ov = iw * ih / ua  # iou between max box and detection box\n\n                    if method == 1:  # soft_nms中linear降权操作，与ov负相关\n                        if ov &gt; Nt:\n                            weight = 1 - ov\n                        else:\n                            weight = 1\n                    elif method == 2:  # soft_nms中gaussian降权操作\n                        weight = np.exp(-(ov * ov) / sigma)\n                    else:  # original NMS，weight = 0就直接把score置0\n                        if ov &gt; Nt:\n                            weight = 0\n                        else:\n                            weight = 1\n\n                    boxes[pos, 4] = weight * boxes[pos, 4]  # 权重重新调整\n\n                    # if box score falls below threshold, discard the box by swapping with last box，update N\n                    # 如果bbox调整后的权重，已经小于阈值threshold，那么这个bbox就可以忽略了，\n                    # 操作方式是直接用最后一个有效的bbox替换当前pos上的bbox\n                    if boxes[pos, 4] &lt; threshold:\n                        boxes[pos, 0] = boxes[N - 1, 0]\n                        boxes[pos, 1] = boxes[N - 1, 1]\n                        boxes[pos, 2] = boxes[N - 1, 2]\n                        boxes[pos, 3] = boxes[N - 1, 3]\n                        boxes[pos, 4] = boxes[N - 1, 4]\n                        N = N - 1  # N-1位置上的bbox已经赋值到前面了，该bbox就可以忽略了；\n                        pos = pos - 1  # pos位置上引入了新的有效bbox(N-1)，就需要再计算一遍了\n\n            pos = pos + 1  # 当前pos bbox计算完毕\n\n    # 求满足soft_nms筛选条件的所有bbox数量，并打散为list，但一个问题是：如何与bbox index对应起来？\n    # 方式很简单，bbox也做了对应的调整、筛选，bbox list中top-N就对应着最高score，且soft-nms筛选通过的bbox，\n    # 不过每个bbox的score也同样经过soft-nms调整了\n    keep = [i for i in range(N)]\n\n    return keep<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h6 id=\"版本2\">版本2</h6>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def py_cpu_softnms(dets, sc, Nt=0.3, sigma=0.5, thresh=0.001, method=2):\n    \"\"\"\n    py_cpu_softnms\n    :param dets:   boexs 坐标矩阵 format [y1, x1, y2, x2]\n    :param sc:     每个 boxes 对应的分数\n    :param Nt:     iou 交叠门限\n    :param sigma:  使用 gaussian 函数的方差\n    :param thresh: 最后的分数门限\n    :param method: 使用的方法\n    :return:       留下的 boxes 的 index\n    \"\"\"\n\n    # indexes concatenate boxes with the last column\n    N = dets.shape[0]\n    indexes = np.array([np.arange(N)])\n    dets = np.concatenate((dets, indexes.T), axis=1)\n\n    # the order of boxes coordinate is [y1,x1,y2,x2]\n    y1 = dets[:, 0]\n    x1 = dets[:, 1]\n    y2 = dets[:, 2]\n    x2 = dets[:, 3]\n    scores = sc\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n    for i in range(N):\n        # intermediate parameters for later parameters exchange\n        tBD = dets[i, :].copy()\n        tscore = scores[i].copy()\n        tarea = areas[i].copy()\n        pos = i + 1\n\n        #\n        if i != N-1:\n            maxscore = np.max(scores[pos:], axis=0)\n            maxpos = np.argmax(scores[pos:], axis=0)\n        else:\n            maxscore = scores[-1]\n            maxpos = 0\n        if tscore &lt; maxscore:\n            dets[i, :] = dets[maxpos + i + 1, :]\n            dets[maxpos + i + 1, :] = tBD\n            tBD = dets[i, :]\n\n            scores[i] = scores[maxpos + i + 1]\n            scores[maxpos + i + 1] = tscore\n            tscore = scores[i]\n\n            areas[i] = areas[maxpos + i + 1]\n            areas[maxpos + i + 1] = tarea\n            tarea = areas[i]\n\n        # IoU calculate\n        xx1 = np.maximum(dets[i, 1], dets[pos:, 1])\n        yy1 = np.maximum(dets[i, 0], dets[pos:, 0])\n        xx2 = np.minimum(dets[i, 3], dets[pos:, 3])\n        yy2 = np.minimum(dets[i, 2], dets[pos:, 2])\n\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[pos:] - inter)\n\n        # Three methods: 1.linear 2.gaussian 3.original NMS\n        if method == 1:  # linear\n            weight = np.ones(ovr.shape)\n            weight[ovr &gt; Nt] = weight[ovr &gt; Nt] - ovr[ovr &gt; Nt]\n        elif method == 2:  # gaussian\n            weight = np.exp(-(ovr * ovr) / sigma)\n        else:  # original NMS\n            weight = np.ones(ovr.shape)\n            weight[ovr &gt; Nt] = 0\n\n        scores[pos:] = weight * scores[pos:]\n\n    # select the boxes and keep the corresponding indexes\n    inds = dets[:, 4][scores &gt; thresh]\n    keep = inds.astype(int)\n\n    return keep<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def test():\n    # boxes and scores\n    boxes = np.array([[200, 200, 400, 400], [220, 220, 420, 420], [200, 240, 400, 440], [240, 200, 440, 400], [1, 1, 2, 2]], dtype=np.float32)\n    boxscores = np.array([0.9, 0.8, 0.7, 0.6, 0.5], dtype=np.float32)\n    index = py_cpu_softnms(boxes, boxscores, method=3)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"c-4\">c++</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">\n#include &lt;bits/stdc++.h&gt;\n\nnamespace nms\n{\nstruct proposal\n{\n  float score, x1, y1, x2, y2;\n};\n\ninline static bool cmp(const proposal&amp; a, const proposal&amp; b)\n{\n  return a.score &lt; b.score;\n}\n\ninline static float iou(const proposal&amp;, const proposal&amp;) __attribute__((always_inline));\n\nstatic float iou(const proposal&amp; a, const proposal&amp; b)\n{\n  auto overlap = 0.f;\n  float iw  = std::min(b.x2, a.x2) - std::max(b.x1, a.x1) + 1;\n  if (iw &gt; 0) {\n    float ih = std::min(b.y2, a.y2) - std::max(b.y1, a.y1) + 1;\n    if (ih &gt; 0) {\n      float ab = (b.x2 - b.x1 + 1) * (b.y2 - b.y1 + 1);\n      float aa = (a.x2 - a.x1 + 1) * (a.y2 - a.y1 + 1);\n      float inter = iw * ih;\n      overlap = inter / (aa + ab - inter);\n    }\n  }\n  return overlap;\n}\n\nenum class Method : uint32_t\n{\n  LINEAR = 0,\n  GAUSSIAN,\n  HARD\n};\n\nsize_t soft_nms(float* boxes,\n                int32_t* index,\n                size_t count,\n                Method method,\n                float Nt,\n                float sigma,\n                float threshold)\n{\n  std::iota(index, index + count, 0);  // np.arange()\n  auto p = reinterpret_cast&lt;proposal*&gt;(boxes);\n\n  auto N = count;\n  for (size_t i = 0; i &lt; N; ++i) {\n    auto max = std::max_element(p + i, p + N, cmp);\n    std::swap(p[i], *max);\n    std::swap(index[i], index[max - p]);\n\n    auto j      = i + 1;\n    auto weight = 0.f;\n    while (j &lt; N) {\n      auto ov = iou(p[i], p[j]);\n      switch (method) {\n        case Method::LINEAR:\n          weight = ov &gt; Nt ? 1.f - ov : 1.f;\n          break;\n        case Method::GAUSSIAN:\n          weight = std::exp(-(ov * ov) / sigma);\n          break;\n        case Method::HARD:\n          weight = ov &gt; Nt ? 0.f : 1.f;\n          break;\n      }\n      p[j].score *= weight;\n      if (p[j].score &lt; threshold) {\n        N--;\n        std::swap(p[j], p[N]);\n        std::swap(index[j], index[N]);\n        j--;\n      }\n      j++;\n    }\n  };\n\n  return N;\n}\n} /* namespace nms */\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"实现one-hot特征\">7. 实现one-hot特征</h4>\n<h5 id=\"python-5\">python</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">one_hot_t= np.zeros_like(y)  #生成和y形状一样的元素为零的数组\nfor j, i in zip(range(t.size), t):\n    #有多少个样本就应该对应多少个标签\n    one_hot_t[j][i] = 1      #变为one-hot类型标签：j表示样本，i表示标签索引\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"softmax\">8. softmax</h4>\n<h5 id=\"python-6\">python</h5>\n<p>由于指数函数的放大作用过于明显，如果直接使用softmax计算公式𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑥𝑖)=𝑒𝑥𝑝(𝑥𝑖)/∑𝑒𝑥𝑝(𝑥𝑗)进行函数实现，容易导致数据溢出(上溢)。所以我们在函数实现时利用其性质：先对输入数据进行处理，之后再利用计算公式计算。具体使得实现步骤为： 查找每个向量x的最大值c； 每个向量减去其最大值c, 得到向量y = x-c; 利用公式进行计算,softmax(x) = softmax(x-c) = softmax(y)</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import numpy as np\n\ndef softmax(x: np.array):\n    x_max = np.max(x, axis=-1, keepdims=True)\n    x -= x_max\n    x_exp = np.exp(x)\n    s = x_exp / np.sum(x_exp, axis=-1, keepdims=True)\n    return s\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"各种滤波\">9. 各种滤波</h4>\n<h5 id=\"马赛克\">马赛克</h5>\n<p>马赛克的实现原理是把图像上某个像素点一定范围邻域内的所有点用邻域内左上像素点的颜色代替，这样可以模糊细节，但是可以保留大体的轮廓。 <pre class=\"line-numbers language-none\"><code class=\"language-none\">import cv2\n\ndef do_mosaic(frame, x, y, w, h, neighbor=9):\n    \"\"\"\n    :param frame: opencv frame\n    :param int x :  马赛克左顶点\n    :param int y:  马赛克右顶点\n    :param int w:  马赛克宽\n    :param int h:  马赛克高\n    :param int neighbor:  马赛克每一块的宽\n    \"\"\"\n    fh, fw = frame.shape[0], frame.shape[1]\n    if (y + h &gt; fh) or (x + w &gt; fw):\n        return\n    for i in range(0, h - neighbor, neighbor):  # 关键点0 减去neightbour 防止溢出\n        for j in range(0, w - neighbor, neighbor):\n            rect = [j + x, i + y, neighbor, neighbor]\n            color = frame[i + y][j + x].tolist()  # 关键点1 tolist\n            left_up = (rect[0], rect[1])\n            right_down = (rect[0] + neighbor - 1, rect[1] + neighbor - 1)  # 关键点2 减去一个像素\n            cv2.rectangle(frame, left_up, right_down, color, -1)\n\n\nim = cv2.imread('test.jpg', 1)\ndo_mosaic(im, 219, 61, 460 - 219, 412 - 61)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></p>\n<h5 id=\"高斯滤波\">高斯滤波</h5>\n<p><a href=\"https://www.cnblogs.com/wojianxin/p/12498391.html\">出处</a></p>\n<figure>\n<img src=\"https://img-blog.csdn.net/20171203094927312\" alt=\"二维高斯函数\"><figcaption aria-hidden=\"true\">二维高斯函数</figcaption>\n</figure>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import cv2\nimport numpy as np\n\ndef gaussian_filter(img, K_size=3, sigma=1.3):\n\n    if len(img.shape) == 3:\n        H, W, C = img.shape\n    else:\n        img = np.expand_dims(img, axis=-1)\n        H, W, C = img.shape\n\n    ## Zero padding\n    pad = K_size // 2\n    out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n\n    ## prepare Kernel\n    K = np.zeros((K_size, K_size), dtype=np.float)\n    for x in range(-pad, -pad + K_size):\n        for y in range(-pad, -pad + K_size):\n            K[y + pad, x + pad] = np.exp( -(x ** 2 + y ** 2) / (2 * (sigma ** 2)))\n\n    K /= (2 * np.pi * sigma * sigma)\n    K /= K.sum()\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad + y, pad + x, c] = np.sum(K * tmp[y: y + K_size, x: x + K_size, c])\n\n    out = np.clip(out, 0, 255)\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n    return out\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"均值滤波\">均值滤波</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import numpy as np\n\n\ndef means_filter(input_image, filter_size):\n    '''\n    均值滤波器\n    :param input_image: 输入图像\n    :param filter_size: 滤波器大小\n    :return: 输出图像\n\n    注：此实现滤波器大小必须为奇数且 &gt;= 3\n    '''\n    input_image_cp = np.copy(input_image)  # 输入图像的副本\n    filter_template = np.ones((filter_size, filter_size))  # 空间滤波器模板\n    pad_num = int((filter_size - 1) / 2)  # 输入图像需要填充的尺寸\n    input_image_cp = np.pad(input_image_cp, (pad_num, pad_num), mode=\"constant\", constant_values=0)  # 填充输入图像\n    m, n = input_image_cp.shape  # 获取填充后的输入图像的大小\n    output_image = np.copy(input_image_cp)  # 输出图像\n\n    # 空间滤波\n    for i in range(pad_num, m - pad_num):\n        for j in range(pad_num, n - pad_num):\n            output_image[i, j] = np.sum(filter_template * input_image_cp[i - pad_num:i + pad_num + 1, j - pad_num:j + pad_num + 1]) / (filter_size ** 2)\n    output_image = output_image[pad_num:m - pad_num, pad_num:n - pad_num]  # 裁剪\n\n    return output_image<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"中值滤波\">中值滤波</h5>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\"># 中值滤波#\nimport cv2\nimport numpy as np\n\ndef MedianFilter(img,k=3,padding=None):\n    imarray=img\n    height = imarray.shape[0]\n    width = imarray.shape[1]\n    if not padding:\n        edge = int((k - 1) / 2)\n        if height - 1 - edge &lt;= edge or width - 1 - edge &lt;= edge:\n            print(\"The parameter k is to large.\")\n            return None\n        new_arr = np.zeros((height, width), dtype=\"uint8\")\n        for i in range(edge,height-edge):\n            for j in range(edge,width-edge):\n                new_arr[i, j] = np.median(imarray[i - edge:i + edge + 1, j - edge:j + edge + 1])# 调用np.median求取中值\n    return new_arr\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"kmeans\">Kmeans</h4>\n<p>第一步 - 随机选择 K 个点作为点的聚类中心，这表示我们要将数据分为 K 类。 第二步 - 遍历所有的点 P, 算出 P 到每个聚类中心的距离，将 P 放到最近的聚类中心的点集中。遍历结束后我们将得到 K 个点集。 第三步 - 遍历每一个点集，算出每一个点集的中心位置，将其作为新的聚类中心。 第四步 - 重复步骤 2 和步骤 3，直到聚类中心位置不再移动。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">import numpy as np\n\npoints_x = np.random.rand(20)\npoints_y = np.random.rand(20)\n\nK = 4\np_list = np.stack([points_x, points_y], axis=1)\nindex = np.random.choice(len(p_list), size=K)\ncenteroid = p_list[index]\n\nfor i in range(10):\n    points_set = {key: [] for key in range(K)}\n\n    for p in p_list:\n        nearest_index = np.argmin(np.sum((centeroid - p) ** 2, axis=1) ** 0.5)\n        points_set[nearest_index].append(p)\n\n    for k_index, p_set in points_set.items():\n        p_xs = [p[0] for p in p_set]\n        p_ys = [p[1] for p in p_set]\n        centeroid[k_index, 0] = sum(p_xs) / len(p_set)\n        centeroid[k_index, 1] = sum(p_ys) / len(p_set)\nprint(centeroid)\n\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"图像旋转\"><a href=\"https://www.cnblogs.com/liwill/p/13875745.html\">图像旋转</a></h4>\n<p>图像旋转的过程：</p>\n<ol type=\"1\">\n<li><p>首先将图像坐标系转换为数学坐标系。</p></li>\n<li><p>使用旋转公式对坐标进行旋转。</p></li>\n<li><p>将旋转后的数学坐标系转换为图像坐标系。</p></li>\n</ol>\n<p>用矩阵运算表示：</p>\n<p><span class=\"math display\"><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -3.743ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"81.252ex\" height=\"8.618ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -2154.5 35913.4 3809\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mo\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(278,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(850,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1100,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mtext\" transform=\"translate(1590,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1840,0)\"><path data-c=\"1D467\" d=\"M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2305,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2860.8,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3916.6,0)\"><path data-c=\"5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path></g><g data-mml-node=\"msub\" transform=\"translate(4194.6,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(605,-150) scale(0.707)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g></g><g data-mml-node=\"mtext\" transform=\"translate(5192.5,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"msub\" transform=\"translate(5442.5,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(523,-150) scale(0.707)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g></g><g data-mml-node=\"mtext\" transform=\"translate(6358.4,0)\"><path data-c=\"A0\" d=\"\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6608.4,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7108.4,0)\"><path data-c=\"5D\" d=\"M22 710V750H159V-250H22V-210H119V710H22Z\"></path></g><g data-mml-node=\"mrow\" transform=\"translate(7553.1,0)\"><g data-mml-node=\"mo\"><path data-c=\"23A1\" d=\"M319 -645V1154H666V1070H403V-645H319Z\" transform=\"translate(0,996)\"></path><path data-c=\"23A3\" d=\"M319 -644V1155H403V-560H666V-644H319Z\" transform=\"translate(0,-1006)\"></path><svg width=\"667\" height=\"402\" y=\"49\" x=\"0\" viewBox=\"0 100.5 667 402\"><path data-c=\"23A2\" d=\"M319 0V602H403V0H319Z\" transform=\"scale(1,1.002)\"></path></svg></g><g data-mml-node=\"mtable\" transform=\"translate(667,0)\"><g data-mml-node=\"mtr\" transform=\"translate(0,1400)\"><g data-mml-node=\"mtd\" transform=\"translate(1302,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4937,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(7270,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\" transform=\"translate(1302,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4548,0)\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(7270,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\" transform=\"translate(0,-1400)\"><g data-mml-node=\"mtd\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\" transform=\"translate(500,0)\"></path><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\" transform=\"translate(778,0)\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2056,0)\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4104,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\" transform=\"translate(500,0)\"></path><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\" transform=\"translate(778,0)\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1278,0)\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(7270,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(8437,0)\"><path data-c=\"23A4\" d=\"M0 1070V1154H347V-645H263V1070H0Z\" transform=\"translate(0,996)\"></path><path data-c=\"23A6\" d=\"M263 -560V1155H347V-644H0V-560H263Z\" transform=\"translate(0,-1006)\"></path><svg width=\"667\" height=\"402\" y=\"49\" x=\"0\" viewBox=\"0 100.5 667 402\"><path data-c=\"23A5\" d=\"M263 0V602H347V0H263Z\" transform=\"scale(1,1.002)\"></path></svg></g></g><g data-mml-node=\"mrow\" transform=\"translate(16823.8,0)\"><g data-mml-node=\"mo\"><path data-c=\"23A1\" d=\"M319 -645V1154H666V1070H403V-645H319Z\" transform=\"translate(0,996)\"></path><path data-c=\"23A3\" d=\"M319 -644V1155H403V-560H666V-644H319Z\" transform=\"translate(0,-1006)\"></path><svg width=\"667\" height=\"402\" y=\"49\" x=\"0\" viewBox=\"0 100.5 667 402\"><path data-c=\"23A2\" d=\"M319 0V602H403V0H319Z\" transform=\"scale(1,1.002)\"></path></svg></g><g data-mml-node=\"mtable\" transform=\"translate(667,0)\"><g data-mml-node=\"mtr\" transform=\"translate(0,1400)\"><g data-mml-node=\"mtd\" transform=\"translate(13.5,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(433,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(918,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1387,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1776,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2245,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(3661,0)\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(778,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1247,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1592,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2192,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2581,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3050,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(8100,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\"><g data-mml-node=\"mtd\"><g data-mml-node=\"mi\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(469,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(814,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1414,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1803,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2272,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4063.5,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(433,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(918,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1387,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1776,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2245,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(8100,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\" transform=\"translate(0,-1400)\"><g data-mml-node=\"mtd\" transform=\"translate(1080.5,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(5130.5,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(8100,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(9267,0)\"><path data-c=\"23A4\" d=\"M0 1070V1154H347V-645H263V1070H0Z\" transform=\"translate(0,996)\"></path><path data-c=\"23A6\" d=\"M263 -560V1155H347V-644H0V-560H263Z\" transform=\"translate(0,-1006)\"></path><svg width=\"667\" height=\"402\" y=\"49\" x=\"0\" viewBox=\"0 100.5 667 402\"><path data-c=\"23A5\" d=\"M263 0V602H347V0H263Z\" transform=\"scale(1,1.002)\"></path></svg></g></g><g data-mml-node=\"mrow\" transform=\"translate(26924.4,0)\"><g data-mml-node=\"mo\"><path data-c=\"23A1\" d=\"M319 -645V1154H666V1070H403V-645H319Z\" transform=\"translate(0,1000.5)\"></path><path data-c=\"23A3\" d=\"M319 -644V1155H403V-560H666V-644H319Z\" transform=\"translate(0,-1010.5)\"></path><svg width=\"667\" height=\"411\" y=\"44.5\" x=\"0\" viewBox=\"0 102.7 667 411\"><path data-c=\"23A2\" d=\"M319 0V602H403V0H319Z\" transform=\"scale(1,1.024)\"></path></svg></g><g data-mml-node=\"mtable\" transform=\"translate(667,0)\"><g data-mml-node=\"mtr\" transform=\"translate(0,1404.5)\"><g data-mml-node=\"mtd\" transform=\"translate(1079.3,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4656.8,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(7155,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\" transform=\"translate(0,4.5)\"><g data-mml-node=\"mtd\" transform=\"translate(1079.3,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(4267.8,0)\"><g data-mml-node=\"mo\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(778,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g><g data-mml-node=\"mtd\" transform=\"translate(7155,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path></g></g></g><g data-mml-node=\"mtr\" transform=\"translate(0,-1404.5)\"><g data-mml-node=\"mtd\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\" transform=\"translate(500,0)\"></path><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\" transform=\"translate(778,0)\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1278,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1136.2,363) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g></g></g><g data-mml-node=\"mtd\" transform=\"translate(3658.7,0)\"><g data-mml-node=\"mn\"><path data-c=\"30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path data-c=\"2E\" d=\"M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z\" transform=\"translate(500,0)\"></path><path data-c=\"35\" d=\"M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z\" transform=\"translate(778,0)\"></path></g><g data-mml-node=\"msup\" transform=\"translate(1278,0)\"><g data-mml-node=\"mi\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(973.9,363) scale(0.707)\"><path data-c=\"2032\" d=\"M79 43Q73 43 52 49T30 61Q30 68 85 293T146 528Q161 560 198 560Q218 560 240 545T262 501Q262 496 260 486Q259 479 173 263T84 45T79 43Z\"></path></g></g></g><g data-mml-node=\"mtd\" transform=\"translate(7155,0)\"><g data-mml-node=\"mn\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g></g></g></g><g data-mml-node=\"mo\" transform=\"translate(8322,0)\"><path data-c=\"23A4\" d=\"M0 1070V1154H347V-645H263V1070H0Z\" transform=\"translate(0,1000.5)\"></path><path data-c=\"23A6\" d=\"M263 -560V1155H347V-644H0V-560H263Z\" transform=\"translate(0,-1010.5)\"></path><svg width=\"667\" height=\"411\" y=\"44.5\" x=\"0\" viewBox=\"0 102.7 667 411\"><path data-c=\"23A5\" d=\"M263 0V602H347V0H263Z\" transform=\"scale(1,1.024)\"></path></svg></g></g></g></g></svg></mjx-container></span></p>\n<p>其中x，y是转换后的坐标，x_o，y_o是原始的坐标，θ是旋转的角度；第一个矩阵是将图像坐标系转换为数学坐标系，W和H分别为图像的宽高；第二个矩阵为旋转公式；第三个公式是将数学坐标系转换为图像坐标系，W’和H'分别是新图像的宽高。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>这里坐标系转换原因：图像坐标系，(0，0)点在左上角，数学中(0，0)点为图片中点。</p></blockquote>\n<p>旋转后的图片长宽：</p>\n<p><img src=\"/images/interview/rotate.png\" width=\"75%\" height=\"75%\"></p>\n<p>参照上图(<a href=\"https://www.cnblogs.com/liwill/p/13875745.html\">来源</a>)，</p>\n<p>旋转的主要情况分为上面4种情况，旋转了[0，90°)，[90°，180°)，[180°，270°)，[270°，360°)，黑色坐标轴为原始图像坐标轴，红色为旋转后的图像坐标轴。注意图二和图四的宽高相对于图一和图三的宽高是变了位置的。</p>\n<p><span class=\"math display\"><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.566ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"21.324ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 9425.2 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(888,0)\"><path data-c=\"2035\" d=\"M12 501Q12 527 31 542T63 558Q73 560 77 560Q114 560 128 528Q133 518 188 293T244 61Q244 56 223 50T195 43Q192 43 190 45T102 263T14 486Q12 496 12 501Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1163,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2218.8,0)\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3106.8,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3539.8,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4024.8,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4716,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5716.2,0)\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6764.2,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7233.2,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7578.2,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8178.2,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8567.2,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9036.2,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container></span> <span class=\"math display\"><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.566ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"21.686ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 9585.2 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1048,0)\"><path data-c=\"2035\" d=\"M12 501Q12 527 31 542T63 558Q73 560 77 560Q114 560 128 528Q133 518 188 293T244 61Q244 56 223 50T195 43Q192 43 190 45T102 263T14 486Q12 496 12 501Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1323,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(2378.8,0)\"><path data-c=\"1D44A\" d=\"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3426.8,0)\"><path data-c=\"1D450\" d=\"M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(3859.8,0)\"><path data-c=\"1D45C\" d=\"M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4344.8,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5036,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6036.2,0)\"><path data-c=\"1D43B\" d=\"M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(6924.2,0)\"><path data-c=\"1D460\" d=\"M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7393.2,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7738.2,0)\"><path data-c=\"1D45B\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8338.2,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(8727.2,0)\"><path data-c=\"1D703\" d=\"M35 200Q35 302 74 415T180 610T319 704Q320 704 327 704T339 705Q393 701 423 656Q462 596 462 495Q462 380 417 261T302 66T168 -10H161Q125 -10 99 10T60 63T41 130T35 200ZM383 566Q383 668 330 668Q294 668 260 623T204 521T170 421T157 371Q206 370 254 370L351 371Q352 372 359 404T375 484T383 566ZM113 132Q113 26 166 26Q181 26 198 36T239 74T287 161T335 307L340 324H145Q145 321 136 286T120 208T113 132Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(9196.2,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container></span></p>\n<p>四个角度相当于θ-0×90°，θ-1×90°，θ-2×90°，θ-3×90°，计算结果可以用θ%90°来得到。但是因为图二和图四的宽高已经变换位置了，为了使用同一条计算新图像宽高的公式，图二图四可以用(90°-(θ%90))得到另一个角的度数，来计算新图像的宽高，只需要计算θ%90°的结果，如果是奇数(1or3)就求另一个角的度数。</p>\n<h5 id=\"前向映射\">前向映射</h5>\n<p>新图像里面很多像素都没有填充到，因为前向映射算出来的结果有小数，不能一一映射到新图像的每个坐标上</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def rotate(x, angle):\n    h, w, c = x.shape\n    if int(angle / 90) % 2 == 0:\n        reshape_angle = angle % 90\n    else:\n        reshape_angle = 90 - (angle % 90)\n\n    radian = math.radians(angle)  # 角度转弧度\n\n    reshape_radian = math.radians(reshape_angle)  # 角度转弧度, 只用来求新的宽高\n\n    # 三角函数计算出来的结果会有小数，所以做了向上取整的操作。\n    new_height = math.ceil(h * np.cos(reshape_radian) + w * np.sin(reshape_radian))\n    new_width = math.ceil(w * np.cos(reshape_radian) + h * np.sin(reshape_radian))\n\n    if c:\n        new_img = np.zeros((new_height, new_width, c), dtype=np.uint8)\n    else:\n        new_img = np.zeros((new_height, new_width), dtype=np.uint8)\n\n    # 图像坐标系到数学坐标系\n    I2M = np.zeros([3, 3])\n    I2M[0, 0] = 1\n    I2M[1, 1] = -1\n    I2M[2, 2] = 1\n    I2M[2, 0] = -0.5 * w\n    I2M[2, 1] = 0.5 * h\n\n    # 数学坐标系到图像坐标系\n    M2I = np.zeros([3, 3])\n    M2I[0, 0] = 1\n    M2I[1, 1] = -1\n    M2I[2, 2] = 1\n    M2I[2, 0] = 0.5 * new_width\n    M2I[2, 1] = 0.5 * new_height\n\n    kernel = np.zeros([3, 3])\n    kernel[0, 0] = np.cos(radian)\n    kernel[0, 1] = -np.sin(radian)\n    kernel[1, 0] = np.sin(radian)\n    kernel[1, 1] = np.cos(radian)\n    kernel[2, 2] = 1\n\n    for y0 in range(h):\n        for x0 in range(w):\n            roi = np.array([x0, y0, 1])\n            roi = roi @ I2M @ kernel @ M2I\n            new_img[int(roi[1]) - 1, int(roi[0]) - 1] = bgr[int(y0), int(x0)]\n\n    return new_img<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"后向映射\">后向映射</h5>\n<p>后向映射就是通过新图像的每个坐标点找到原始图像中对应的坐标点，再把像素赋值上去。 重点是修改旋转矩阵和两个坐标变换矩阵</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def rotate2(x, angle):\n    h, w, c = x.shape\n    if int(angle / 90) % 2 == 0:\n        reshape_angle = angle % 90\n    else:\n        reshape_angle = 90 - (angle % 90)\n\n    radian = math.radians(angle)  # 角度转弧度\n\n    reshape_radian = math.radians(reshape_angle)  # 角度转弧度\n\n    # 三角函数计算出来的结果会有小数，所以做了向上取整的操作。\n    new_height = math.ceil(h * np.cos(reshape_radian) + w * np.sin(reshape_radian))\n    new_width = math.ceil(w * np.cos(reshape_radian) + h * np.sin(reshape_radian))\n\n    if c:\n        new_img = np.zeros((new_height, new_width, c), dtype=np.uint8)\n    else:\n        new_img = np.zeros((new_height, new_width), dtype=np.uint8)\n\n    # 图像坐标系到数学坐标系\n    I2M = np.zeros([3, 3])\n    I2M[0, 0] = 1\n    I2M[1, 1] = -1\n    I2M[2, 2] = 1\n    I2M[2, 0] = -0.5 * new_width\n    I2M[2, 1] = 0.5 * new_height\n\n    # 数学坐标系到图像坐标系\n    M2I = np.zeros([3, 3])\n    M2I[0, 0] = 1\n    M2I[1, 1] = -1\n    M2I[2, 2] = 1\n    M2I[2, 0] = 0.5 * w\n    M2I[2, 1] = 0.5 * h\n\n    kernel = np.zeros([3, 3])\n    kernel[0, 0] = np.cos(radian)\n    kernel[0, 1] = np.sin(radian)\n    kernel[1, 0] = -np.sin(radian)\n    kernel[1, 1] = np.cos(radian)\n    kernel[2, 2] = 1\n\n    for y0 in range(new_height):\n        for x0 in range(new_width):\n            roi = np.array([x0, y0, 1])\n            roi = roi @ I2M @ kernel @ M2I\n            if 0 &lt; int(roi[0]) &lt;= w and 0 &lt; int(roi[1]) &lt;= h:\n                new_img[int(y0), int(x0)] = bgr[int(roi[1]) - 1, int(roi[0]) - 1]\n\n    return new_img<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"积分图\">积分图</h4>\n<p><a href=\"https://zhuanlan.zhihu.com/p/355255078\">原理参考</a></p>\n<p>总结：(x,y)的积分值可以使用(x-1,y)与(x,y-1)的积分值之和，然后减去重叠区域，也就是减去(x-1,y-1)的积分值，最后再加上(x,y)的像素值得到(x,y)的积分值。</p>\n<p><span class=\"math display\"><mjx-container class=\"MathJax\" jax=\"SVG\" display=\"true\"><svg style=\"vertical-align: -0.566ex\" xmlns=\"http://www.w3.org/2000/svg\" width=\"62.249ex\" height=\"2.262ex\" role=\"img\" focusable=\"false\" viewBox=\"0 -750 27514 1000\"><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"scale(1,-1)\"><g data-mml-node=\"math\"><g data-mml-node=\"mi\"><path data-c=\"1D43C\" d=\"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(504,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(893,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(1465,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(1909.7,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(2399.7,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(3066.4,0)\"><path data-c=\"3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(4122.2,0)\"><path data-c=\"1D43C\" d=\"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(4626.2,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(5015.2,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(5809.4,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(6809.7,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(7309.7,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(7754.3,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8244.3,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(8855.6,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(9855.8,0)\"><path data-c=\"1D43C\" d=\"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(10359.8,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(10748.8,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(11320.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(11765.4,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(12477.7,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(13477.9,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(13977.9,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(14589.1,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(15589.3,0)\"><path data-c=\"1D43C\" d=\"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(16093.3,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(16482.3,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(17276.6,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(18276.8,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(18776.8,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(19221.4,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(19933.7,0)\"><path data-c=\"2212\" d=\"M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z\"></path></g><g data-mml-node=\"mn\" transform=\"translate(20933.9,0)\"><path data-c=\"31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(21433.9,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(22045.1,0)\"><path data-c=\"2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(23045.3,0)\"><path data-c=\"1D45D\" d=\"M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(23548.3,0)\"><path data-c=\"1D456\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(23893.3,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(24465.3,0)\"><path data-c=\"1D452\" d=\"M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(24931.3,0)\"><path data-c=\"1D459\" d=\"M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(25229.3,0)\"><path data-c=\"28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(25618.3,0)\"><path data-c=\"1D465\" d=\"M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(26190.3,0)\"><path data-c=\"2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path></g><g data-mml-node=\"mi\" transform=\"translate(26635,0)\"><path data-c=\"1D466\" d=\"M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></g><g data-mml-node=\"mo\" transform=\"translate(27125,0)\"><path data-c=\"29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></g></g></g></svg></mjx-container></span></p>\n<p>额外注意第一行/第一列计算： 对于第一行：</p>\n<p>I(0,0) = pixel(0,0)，x=0，y=0 I(x,0) = I(x-1,0) + pixel(x,0)，x&gt;0，y=0</p>\n<p>对于第一列： I(0,y) = I(0,y-1) + pixel(0,y)，x=0，y&gt;0</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">matrix = np.ones([12, 10])\nprint(np.sum(matrix))\nh, w = matrix.shape\n\ngraph = np.zeros([12, 10])\nfor y in range(h):\n    for x in range(w):\n        if x == 0:\n            if y == 0:\n                graph[y, x] = matrix[y, x]\n            else:\n                graph[y, x] = graph[y-1, x] + matrix[y, x]\n        elif y == 0:\n            graph[y, x] = graph[y, x-1] + matrix[y, x]\n        else:\n            graph[y, x] = graph[y, x-1] + graph[y-1, x] - graph[y-1, x-1] + matrix[y, x]\n\nprint(graph)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"积分图均值滤波\">积分图均值滤波</h4>\n<p><a href=\"https://blog.csdn.net/weixin_40647819/article/details/88775598\">参考</a></p>\n<p><img src=\"/images/interview/jifentu.png\" width=\"75%\" height=\"75%\"></p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def meanFilter(matrix, k):\n    ss = (k - 1) // 2\n    for y in range(ss, h - ss):\n        for x in range(ss, w - ss):\n            y0 = y - ss - 1\n            x0 = x - ss - 1\n    \n            y1 = y + ss\n            x1 = x + ss\n    \n            if y == ss:\n                if x == ss:\n                    matrix[y, x] = graph[y1, x1] / (k * k)\n                else:\n                    m = (graph[y1, x1] - graph[y1, x0]) / (k * k)\n                    matrix[y, x] = m\n    \n            elif x == ss:\n                m = (graph[y1, x1] - graph[y0, x1]) / (k * k)\n                matrix[y, x] = m\n    \n            else:\n                m = (graph[y1, x1] + graph[x0, y0] - graph[y1, x0] - graph[y0, x1]) / (k * k)\n                matrix[y, x] = m\n    return matrix<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h4 id=\"双线性插值\"><a href=\"https://blog.csdn.net/pentiumCM/article/details/104720100/\">双线性插值</a></h4>\n<p>对于一个目的像素点dst[x][y]，通过反向变换得到的源图像中 浮点坐标为 src[i + u][j + v] (其中i、j均为浮点坐标的整数部分，u、v为浮点坐标的小数部分，是取值[0,1)区间的浮点数)，则这个像素点的值 f(i+u,j+v) 可由原图像中坐标为 (i,j)、(i+1,j)、(i,j+1)、(i+1,j+1)所对应的最相邻四个像素点的值（灰度值或者RGB值）最相邻四个像素点的值（灰度值或者RGB值）最相邻四个像素点的值（灰度值或者RGB值）决定，即：</p>\n<p>f(i+u,j+v) = (1-u)(1-v)f(i,j) + (1-u)vf(i,j+1) + u(1-v)f(i+1,j) + uvf(i+1,j+1)</p>\n<p>其中f(i,j)表示源图像(i,j)处的的值（灰度值或者RGB值），以此类推。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">def bilinear(src_img, dst_shape):\n    \"\"\"\n    双线性插值法,来调整图片尺寸\n\n    :param org_img: 原始图片\n    :param dst_shape: 调整后的目标图片的尺寸\n    :return:    返回调整尺寸后的图片矩阵信息\n    \"\"\"\n    dst_img = np.zeros((dst_shape[0], dst_shape[1], 3), np.uint8)\n    dst_h, dst_w = dst_shape\n    src_h = src_img.shape[0]\n    src_w = src_img.shape[1]\n    # i：纵坐标y，j：横坐标x\n    # 缩放因子，dw,dh\n    scale_w = src_w / dst_w\n    scale_h = src_h / dst_h\n\n    for i in range(dst_h):\n        for j in range(dst_w):\n            src_x = float((j + 0.5) * scale_w - 0.5)\n            src_y = float((i + 0.5) * scale_h - 0.5)\n\n            # 向下取整，代表靠近源点的左上角的那一点的行列号\n            src_x_int = math.floor(src_x)\n            src_y_int = math.floor(src_y)\n\n            # 取出小数部分，用于构造权值\n            src_x_float = src_x - src_x_int\n            src_y_float = src_y - src_y_int\n\n            if src_x_int + 1 == src_w or src_y_int + 1 == src_h:\n                dst_img[i, j, :] = src_img[src_y_int, src_x_int, :]\n                continue\n            dst_img[i, j, :] = (1. - src_y_float) * (1. - src_x_float) * src_img[src_y_int, src_x_int, :] + \\\n                               (1. - src_y_float) * src_x_float * src_img[src_y_int, src_x_int + 1, :] + \\\n                               src_y_float * (1. - src_x_float) * src_img[src_y_int + 1, src_x_int, :] + \\\n                               src_y_float * src_x_float * src_img[src_y_int + 1, src_x_int + 1, :]\n    return dst_img<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n","text":"1. IOU python def bb_intersection_over_union(boxA, boxB): boxA = [int(x) for x in boxA] boxB = [int(x) for x in boxB] xA = max(boxA[0], boxB...","link":"","photos":[],"count_time":{"symbolsCount":"33k","symbolsTime":"30 mins."},"categories":[],"tags":[{"name":"interview summary","slug":"interview-summary","count":2,"path":"api/tags/interview-summary.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#iou\"><span class=\"toc-text\">1. IOU</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python\"><span class=\"toc-text\">python</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#c\"><span class=\"toc-text\">c++</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#nms\"><span class=\"toc-text\">2. NMS</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-1\"><span class=\"toc-text\">python</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#c-1\"><span class=\"toc-text\">c++</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF\"><span class=\"toc-text\">3. 卷积</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-2\"><span class=\"toc-text\">python</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#c-2\"><span class=\"toc-text\">c++</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#pooling\"><span class=\"toc-text\">4. Pooling</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#maxpooling\"><span class=\"toc-text\">maxpooling</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC1%E7%AE%80%E5%8D%95%E7%89%88\"><span class=\"toc-text\">版本1(简单版)</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC2%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD\"><span class=\"toc-text\">版本2(反向传播)</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#avg-pooling\"><span class=\"toc-text\">avg-pooling</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC1%E7%AE%80%E5%8D%95%E7%89%88-1\"><span class=\"toc-text\">版本1(简单版)</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC2%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD-1\"><span class=\"toc-text\">版本2(反向传播)</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#map\"><span class=\"toc-text\">5. mAP</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-3\"><span class=\"toc-text\">python</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#c-3\"><span class=\"toc-text\">c++</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#softnms\"><span class=\"toc-text\">6. softnms</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-4\"><span class=\"toc-text\">python</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC1\"><span class=\"toc-text\">版本1</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E7%89%88%E6%9C%AC2\"><span class=\"toc-text\">版本2</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#c-4\"><span class=\"toc-text\">c++</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E7%8E%B0one-hot%E7%89%B9%E5%BE%81\"><span class=\"toc-text\">7. 实现one-hot特征</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-5\"><span class=\"toc-text\">python</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#softmax\"><span class=\"toc-text\">8. softmax</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#python-6\"><span class=\"toc-text\">python</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%90%84%E7%A7%8D%E6%BB%A4%E6%B3%A2\"><span class=\"toc-text\">9. 各种滤波</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E9%A9%AC%E8%B5%9B%E5%85%8B\"><span class=\"toc-text\">马赛克</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E9%AB%98%E6%96%AF%E6%BB%A4%E6%B3%A2\"><span class=\"toc-text\">高斯滤波</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%9D%87%E5%80%BC%E6%BB%A4%E6%B3%A2\"><span class=\"toc-text\">均值滤波</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E4%B8%AD%E5%80%BC%E6%BB%A4%E6%B3%A2\"><span class=\"toc-text\">中值滤波</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#kmeans\"><span class=\"toc-text\">Kmeans</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E6%97%8B%E8%BD%AC\"><span class=\"toc-text\">图像旋转</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%89%8D%E5%90%91%E6%98%A0%E5%B0%84\"><span class=\"toc-text\">前向映射</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%90%8E%E5%90%91%E6%98%A0%E5%B0%84\"><span class=\"toc-text\">后向映射</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A7%AF%E5%88%86%E5%9B%BE\"><span class=\"toc-text\">积分图</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%A7%AF%E5%88%86%E5%9B%BE%E5%9D%87%E5%80%BC%E6%BB%A4%E6%B3%A2\"><span class=\"toc-text\">积分图均值滤波</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8F%8C%E7%BA%BF%E6%80%A7%E6%8F%92%E5%80%BC\"><span class=\"toc-text\">双线性插值</span></a></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"无监督对比学习(Contrastive Learning)","uid":"6a7adc715ac6ff36450127ebb3bb8662","slug":"无监督对比学习-Contrastive-LearningOC","date":"2021-11-02T03:39:11.000Z","updated":"2021-11-16T09:01:41.483Z","comments":true,"path":"api/articles/无监督对比学习-Contrastive-LearningOC.json","keywords":null,"cover":"/images/contrastive/cl.jpg","text":" 推荐阅读 对比学习 原理: 输入N个图片，用不同的数据增强方法为每个图片生成两个view，分别对它们编码得到y和y'。我们对上下两批表示两两计算cosine，得到NxN的矩阵，每一行的对角线位置代表y和y'的相似度，其余代表y和N-1个负例的相似度。 对每一行做softmax分...","link":"","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"work summary","slug":"work-summary","count":5,"path":"api/tags/work-summary.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}},"next_post":{"title":"CV面试基础总结","uid":"2d84f3892209cec11720cffbf464a897","slug":"CV面试基础总结","date":"2021-10-12T07:57:22.000Z","updated":"2021-12-10T08:10:44.893Z","comments":true,"path":"api/articles/CV面试基础总结.json","keywords":null,"cover":"/images/interview/FID_dis.jpg","text":"1. 评测指标 1.1 基本概念 1.1.1 TP TN FP FN T-Ture;F-False 表示预测结果的正确性，T表示预测正确，F表示预测错误； P-positive;N-negative 表示预测的正负性，P表示预测为正样本，N表示预测为负样本； --- --- TP...","link":"","photos":[],"count_time":{"symbolsCount":"49k","symbolsTime":"45 mins."},"categories":[],"tags":[{"name":"interview summary","slug":"interview-summary","count":2,"path":"api/tags/interview-summary.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}}}