{"title":"YOLO-V5学习笔记","uid":"57d3aa7cdcc56700d35ee7aa4e8c6558","slug":"YOLO-V5学习笔记","date":"2021-09-09T07:42:37.000Z","updated":"2021-11-15T08:43:40.519Z","comments":true,"path":"api/articles/YOLO-V5学习笔记.json","keywords":null,"cover":"https://gimg2.baidu.com/image_search/src=http%3A%2F%2Fuser-images.githubusercontent.com%2F26833433%2F98699617-a1595a00-2377-11eb-8145-fc674eb9b1a7.jpg&refer=http%3A%2F%2Fuser-images.githubusercontent.com&app=2002&size=f9999,10000&q=a80&n=0&g=0n&fmt=jpeg?sec=1639557802&t=bf12f6b55521be8949bcb635defaedc5","content":"<h3 id=\"yolo-v5学习笔记\">YOLO-V5学习笔记</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380</p></blockquote>\n<h4 id=\"网络结构\">网络结构</h4>\n<img src=\"/images/yolo_v5/arch.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nYolov5s网络结构(来源见水印)\n</p>\n<p>如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、Neck以及Prediction四部分来理解。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Yolov5官方代码中，一共有4个版本，分别是Yolov5s、Yolov5m、Yolov5l、Yolov5x四个模型。Yolov5s是Yolov5系列中深度最小，特征图的宽度最小的网络。后面的3种都是在此基础上不断加深，不断加宽。</p></blockquote>\n<h4 id=\"输入端\">输入端</h4>\n<h5 id=\"mosaic数据增强\">Mosaic数据增强</h5>\n<p>与v4一样，采用Mosaic数据增强；</p>\n<h5 id=\"自适应锚框计算\">自适应锚框计算</h5>\n<p>将anchor初始计算(聚类)集成到训练代码中；</p>\n<h5 id=\"自适应图片缩放\">自适应图片缩放</h5>\n<p><u><strong>针对inference阶段的优化</strong></u></p>\n<p>在常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，再送入检测网络中。</p>\n<img src=\"/images/yolo_v5/auto_pad_1.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\n传统方法(来源见水印)\n</p>\n<p>但Yolov5代码中对此进行了改进，也是Yolov5推理速度能够很快的一个不错的trick。</p>\n<p>作者认为，在项目实际使用时，很多图片的长宽比不同，因此缩放填充后，两端的黑边大小都不同，而如果填充的比较多，则存在信息冗余，影响推理速度。</p>\n<p>因此在Yolov5的代码中datasets.py的letterbox函数中进行了修改，对原始图像自适应的添加最少的黑边。</p>\n<img src=\"/images/yolo_v5/auto_pad_2.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nyolov5(来源见水印)\n</p>\n<p>举例说明填充方法： 原始：800x600 目标：416</p>\n<ol type=\"1\">\n<li>选择小的缩放系数，短边:min(416/800, 416/600);</li>\n<li>得到新的尺寸(即长边resize到目标尺寸,短边按原始长宽比变换）: (416,312);</li>\n<li>计算pad大小(找到大于312且能被32整除的最小整数): (416 - 312) mod 32 = 8 所以pad值为8/2=4</li>\n</ol>\n<h4 id=\"backbone\">Backbone</h4>\n<h5 id=\"focus结构\">Focus结构</h5>\n<img src=\"/images/yolo_v5/focus.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nfocus(来源见水印)\n</p>\n<p>yolov5中，Focus模块位于backbone前。具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张近似下采样的图片，但是没有信息丢失。相当于w,h变为1/2，输入通道扩充了4倍，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。</p>\n<p>以yolov5s为例，原始的640 × 640 × 3的图像输入Focus结构，采用切片操作，先变成320 × 320 × 12的特征图，再经过一次卷积操作，最终变成320 × 320 × 32的特征图。</p>\n<p><strong>具体代码实现：</strong></p>\n<p><img src=\"/images/yolo_v5/focus_code.jpg\" width=\"75%\" height=\"75%\"></p>\n<p><strong>目的和作用：</strong> Focus是为了提速，和mAP无关，减少了计算量和参数量。</p>\n<p>The YOLOv5 Focus layer replaces the first 3 YOLOv3 layers with a single layer:</p>\n<p><img src=\"/images/yolo_v5/focus_2.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>详见<a href=\"https://github.com/ultralytics/yolov5/discussions/3181\">作者解答</a></p>\n<h5 id=\"csp结构\">CSP结构</h5>\n<p>Yolov5与Yolov4不同点在于，Yolov4中只有主干网络使用了CSP结构。</p>\n<p>而Yolov5中设计了两种CSP结构，以Yolov5s网络为例，CSP1_X结构应用于Backbone主干网络，另一种CSP2_X结构则应用于Neck中。</p>\n<p><img src=\"/images/yolo_v5/csp.jpg\" width=\"75%\" height=\"75%\"></p>\n<h4 id=\"neck\">Neck</h4>\n<ol type=\"1\">\n<li>Yolov5现在的Neck和Yolov4中一样，都采用FPN+PAN的结构.</li>\n<li>如CSP结构中讲到，Yolov5和Yolov4的不同点在于，Yolov4的Neck结构中，采用的都是普通的卷积操作。而Yolov5的Neck结构中，采用借鉴CSPnet设计的CSP2结构，加强网络特征融合的能力。</li>\n</ol>\n<p><img src=\"/images/yolo_v5/neck.jpg\" width=\"75%\" height=\"75%\"></p>\n<h4 id=\"prediction\">Prediction</h4>\n<h5 id=\"bounding-box损失函数\">Bounding box损失函数</h5>\n<p>Yolov5: GIOU_Loss Yolov4: CIOU_Loss</p>\n<h5 id=\"nms非极大值抑制\">nms非极大值抑制</h5>\n<p>Yolov4: DIOU_nms Yolov5: 加权nms</p>\n<p>加权非极大值抑制与传统的非极大值抑制相比，是在进行矩形框剔除的过程中，并未将那些与当前矩形框IOU大于阈值，且类别相同的框直接剔除，而是根据网络预测的置信度进行加权，得到新的矩形框，把该矩形框作为最终预测的矩形框，再将那些框剔除。</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">while detections.size(0):\n    # 得到第一个bbx与其余bbx的iou大于nms_thres的判别(0, 1)， 1为大于，0为小于\n    large_overlap = bbox_iou(detections[0, :4].unsqueeze(0), detections[:, :4]) &gt; nms_thres\n\n    # 判断他们的类别是否相同，只有相同时才进行nms， 相同时为1， 不同时为0\n    label_match = detections[0, -1] == detections[:, -1]\n    # Indices of boxes with lower confidence scores, large IOUs and matching labels\n\n    # 只有在两个bbx的iou大于thres，且类别相同时，invalid为True，其余为False\n    invalid = large_overlap &amp; label_match\n\n    # weights为对应的权值, 其格式为：将True bbx中的confidence连成一个Tensor\n    weights = detections[invalid, 4:5]\n\n    # Merge overlapping bboxes by order of confidence\n    # 这里得到最后的bbx它是跟他满足IOU大于threshold，并且相同label的一些bbx，根据confidence重新加权得到\n    # 并不是原始bbx的保留。\n\n    detections[0, :4] = (weights * detections[invalid, :4]).sum(0) / weights.sum()\n    keep_boxes += [detections[0]]\n\n    # 去掉这些invalid\n    detections = detections[~invalid]\nif keep_boxes:\n    output[image_i] = torch.stack(keep_boxes)\n<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Weighted NMS出现于ICME Workshop 2017《Inception Single Shot MultiBox Detector for object detection》一文中。论文认为Traditional NMS每次迭代所选出的最大得分框未必是精确定位的，冗余框也有可能是定位良好的。那么与直接剔除机制不同，Weighted NMS顾名思义是对坐标加权平均，加权平均的对象包括M自身以及IoU≥NMS阈值的相邻框。 <img src=\"/images/yolo_v5/weight_nms.jpg\" width=\"30%\" height=\"30%\"> 加权的权重为 : <img src=\"/images/yolo_v5/weight_nms_2.jpg\" width=\"20%\" height=\"20%\">  ，表示得分与IoU的乘积。</p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>优点</strong>：Weighted NMS通常能够获得更高的Precision和Recall，只要NMS阈值选取得当，Weighted NMS均能稳定提高AP与AR，无论是AP50还是AP75，也不论所使用的检测模型是什么。</p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>缺点</strong>：顺序处理模式，且运算效率比Traditional NMS更低。加权因子是IoU与得分，前者只考虑两个框的重叠面积，这对描述box重叠关系或许不够全面；而后者受到定位与得分不一致问题的限制。</p></blockquote>\n","text":"YOLO-V5学习笔记 知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380 网络结构 Yolov5s网络结构(来源见水印) 如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、N...","link":"","photos":[],"count_time":{"symbolsCount":"3.2k","symbolsTime":"3 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":6,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#yolo-v5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">YOLO-V5学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">网络结构</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%BE%93%E5%85%A5%E7%AB%AF\"><span class=\"toc-text\">输入端</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#mosaic%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">Mosaic数据增强</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E9%94%9A%E6%A1%86%E8%AE%A1%E7%AE%97\"><span class=\"toc-text\">自适应锚框计算</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE\"><span class=\"toc-text\">自适应图片缩放</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#backbone\"><span class=\"toc-text\">Backbone</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#focus%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">Focus结构</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#csp%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">CSP结构</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#neck\"><span class=\"toc-text\">Neck</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#prediction\"><span class=\"toc-text\">Prediction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#bounding-box%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">Bounding box损失函数</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#nms%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6\"><span class=\"toc-text\">nms非极大值抑制</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"FCOS学习笔记","uid":"7f399d762217f0410e81da356daa491f","slug":"FCOS学习笔记","date":"2021-09-13T08:19:35.000Z","updated":"2021-11-15T08:42:37.687Z","comments":true,"path":"api/articles/FCOS学习笔记.json","keywords":null,"cover":"/images/FCOS/regress.jpg","text":"FCOS学习笔记 笔记来源：FCOS算法详解 FCOS论文精读——看这一篇就够了 FCOS是一个基于FCN的per-pixel、anchor free的one-stage目标检测算法，论文全:《FCOS: Fully Convolutional One-Stage Object ...","link":"","photos":[],"count_time":{"symbolsCount":"2.7k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":6,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}},"next_post":{"title":"Pixel-Level Domain Transfer论文复现","uid":"f45a749a54e27d0a1f22b1f23eadc80a","slug":"Pixel-Level-Domain-Transfer论文复现","date":"2021-09-06T11:51:46.000Z","updated":"2021-11-03T10:59:59.413Z","comments":true,"path":"api/articles/Pixel-Level-Domain-Transfer论文复现.json","keywords":null,"cover":"/images/DTGan/arch.jpg","text":"Pixel-Level Domain Transfer论文复现 博客迁移，原文链接 Abstract.：We present an image-conditional image generation model. The model transfers an input dom...","link":"","photos":[],"count_time":{"symbolsCount":"6.5k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"csdn迁移","slug":"csdn迁移","count":1,"path":"api/tags/csdn迁移.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"学习、记录、总结<br />kill拖延症<br /> 不生产知识，只是知识的搬运工<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}}}