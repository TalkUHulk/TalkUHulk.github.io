{"title":"YOLO-V5学习笔记","uid":"57d3aa7cdcc56700d35ee7aa4e8c6558","slug":"YOLO-V5学习笔记","date":"2021-09-09T07:42:37.000Z","updated":"2021-10-12T07:12:51.837Z","comments":true,"path":"api/articles/YOLO-V5学习笔记.json","keywords":null,"cover":[],"content":"<h3 id=\"yolo-v5学习笔记\">YOLO-V5学习笔记</h3>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380</p></blockquote>\n<h4 id=\"网络结构\">网络结构</h4>\n<img src=\"/images/yolo_v5/arch.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nYolov5s网络结构(来源见水印)\n</p>\n<p>如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、Neck以及Prediction四部分来理解。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Yolov5官方代码中，一共有4个版本，分别是Yolov5s、Yolov5m、Yolov5l、Yolov5x四个模型。Yolov5s是Yolov5系列中深度最小，特征图的宽度最小的网络。后面的3种都是在此基础上不断加深，不断加宽。</p></blockquote>\n<h4 id=\"输入端\">输入端</h4>\n<h5 id=\"mosaic数据增强\">Mosaic数据增强</h5>\n<p>与v4一样，采用Mosaic数据增强；</p>\n<h5 id=\"自适应锚框计算\">自适应锚框计算</h5>\n<p>将anchor初始计算(聚类)集成到训练代码中；</p>\n<h5 id=\"自适应图片缩放\">自适应图片缩放</h5>\n<p><u><strong>针对inference阶段的优化</strong></u></p>\n<p>在常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，再送入检测网络中。</p>\n<img src=\"/images/yolo_v5/auto_pad_1.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\n传统方法(来源见水印)\n</p>\n<p>但Yolov5代码中对此进行了改进，也是Yolov5推理速度能够很快的一个不错的trick。</p>\n<p>作者认为，在项目实际使用时，很多图片的长宽比不同，因此缩放填充后，两端的黑边大小都不同，而如果填充的比较多，则存在信息冗余，影响推理速度。</p>\n<p>因此在Yolov5的代码中datasets.py的letterbox函数中进行了修改，对原始图像自适应的添加最少的黑边。</p>\n<img src=\"/images/yolo_v5/auto_pad_2.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nyolov5(来源见水印)\n</p>\n<p>举例说明填充方法： 原始：800x600 目标：416</p>\n<ol type=\"1\">\n<li>选择小的缩放系数，短边:min(416/800, 416/600);</li>\n<li>得到新的尺寸(即长边resize到目标尺寸,短边按原始长宽比变换）: (416,312);</li>\n<li>计算pad大小(找到大于312且能被32整除的最小整数): (416 - 312) mod 32 = 8 所以pad值为8/2=4</li>\n</ol>\n<h4 id=\"backbone\">Backbone</h4>\n<h5 id=\"focus结构\">Focus结构</h5>\n<img src=\"/images/yolo_v5/focus.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\">\nfocus(来源见水印)\n</p>\n<p>yolov5中，Focus模块位于backbone前。具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张近似下采样的图片，但是没有信息丢失。相当于w,h变为1/2，输入通道扩充了4倍，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。</p>\n<p>以yolov5s为例，原始的640 × 640 × 3的图像输入Focus结构，采用切片操作，先变成320 × 320 × 12的特征图，再经过一次卷积操作，最终变成320 × 320 × 32的特征图。</p>\n<p><strong>具体代码实现：</strong></p>\n<p><img src=\"/images/yolo_v5/focus_code.jpg\" width=\"75%\" height=\"75%\"></p>\n<p><strong>目的和作用：</strong> Focus是为了提速，和mAP无关，减少了计算量和参数量。</p>\n<p>The YOLOv5 Focus layer replaces the first 3 YOLOv3 layers with a single layer:</p>\n<p><img src=\"/images/yolo_v5/focus_2.jpg\" width=\"75%\" height=\"75%\"></p>\n<p>详见<a href=\"https://github.com/ultralytics/yolov5/discussions/3181\">作者解答</a></p>\n<h5 id=\"csp结构\">CSP结构</h5>\n<p>Yolov5与Yolov4不同点在于，Yolov4中只有主干网络使用了CSP结构。</p>\n<p>而Yolov5中设计了两种CSP结构，以Yolov5s网络为例，CSP1_X结构应用于Backbone主干网络，另一种CSP2_X结构则应用于Neck中。</p>\n<p><img src=\"/images/yolo_v5/csp.jpg\" width=\"75%\" height=\"75%\"></p>\n<h4 id=\"neck\">Neck</h4>\n<ol type=\"1\">\n<li>Yolov5现在的Neck和Yolov4中一样，都采用FPN+PAN的结构.</li>\n<li>如CSP结构中讲到，Yolov5和Yolov4的不同点在于，Yolov4的Neck结构中，采用的都是普通的卷积操作。而Yolov5的Neck结构中，采用借鉴CSPnet设计的CSP2结构，加强网络特征融合的能力。</li>\n</ol>\n<p><img src=\"/images/yolo_v5/neck.jpg\" width=\"75%\" height=\"75%\"></p>\n<h4 id=\"prediction\">Prediction</h4>\n<h5 id=\"bounding-box损失函数\">Bounding box损失函数</h5>\n<p>Yolov5: GIOU_Loss Yolov4: CIOU_Loss</p>\n<h5 id=\"nms非极大值抑制\">nms非极大值抑制</h5>\n<p>Yolov4: DIOU_nms Yolov5: 加权nms</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Weighted NMS出现于ICME Workshop 2017《Inception Single Shot MultiBox Detector for object detection》一文中。论文认为Traditional NMS每次迭代所选出的最大得分框未必是精确定位的，冗余框也有可能是定位良好的。那么与直接剔除机制不同，Weighted NMS顾名思义是对坐标加权平均，加权平均的对象包括M自身以及IoU≥NMS阈值的相邻框。 <img src=\"/images/yolo_v5/weight_nms.jpg\" width=\"30%\" height=\"30%\"> 加权的权重为 : <img src=\"/images/yolo_v5/weight_nms_2.jpg\" width=\"20%\" height=\"20%\">  ，表示得分与IoU的乘积。 <strong>优点</strong>： Weighted NMS通常能够获得更高的Precision和Recall，只要NMS阈值选取得当，Weighted NMS均能稳定提高AP与AR，无论是AP50还是AP75，也不论所使用的检测模型是什么。 <strong>缺点</strong>： 顺序处理模式，且运算效率比Traditional NMS更低。加权因子是IoU与得分，前者只考虑两个框的重叠面积，这对描述box重叠关系或许不够全面；而后者受到定位与得分不一致问题的限制。</p></blockquote>\n","feature":true,"text":"YOLO-V5学习笔记 知识点来源于网络，仅记录学习 来源：https://zhuanlan.zhihu.com/p/172121380 网络结构 Yolov5s网络结构(来源见水印) 如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、N...","link":"","photos":[],"count_time":{"symbolsCount":"2.1k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":4,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#yolo-v5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">YOLO-V5学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">网络结构</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%BE%93%E5%85%A5%E7%AB%AF\"><span class=\"toc-text\">输入端</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#mosaic%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">Mosaic数据增强</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E9%94%9A%E6%A1%86%E8%AE%A1%E7%AE%97\"><span class=\"toc-text\">自适应锚框计算</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE\"><span class=\"toc-text\">自适应图片缩放</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#backbone\"><span class=\"toc-text\">Backbone</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#focus%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">Focus结构</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#csp%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">CSP结构</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#neck\"><span class=\"toc-text\">Neck</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#prediction\"><span class=\"toc-text\">Prediction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#bounding-box%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">Bounding box损失函数</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#nms%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6\"><span class=\"toc-text\">nms非极大值抑制</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Faster RCNN 记录","uid":"06a101cf6ba6fad0463c3458164de1c3","slug":"Faster-RCNN-记录","date":"2021-10-11T07:47:29.000Z","updated":"2021-10-12T07:13:57.713Z","comments":true,"path":"api/articles/Faster-RCNN-记录.json","keywords":null,"cover":[],"text":" 参考来源： https://zhuanlan.zhihu.com/p/31426458 https://zhuanlan.zhihu.com/p/86403390 Faster RCNN基本结构 Faster RCNN其实可以分为4个主要内容： 特征提取：Faster RCNN...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":4,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"Pixel-Level Domain Transfer论文复现","uid":"f45a749a54e27d0a1f22b1f23eadc80a","slug":"Pixel-Level-Domain-Transfer论文复现","date":"2021-09-06T11:51:46.000Z","updated":"2021-09-06T15:35:42.197Z","comments":true,"path":"api/articles/Pixel-Level-Domain-Transfer论文复现.json","keywords":null,"cover":[],"text":"Pixel-Level Domain Transfer论文复现 博客迁移，原文链接 Abstract.：We present an image-conditional image generation model. The model transfers an input dom...","link":"","photos":[],"count_time":{"symbolsCount":"6.9k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"csdn迁移","slug":"csdn迁移","count":1,"path":"api/tags/csdn迁移.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"feature":true}}