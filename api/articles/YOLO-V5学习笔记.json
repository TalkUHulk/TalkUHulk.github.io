{"title":"YOLO-V5学习笔记","uid":"57d3aa7cdcc56700d35ee7aa4e8c6558","slug":"YOLO-V5学习笔记","date":"2021-09-09T07:42:37.000Z","updated":"2021-09-09T09:25:30.928Z","comments":true,"path":"api/articles/YOLO-V5学习笔记.json","keywords":null,"cover":[],"content":"<h3 id=\"YOLO-V5学习笔记\"><a href=\"#YOLO-V5学习笔记\" class=\"headerlink\" title=\"YOLO-V5学习笔记\"></a>YOLO-V5学习笔记</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>知识点来源于网络，仅记录学习<br>来源：<a href=\"https://zhuanlan.zhihu.com/p/172121380\">https://zhuanlan.zhihu.com/p/172121380</a></p></blockquote>\n<h4 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h4><img src=\"/images/yolo_v5/arch.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\"> Yolov5s网络结构(来源见水印)</p>\n\n\n<p>如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、Neck以及Prediction四部分来理解。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Yolov5官方代码中，一共有4个版本，分别是Yolov5s、Yolov5m、Yolov5l、Yolov5x四个模型。Yolov5s是Yolov5系列中深度最小，特征图的宽度最小的网络。后面的3种都是在此基础上不断加深，不断加宽。</p></blockquote>\n<h4 id=\"输入端\"><a href=\"#输入端\" class=\"headerlink\" title=\"输入端\"></a>输入端</h4><h5 id=\"Mosaic数据增强\"><a href=\"#Mosaic数据增强\" class=\"headerlink\" title=\"Mosaic数据增强\"></a>Mosaic数据增强</h5><p>与v4一样，采用Mosaic数据增强；</p>\n<h5 id=\"自适应锚框计算\"><a href=\"#自适应锚框计算\" class=\"headerlink\" title=\"自适应锚框计算\"></a>自适应锚框计算</h5><p>将anchor初始计算(聚类)集成到训练代码中；</p>\n<h5 id=\"自适应图片缩放\"><a href=\"#自适应图片缩放\" class=\"headerlink\" title=\"自适应图片缩放\"></a>自适应图片缩放</h5><p><u><strong>针对inference阶段的优化</strong></u></p>\n<p>在常用的目标检测算法中，不同的图片长宽都不相同，因此常用的方式是将原始图片统一缩放到一个标准尺寸，再送入检测网络中。</p>\n<img src=\"/images/yolo_v5/auto_pad_1.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\"> 传统方法(来源见水印)</p>\n\n<p>但Yolov5代码中对此进行了改进，也是Yolov5推理速度能够很快的一个不错的trick。</p>\n<p>作者认为，在项目实际使用时，很多图片的长宽比不同，因此缩放填充后，两端的黑边大小都不同，而如果填充的比较多，则存在信息冗余，影响推理速度。</p>\n<p>因此在Yolov5的代码中datasets.py的letterbox函数中进行了修改，对原始图像自适应的添加最少的黑边。</p>\n<img src=\"/images/yolo_v5/auto_pad_2.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\"> yolov5(来源见水印)</p>\n\n<p>举例说明填充方法：<br>原始：800x600<br>目标：416</p>\n<ol>\n<li>选择小的缩放系数，短边:min(416/800, 416/600);</li>\n<li>得到新的尺寸(即长边resize到目标尺寸,短边按原始长宽比变换）: (416,312);</li>\n<li>计算pad大小(找到大于312且能被32整除的最小整数):<br> (416 - 312) mod 32 = 8<br> 所以pad值为8/2=4</li>\n</ol>\n<h4 id=\"Backbone\"><a href=\"#Backbone\" class=\"headerlink\" title=\"Backbone\"></a>Backbone</h4><h5 id=\"Focus结构\"><a href=\"#Focus结构\" class=\"headerlink\" title=\"Focus结构\"></a>Focus结构</h5><img src=\"/images/yolo_v5/focus.jpg\" width=\"75%\" height=\"75%\">\n<p align=\"center\"> focus(来源见水印)</p>\n\n<p>yolov5中，Focus模块位于backbone前。具体操作是在一张图片中每隔一个像素拿到一个值，类似于邻近下采样，这样就拿到了四张近似下采样的图片，但是没有信息丢失。相当于w,h变为1/2，输入通道扩充了4倍，最后将得到的新图片再经过卷积操作，最终得到了没有信息丢失情况下的二倍下采样特征图。</p>\n<p>以yolov5s为例，原始的640 × 640 × 3的图像输入Focus结构，采用切片操作，先变成320 × 320 × 12的特征图，再经过一次卷积操作，最终变成320 × 320 × 32的特征图。</p>\n<p><strong>具体代码实现：</strong><br><code>class Focus(nn.Module):     def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):            super(Focus, self).__init__()         self.conv = Conv(c1 * 4, c2, k, s, p, g, act)      def forward(self, x):           return self.conv(torch.cat([x[..., ::2, ::2], x[..., 1::2, ::2], x[..., ::2, 1::2], x[..., 1::2, 1::2]], 1))</code><br><strong>目的和作用：</strong> Focus是为了提速，和mAP无关，减少了计算量和参数量。</p>\n<p>The YOLOv5 Focus layer replaces the first 3 YOLOv3 layers with a single layer:</p>\n<img src=\"/images/yolo_v5/focus_2.jpg\" width=\"75%\" height=\"75%\">\n\n<p>详见<a href=\"https://github.com/ultralytics/yolov5/discussions/3181\">作者解答</a></p>\n<h5 id=\"CSP结构\"><a href=\"#CSP结构\" class=\"headerlink\" title=\"CSP结构\"></a>CSP结构</h5><p>Yolov5与Yolov4不同点在于，Yolov4中只有主干网络使用了CSP结构。</p>\n<p>而Yolov5中设计了两种CSP结构，以Yolov5s网络为例，CSP1_X结构应用于Backbone主干网络，另一种CSP2_X结构则应用于Neck中。</p>\n<img src=\"/images/yolo_v5/csp.jpg\" width=\"75%\" height=\"75%\">\n\n<h4 id=\"Neck\"><a href=\"#Neck\" class=\"headerlink\" title=\"Neck\"></a>Neck</h4><ol>\n<li>Yolov5现在的Neck和Yolov4中一样，都采用FPN+PAN的结构.</li>\n<li>如CSP结构中讲到，Yolov5和Yolov4的不同点在于，Yolov4的Neck结构中，采用的都是普通的卷积操作。而Yolov5的Neck结构中，采用借鉴CSPnet设计的CSP2结构，加强网络特征融合的能力。</li>\n</ol>\n<img src=\"/images/yolo_v5/neck.jpg\" width=\"75%\" height=\"75%\">\n\n<h4 id=\"Prediction\"><a href=\"#Prediction\" class=\"headerlink\" title=\"Prediction\"></a>Prediction</h4><h5 id=\"Bounding-box损失函数\"><a href=\"#Bounding-box损失函数\" class=\"headerlink\" title=\"Bounding box损失函数\"></a>Bounding box损失函数</h5><p>Yolov5: GIOU_Loss<br>Yolov4: CIOU_Loss</p>\n<h5 id=\"nms非极大值抑制\"><a href=\"#nms非极大值抑制\" class=\"headerlink\" title=\"nms非极大值抑制\"></a>nms非极大值抑制</h5><p>Yolov4: DIOU_nms<br>Yolov5: 加权nms</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Weighted NMS出现于ICME Workshop 2017《Inception Single Shot MultiBox Detector for object detection》一文中。论文认为Traditional NMS每次迭代所选出的最大得分框未必是精确定位的，冗余框也有可能是定位良好的。那么与直接剔除机制不同，Weighted NMS顾名思义是对坐标加权平均，加权平均的对象包括M自身以及IoU≥NMS阈值的相邻框。<br><img src=\"evernotecid://B26882A6-9AE9-467C-A70F-24D1465FC8A1/appyinxiangcom/4753150/ENNote/p631?hash=f432aa2121625fcd3199ee9d118e7b64\" alt=\"f432aa2121625fcd3199ee9d118e7b64.svg\"><br>加权的权重为 <img src=\"evernotecid://B26882A6-9AE9-467C-A70F-24D1465FC8A1/appyinxiangcom/4753150/ENNote/p631?hash=59972de58e6d2f41ef789e1d1d5f6dcd\" alt=\"59972de58e6d2f41ef789e1d1d5f6dcd.svg\"><br> ，表示得分与IoU的乘积。<br><strong>优点</strong>：<br>Weighted NMS通常能够获得更高的Precision和Recall，只要NMS阈值选取得当，Weighted NMS均能稳定提高AP与AR，无论是AP50还是AP75，也不论所使用的检测模型是什么。<br><strong>缺点</strong>：<br>顺序处理模式，且运算效率比Traditional NMS更低。加权因子是IoU与得分，前者只考虑两个框的重叠面积，这对描述box重叠关系或许不够全面；而后者受到定位与得分不一致问题的限制。</p></blockquote>\n","feature":true,"text":"YOLO-V5学习笔记 知识点来源于网络，仅记录学习来源：https://zhuanlan.zhihu.com/p/172121380 网络结构 Yolov5s网络结构(来源见水印) 如上图为yolov5的整体网络结构，跟yolov4一样，分别按input、backbone、Ne...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":3,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#YOLO-V5%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">YOLO-V5学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">网络结构</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%BE%93%E5%85%A5%E7%AB%AF\"><span class=\"toc-text\">输入端</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Mosaic%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">Mosaic数据增强</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E9%94%9A%E6%A1%86%E8%AE%A1%E7%AE%97\"><span class=\"toc-text\">自适应锚框计算</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%87%AA%E9%80%82%E5%BA%94%E5%9B%BE%E7%89%87%E7%BC%A9%E6%94%BE\"><span class=\"toc-text\">自适应图片缩放</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Backbone\"><span class=\"toc-text\">Backbone</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Focus%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">Focus结构</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#CSP%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">CSP结构</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Neck\"><span class=\"toc-text\">Neck</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Prediction\"><span class=\"toc-text\">Prediction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Bounding-box%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">Bounding box损失函数</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#nms%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6\"><span class=\"toc-text\">nms非极大值抑制</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{},"next_post":{"title":"Pixel-Level Domain Transfer论文复现","uid":"f45a749a54e27d0a1f22b1f23eadc80a","slug":"Pixel-Level-Domain-Transfer论文复现","date":"2021-09-06T11:51:46.000Z","updated":"2021-09-06T15:35:42.197Z","comments":true,"path":"api/articles/Pixel-Level-Domain-Transfer论文复现.json","keywords":null,"cover":[],"text":"Pixel-Level Domain Transfer论文复现博客迁移，原文链接 Abstract.：We present an image-conditional image generation model. The model transfers an input doma...","link":"","photos":[],"count_time":{"symbolsCount":"6.9k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"csdn迁移","slug":"csdn迁移","count":1,"path":"api/tags/csdn迁移.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"feature":true}}