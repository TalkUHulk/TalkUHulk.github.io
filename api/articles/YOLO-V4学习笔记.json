{"title":"YOLO-V4学习笔记","uid":"260edd383abab8c5258536a42ddb3e2a","slug":"YOLO-V4学习笔记","date":"2021-09-06T10:10:36.000Z","updated":"2021-09-07T06:39:04.426Z","comments":true,"path":"api/articles/YOLO-V4学习笔记.json","keywords":null,"cover":[],"content":"<h3 id=\"YOLO-V4学习笔记\"><a href=\"#YOLO-V4学习笔记\" class=\"headerlink\" title=\"YOLO-V4学习笔记\"></a>YOLO-V4学习笔记</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>知识点来源于网络，仅记录学习<br>来源：<a href=\"https://zhuanlan.zhihu.com/p/143747206\">https://zhuanlan.zhihu.com/p/143747206</a></p></blockquote>\n<h4 id=\"网络结构\"><a href=\"#网络结构\" class=\"headerlink\" title=\"网络结构\"></a>网络结构</h4><img src=\"/images/yolo_v4/arch.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n<p align=\"center\"> 网络结构(来源见水印)</p>\n\n<p>五个基本组件:</p>\n<ol>\n<li>CBM：Yolov4网络结构中的最小组件，由Conv+Bn+Mish激活函数三者组成。</li>\n<li>CBL：由Conv+Bn+Leaky_relu激活函数三者组成。</li>\n<li>Res unit：借鉴Resnet网络中的残差结构，让网络可以构建的更深。</li>\n<li>CSPX：借鉴CSPNet网络结构，由卷积层和X个Res unint模块Concate组成。</li>\n<li>SPP：采用1×1，5×5，9×9，13×13的最大池化的方式，进行多尺度融合。</li>\n</ol>\n<img src=\"/images/yolo_v4/obj_detect.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n<p align=\"center\">  Object detector</p>\n\n<p>如上图，大致分为四个阶段理解yolov4，分别为输入端、backbone、Neck以及Prediction。</p>\n<h4 id=\"输入端\"><a href=\"#输入端\" class=\"headerlink\" title=\"输入端\"></a>输入端</h4><h5 id=\"Mosaic数据增强\"><a href=\"#Mosaic数据增强\" class=\"headerlink\" title=\"Mosaic数据增强\"></a>Mosaic数据增强</h5><p>Yolov4中使用的Mosaic是参考2019年底提出的CutMix数据增强的方式，但CutMix只使用了两张图片进行拼接，而<u><strong>Mosaic数据增强则采用了4张图片，随机缩放、随机裁剪、随机排布的方式进行拼接</strong></u>。</p>\n<img src=\"/images/yolo_v4/mosaic.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n\n<h6 id=\"为什么要进行Mosaic数据增强\"><a href=\"#为什么要进行Mosaic数据增强\" class=\"headerlink\" title=\"为什么要进行Mosaic数据增强?\"></a>为什么要进行Mosaic数据增强?</h6><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在平时项目训练时，小目标的AP一般比中目标和大目标低很多。而Coco数据集中也包含大量的小目标，但比较麻烦的是小目标的分布并不均匀。</p>\n<p>首先看下小、中、大目标的定义：<br>2019年发布的论文《Augmentation for small object detection》对此进行了区分:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>最小矩形区域面积</th>\n<th>最大矩形区域面积</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>小目标</td>\n<td>0 * 0</td>\n<td>32 * 32</td>\n</tr>\n<tr>\n<td>中目标</td>\n<td>32 * 32</td>\n<td>96 * 96</td>\n</tr>\n<tr>\n<td>大目标</td>\n<td>96 * 96</td>\n<td>∞ * ∞</td>\n</tr>\n</tbody></table></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>可以看到小目标的定义是目标框的长宽0×0~32×32之间的物体。</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>小</th>\n<th>中</th>\n<th>大</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>数据集中小目标占比</td>\n<td>41.4%</td>\n<td>34.3%</td>\n<td>24.3%</td>\n</tr>\n<tr>\n<td>数据集图片包含占比</td>\n<td>52.3%</td>\n<td>70.7%</td>\n<td>83.0%</td>\n</tr>\n<tr>\n<td>但在整体的数据集中，小、中、大目标的占比并不均衡。</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>如上表所示，Coco数据集中小目标占比达到41.4%，数量比中目标和大目标都要多。</td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p>但在所有的训练集图片中，只有52.3%的图片有小目标，而中目标和大目标的分布相对来说更加均匀一些。</p>\n<p>针对这种状况，Yolov4的作者采用了Mosaic数据增强的方式。</p>\n<p>主要有几个优点：</p>\n<ol>\n<li>丰富数据集：随机使用4张图片，随机缩放，再随机分布进行拼接，丰富了图片的背景，大大丰富了检测数据集，特别是随机缩放增加了很多小目标，让网络的鲁棒性更好。</li>\n<li>减少GPU：四张图片拼接在一起变相地提高了batch_size，在进行batch normalization的时候也会计算四张图片，所以对本身batch_size不是很依赖，单块GPU就可以训练YOLOV4。</li>\n</ol></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><u><strong>最后说明一下对于标签框的处理，当进行裁剪的时候，如果裁剪了样本当中的标签框的部分区域，则将其舍弃，保留裁剪之后还完整的标签框</strong></u>。</p></blockquote>\n<p><a href=\"https://www.zhihu.com/question/390191723?rf=390194081\">参考</a></p>\n<h5 id=\"与其他增强方法对比\"><a href=\"#与其他增强方法对比\" class=\"headerlink\" title=\"与其他增强方法对比\"></a>与其他增强方法对比</h5><ul>\n<li><p><strong>Mixup</strong>:将随机的两张样本按比例混合，分类的结果按比例分配；</p>\n</li>\n<li><p><strong>Cutout</strong>:随机的将样本中的部分区域cut掉，并且填充0像素值，分类的结果不变；</p>\n</li>\n<li><p><strong>CutMix</strong>:就是将一部分区域cut掉但不填充0像素而是随机填充训练集中的其他数据的区域像素值，分类结果按一定的比例分配</p>\n</li>\n</ul>\n<img src=\"/images/yolo_v4/compare.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n\n<p>上述三种数据增强的区别：</p>\n<ol>\n<li>cutout和cutmix就是填充区域像素值的区别;</li>\n<li>mixup和cutmix是混合两种样本方式上的区别;</li>\n<li>mixup是将两张图按比例进行插值来混合样本，cutmix是采用cut部分区域再补丁的形式去混合图像，不会有图像混合后不自然的情形。</li>\n</ol>\n<p><a href=\"https://zhuanlan.zhihu.com/p/405639109\">参考</a></p>\n<h4 id=\"BackBone\"><a href=\"#BackBone\" class=\"headerlink\" title=\"BackBone\"></a>BackBone</h4><h5 id=\"CSPDarknet53\"><a href=\"#CSPDarknet53\" class=\"headerlink\" title=\"CSPDarknet53\"></a>CSPDarknet53</h5><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>CSPDarknet53是在Yolov3主干网络Darknet53的基础上，借鉴2019年CSPNet的经验，产生的Backbone结构。因为Backbone有5个CSP模块（见网络结构），输入图像是608 * 608，所以特征图变化的规律是：608-&gt;304-&gt;152-&gt;76-&gt;38-&gt;19。经过5次CSP模块后得到19*19大小的特征图。<br>而且作者只在Backbone中采用了Mish激活函数，网络后面仍然采用Leaky_relu激活函数。</p></blockquote>\n<h5 id=\"CSPNet\"><a href=\"#CSPNet\" class=\"headerlink\" title=\"CSPNet\"></a>CSPNet</h5><p><a href=\"https://arxiv.org/pdf/1911.11929.pdf\">论文地址</a></p>\n<p>  CSPNet全称是Cross Stage Paritial Network，主要从网络结构设计的角度解决推理中从计算量很大的问题。</p>\n<p>  设计CSPNet的主要目的是<strong>使该体系结构能够实现更丰富的梯度组合信息，同时减少计算量</strong>。 通过<u><strong>将基础层的特征图划分为两个部分</strong></u>，然后通过提出的<u><strong>跨阶段层次结构将它们合并</strong></u>，可以实现此目标。 </p>\n<p>  CSPNet的作者认为推理计算过高的问题是由于网络优化中的梯度信息重复导致的。</p>\n<p>  因此采用CSP模块先将基础层的特征映射划分为两部分，然后通过跨阶段层次结构将它们合并，在减少了计算量的同时可以保证准确率。</p>\n<p>  因此Yolov4在主干网络Backbone采用CSPDarknet53网络结构，主要有三个方面的优点：</p>\n<ol>\n<li>增强CNN的学习能力，使得在轻量化的同时保持准确性</li>\n<li>降低计算瓶颈</li>\n<li>降低内存成本</li>\n</ol>\n<h6 id=\"论文方法\"><a href=\"#论文方法\" class=\"headerlink\" title=\"论文方法\"></a>论文方法</h6><img src=\"/images/yolo_v4/densenet_and_cspnet.jpg\" width=\"125%\" height=\"125%\" align=\"center\">\n\n<p>如上图(a), DenseNet的每个阶段均包含一个dense block(密集连接层)和transition layer(过渡层)，同时，每个dense block由K个密集层连接。第$i^{th}$个密集层的输出将会同第$i^{th}$个密集层的输入相连接，同时拼接后的输出结果作为${i+1}^{th}$个密集层的输入，等式表示如下所示：</p>\n<img src=\"/images/yolo_v4/densenet_equations.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n\n<p>如果使用反向传播算法更新权重，则权重更新方程可写为：</p>\n<img src=\"/images/yolo_v4/densenet_updating.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n\n<p>其中f是权重更新的函数，$g_i$表示传播到第$i^{th}$个密集层的梯度。<br>作者发现<u><strong>大量重复的梯度信息被用来更新不同密集层的权重。 这将导致不同的密集层重复学习复制的梯度信息。</strong></u></p>\n<p>如上图(b),改进点在于CSPNet将浅层特征映射为两个部分，一部分经过Dense模块（图中的Partial Dense Block）,另一部分直接与Partial Dense Block输出进行concate。CSPDenseNet的前馈传递和权重更新的方程式分别显示如下：</p>\n<img src=\"/images/yolo_v4/cspnet_equations.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n\n\n<img src=\"/images/yolo_v4/cspnet_updating.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n\n<p>总体而言，<u><strong>CSPDenseNet保留了DenseNet的特征重用特性的优点，但同时通过截断梯度流，防止了过多的梯度信息重复。 通过设计分层特征融合策略来实现此思想，并将其用于部分过渡层。</strong></u></p>\n<p>作者也设计了几种特征融合的策略，如下图所示：<br><img src=\"/images/yolo_v4/fusion_strategies.jpg\" width=\"75%\" height=\"75%\" align=\"center\"></p>\n<p>Fustion First的方式是对两个分支的feature map先进行concatenation操作，这样梯度信息可以被重用。<br>Fusion Last的方式是对Dense Block所在分支先进性transition操作，然后再进行concatenation， 梯度信息将被截断，因此不会重复使用梯度信息 。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>所以CSP-DarkNet到底是怎么借鉴CSPNet的？<br>如果按照CSPNet的思想，那特征输入应该按一定比例分为两路，分别经过Part1和Part2后concat，比如下图这样：</p></blockquote>\n<img src=\"/images/yolo_v4/cspdarknet_flow_1.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n<p align=\"center\"> 来源见水印</p>\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>但实际CSP-DarkNet没有做split操作，Part1和Part2输入的是全部特征，如下图：</p></blockquote>\n<img src=\"/images/yolo_v4/cspdarknet_flow_2.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n<p align=\"center\"> 来源见水印</p>\n\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>直接用两路的1x1卷积将输入特征进行变换。 可以理解的是，将全部的输入特征利用两路1x1进行transition，<strong>比直接划分通道能够进一步提高特征的重用性，并且在输入到resiudal block之前也确实通道减半，减少了计算量</strong>。</p></blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/263555912\">参考来源</a></p>\n<h5 id=\"Mish激活函数\"><a href=\"#Mish激活函数\" class=\"headerlink\" title=\"Mish激活函数\"></a>Mish激活函数</h5><p><a href=\"https://arxiv.org/pdf/1908.08681.pdf\">论文地址</a></p>\n<img src=\"/images/yolo_v4/mish.jpg\" width=\"50%\" height=\"50%\" align=\"center\">\n<p align=\"center\"> Mish曲线</p>\n\n<p><code>y = x * tanh(ln(1+exp(x)))</code></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> 一种自正则的非单调神经激活函数，平滑的激活函数允许更好的信息深入神经网络，从而得到更好的准确性和泛化。论文中提出，相比Swish有0.494%的提升，相比ReLU有1.671%的提升。</p></blockquote>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> Yolov4的Backbone中都使用了Mish激活函数，而后面的网络则还是使用leaky_relu函数。</p></blockquote>\n<p>优点：</p>\n<ol>\n<li>以上无边界(即正值可以达到任何高度)避免了由于封顶而导致的饱和。2. 理论上对负值的轻微允许可以产生更好的梯度流，而不是像ReLU中那样的硬零边界。</li>\n<li><strong>平滑的激活函数允许更好的信息深入神经网络，从而得到更好的准确性和泛化</strong>。</li>\n</ol>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">更平滑的激活函数允许信息更深入地流动<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<p>缺点：</p>\n<ol>\n<li>计算量肯定比relu大，占用的内存也多了不少；</li>\n</ol>\n<h6 id=\"pytorch实现\"><a href=\"#pytorch实现\" class=\"headerlink\" title=\"pytorch实现\"></a>pytorch实现</h6><img src=\"/images/yolo_v4/mish_pytorch.jpg\" width=\"50%\" height=\"50%\" >\n\n\n<h5 id=\"Dropblock\"><a href=\"#Dropblock\" class=\"headerlink\" title=\"Dropblock\"></a>Dropblock</h5><p><a href=\"https://arxiv.org/pdf/1810.12890.pdf\">论文地址</a></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Yolov4中使用的Dropblock，其实和常见网络中的Dropout功能类似，也是缓解过拟合的一种正则化方式。</p></blockquote>\n<p>dropout方法多是作用在全连接层上，在卷积层应用dropout方法意义不大。文章认为是因为每个feature map的位置都有一个感受野范围，仅仅对单个像素位置进行dropout并不能降低feature map学习的特征范围，也就是说网络仍可以通过该位置的相邻位置元素去学习对应的语义信息，也就不会促使网络去学习更加鲁棒的特征。<br>    既然单独的对每个位置进行dropout并不能提高网络的泛化能力，那么很自然的，如果我们按照一块一块的去dropout，就自然可以促使网络去学习更加鲁棒的特征。思路很简单，就是在feature map上去一块一块的找，进行归零操作，类似于dropout，叫做dropblock。</p>\n<img src=\"/images/yolo_v4/dropblock.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n<p align=\"center\"> 绿色阴影区域是语义特征，b图是模拟dropout的做法，随机丢弃一些位置的特征,(c)是dropblock</p>\n\n<img src=\"/images/yolo_v4/dropblock_algorithm.jpg\" width=\"75%\" height=\"75%\">\n\n<p>dropblock有三个比较重要的参数，一个是block_size，用来控制进行归零的block大小；一个是γ，用来控制每个卷积结果中，到底有多少个channel要进行dropblock；最后一个是keep_prob，作用和dropout里的参数一样。</p>\n<p>M大小和输出特征图大小一致，非0即1，为了保证训练和测试一致，需要和dropout一样，进行rescale。</p>\n<p>上述是理论分析，在做实验时候发现，<strong>block_size控制为7*7效果最好</strong>，对于所有的feature map都一样，γ通过一个公式来控制，keep_prob则是一个线性衰减过程，从最初的1到设定的阈值(具体实现是dropout率从0增加到指定值为止)，论文通过实验表明这种方法效果最好。如果固定prob效果好像不好。<br>实践中，并没有显式的设置γ的值，而是根据keep_prob(具体实现是反的，是丢弃概率)来调整。</p>\n<h4 id=\"Neck\"><a href=\"#Neck\" class=\"headerlink\" title=\"Neck\"></a>Neck</h4><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在目标检测领域，为了更好的提取融合特征，通常在Backbone和输出层，会插入一些层，这个部分称为Neck。相当于目标检测网络的颈部，也是非常关键的。</p>\n<p>Yolov4的Neck结构主要采用了SPP模块、FPN+PAN的方式。</p></blockquote>\n<h5 id=\"SPP模块\"><a href=\"#SPP模块\" class=\"headerlink\" title=\"SPP模块\"></a>SPP模块</h5><img src=\"/images/yolo_v4/spp.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n\n<p>作者在SPP模块中，使用k={1 * 1,5 * 5,9 * 9,13 * 13}的最大池化的方式，再将不同尺度的特征图进行Concat操作。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>采用SPP模块的方式，比单纯的使用k<em>k最大池化的方式，*<em>更有效的增加主干特征的接收范围，显著的分离了最重要的上下文特征</em></em></p></blockquote>\n<h5 id=\"FPN-PAN\"><a href=\"#FPN-PAN\" class=\"headerlink\" title=\"FPN+PAN\"></a>FPN+PAN</h5><p><a href=\"https://arxiv.org/pdf/1803.01534.pdf\">论文地址</a></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Path Aggregation Network(PANet)，旨在提升基于侯选区域的实例分割框架内的信息流传播。具体来讲，通过自下向上(bottom-up)的路径增强在较低层(lower layer)中准确的定位信息流，建立底层特征和高层特征之间的信息路径，从而增强整个特征层次架构。</p></blockquote>\n<p>yolo-v3中使用FPN具体如下：</p>\n<img src=\"/images/yolo_v4/yolo_v3_fpn.jpg\" width=\"50%\" height=\"50%\" align=\"center\">\n<p align=\"center\">  来源见水印</p>\n\n\n<p>FPN是自顶向下的，将高层的特征信息通过上采样的方式进行传递融合，得到进行预测的特征图。</p>\n<p>在yolo_v4中，在FPN的基础上增加PAN，具体结构如下：</p>\n<img src=\"/images/yolo_v4/pan_1.jpg\" width=\"100%\" height=\"100%\" align=\"center\">\n<p align=\"center\">  来源见水印</p>\n\n<p>如上图，紫色箭头处分别是三个中间feature map，分辨率为76 * 76、38 * 38、19 * 19</p>\n<img src=\"/images/yolo_v4/pan_2.jpg\" width=\"50%\" height=\"50%\" align=\"center\">\n<p align=\"center\"> 来源见水印</p>\n\n\n<p>这样结合操作，FPN层自顶向下传达强语义特征，而特征金字塔则自底向上传达强定位特征，两两联手，从不同的主干层对不同的检测层进行参数聚合。</p>\n<img src=\"/images/yolo_v4/pan_3.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n<p align=\"center\">  yolo_v4中使用的是修改的PAN</p>\n\n\n<h4 id=\"Prediction\"><a href=\"#Prediction\" class=\"headerlink\" title=\"Prediction\"></a>Prediction</h4><p>目标检测任务的损失函数一般由Classificition Loss（分类损失函数）和Bounding Box Regeression Loss（回归损失函数）两部分构成。</p>\n<p>Bounding Box Regeression的Loss近些年的发展过程是：Smooth L1 Loss-&gt; IoU Loss（2016）-&gt; GIoU Loss（2019）-&gt; DIoU Loss（2020）-&gt;CIoU Loss（2020）</p>\n<p>我们从最常用的IOU_Loss开始，进行对比拆解分析，看下Yolov4为啥要选择CIOU_Loss。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong><u>记住一点：好的目标框回归函数应该考虑三个重要几何因素：重叠面积、中心点距离，长宽比。</u></strong></p></blockquote>\n<h6 id=\"IOU-Loss\"><a href=\"#IOU-Loss\" class=\"headerlink\" title=\"IOU_Loss\"></a>IOU_Loss</h6><img src=\"/images/yolo_v4/iou_1.jpg\" width=\"75%\" height=\"75%\">\n\n<p>IOU的loss其实很简单，主要是交集/并集，但其实也存在两个问题。</p>\n<img src=\"/images/yolo_v4/iou_2.jpg\" width=\"75%\" height=\"75%\">\n\n<ol>\n<li><p>即状态1的情况，当预测框和目标框不相交时，IOU=0，无法反应两个框距离的远近，此时损失函数不可导，IOU_Loss无法优化两个框不相交的情况。</p>\n</li>\n<li><p>即状态2和状态3的情况，当两个预测框大小相同，两个IOU也相同，IOU_Loss无法区分两者相交情况的不同。</p>\n</li>\n</ol>\n<p>因此2019年出现了GIOU_Loss来进行改进。</p>\n<h6 id=\"GIOU-Loss\"><a href=\"#GIOU-Loss\" class=\"headerlink\" title=\"GIOU_Loss\"></a>GIOU_Loss</h6><img src=\"/images/yolo_v4/giou_1.jpg\" width=\"75%\" height=\"75%\">\n\n<p>可以看到上图GIOU_Loss中，增加了相交尺度的衡量方式，缓解了单纯IOU_Loss时的尴尬。<br>但还有一种不足，如下：</p>\n<img src=\"/images/yolo_v4/giou_2.jpg\" width=\"75%\" height=\"75%\">\n\n<p>问题：状态1、2、3都是预测框在目标框内部且预测框大小一致的情况，这时预测框和目标框的差集都是相同的，因此这三种状态的GIOU值也都是相同的，这时GIOU退化成了IOU，无法区分相对位置关系。<br>基于这个问题，2020年的AAAI又提出了DIOU_Loss。</p>\n<h6 id=\"DIOU-Loss\"><a href=\"#DIOU-Loss\" class=\"headerlink\" title=\"DIOU_Loss\"></a>DIOU_Loss</h6><p>好的目标框回归函数应该考虑三个重要几何因素：重叠面积、中心点距离，长宽比。</p>\n<p>针对IOU和GIOU存在的问题，作者从两个方面进行考虑</p>\n<p>一：如何最小化预测框和目标框之间的归一化距离？<br>二：如何在预测框和目标框重叠时，回归的更准确？</p>\n<p>针对第一个问题，提出了DIOU_Loss（Distance_IOU_Loss）</p>\n<img src=\"/images/yolo_v4/diou_1.jpg\" width=\"75%\" height=\"75%\">\n\n<p>DIOU_Loss考虑了重叠面积和中心点距离，当目标框包裹预测框的时候，直接度量2个框的距离，因此DIOU_Loss收敛的更快。<br>但就像前面好的目标框回归函数所说的，没有考虑到长宽比。</p>\n<img src=\"/images/yolo_v4/diou_2.jpg\" width=\"75%\" height=\"75%\">\n\n<p>比如上面三种情况，目标框包裹预测框，本来DIOU_Loss可以起作用。<br>但预测框的中心点的位置都是一样的，因此按照DIOU_Loss的计算公式，三者的值都是相同的。</p>\n<h6 id=\"CIOU-Loss\"><a href=\"#CIOU-Loss\" class=\"headerlink\" title=\"CIOU_Loss\"></a>CIOU_Loss</h6><p>CIOU_Loss和DIOU_Loss前面的公式都是一样的，不过在此基础上还增加了一个影响因子，将预测框和目标框的长宽比都考虑了进去。</p>\n<img src=\"/images/yolo_v4/ciou_1.jpg\" width=\"50%\" height=\"50%\" align=\"center\">\n\n<p>其中v是衡量长宽比一致性的参数，我们也可以定义为：</p>\n<img src=\"/images/yolo_v4/ciou_2.jpg\" width=\"30%\" height=\"30%\" align=\"center\">\n\n<p>这样CIOU_Loss就将目标框回归函数应该考虑三个重要几何因素：重叠面积、中心点距离，长宽比全都考虑进去了。</p>\n<h6 id=\"对比\"><a href=\"#对比\" class=\"headerlink\" title=\"对比\"></a>对比</h6><p>再来综合的看下各个Loss函数的不同点：</p>\n<p>IOU_Loss：主要考虑检测框和目标框重叠面积。<br>GIOU_Loss：在IOU的基础上，解决边界框不重合时的问题。<br>DIOU_Loss：在IOU和GIOU的基础上，考虑边界框中心点距离的信息。<br>CIOU_Loss：在DIOU的基础上，考虑边界框宽高比的尺度信息。</p>\n<p>Yolov4中采用了CIOU_Loss的回归方式，使得预测框回归的速度和精度更高一些。</p>\n<h5 id=\"DIOU-nms\"><a href=\"#DIOU-nms\" class=\"headerlink\" title=\"DIOU_nms\"></a>DIOU_nms</h5><p>DIoU用作 NMS 的一个因子。该方法在抑制冗余的边界框时会使用 IoU 和两个边界框的中心点之间的距离。这能<strong>使得模型能更加稳健地应对有遮挡的情况</strong>。<br>在传统NMS中，IoU指标常用于抑制冗余bbox，其中重叠区域是唯一因素，对于遮挡情况经常产生错误抑制。 DIoU-NMS将DIoU作为NMS的准则，因为<strong>在抑制准则中不仅应考虑重叠区域，而且还应考虑两个box之间的中心点距离</strong>，而DIoU就是同时考虑了重叠区域和两个box的中心距离。 </p>\n<p><u><strong>DIoU-NMS建议两个中心点较远的box可能位于不同的对象上，不应将其删除(这就是DIoU-NMS的与NMS的最大不同之处)</strong></u>。</p>\n<img src=\"/images/yolo_v4/DIOU_nms.jpg\" width=\"75%\" height=\"75%\" align=\"center\">\n\n<p>在上图重叠的摩托车检测中，中间的摩托车因为考虑边界框中心点的位置信息，也可以回归出来。</p>\n<p>因此在重叠目标的检测中，DIOU_nms的效果优于传统的nms。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>这里为什么不用CIOU_nms，而用DIOU_nms?</p>\n<p>答：因为前面讲到的CIOU_loss，是在DIOU_loss的基础上，添加的影响因子，包含groundtruth标注框的信息，在训练时用于回归。<br>但在测试过程中，并没有groundtruth的信息，不用考虑影响因子，因此直接用DIOU_nms即可。</p></blockquote>\n","feature":true,"text":"YOLO-V4学习笔记 知识点来源于网络，仅记录学习来源：https://zhuanlan.zhihu.com/p/143747206 网络结构 网络结构(来源见水印) 五个基本组件: CBM：Yolov4网络结构中的最小组件，由Conv+Bn+Mish激活函数三者组成。 CBL...","link":"","photos":[],"count_time":{"symbolsCount":"7.2k","symbolsTime":"7 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":3,"path":"api/tags/detection.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#YOLO-V4%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0\"><span class=\"toc-text\">YOLO-V4学习笔记</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">网络结构</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%BE%93%E5%85%A5%E7%AB%AF\"><span class=\"toc-text\">输入端</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Mosaic%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">Mosaic数据增强</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E8%BF%9B%E8%A1%8CMosaic%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA\"><span class=\"toc-text\">为什么要进行Mosaic数据增强?</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E4%B8%8E%E5%85%B6%E4%BB%96%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">与其他增强方法对比</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#BackBone\"><span class=\"toc-text\">BackBone</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#CSPDarknet53\"><span class=\"toc-text\">CSPDarknet53</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#CSPNet\"><span class=\"toc-text\">CSPNet</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">论文方法</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Mish%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0\"><span class=\"toc-text\">Mish激活函数</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#pytorch%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">pytorch实现</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#Dropblock\"><span class=\"toc-text\">Dropblock</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Neck\"><span class=\"toc-text\">Neck</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#SPP%E6%A8%A1%E5%9D%97\"><span class=\"toc-text\">SPP模块</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#FPN-PAN\"><span class=\"toc-text\">FPN+PAN</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Prediction\"><span class=\"toc-text\">Prediction</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#IOU-Loss\"><span class=\"toc-text\">IOU_Loss</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#GIOU-Loss\"><span class=\"toc-text\">GIOU_Loss</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#DIOU-Loss\"><span class=\"toc-text\">DIOU_Loss</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#CIOU-Loss\"><span class=\"toc-text\">CIOU_Loss</span></a></li><li class=\"toc-item toc-level-6\"><a class=\"toc-link\" href=\"#%E5%AF%B9%E6%AF%94\"><span class=\"toc-text\">对比</span></a></li></ol></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#DIOU-nms\"><span class=\"toc-text\">DIOU_nms</span></a></li></ol></li></ol></li></ol>","author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"mapped":true,"prev_post":{"title":"Pixel-Level Domain Transfer论文复现","uid":"f45a749a54e27d0a1f22b1f23eadc80a","slug":"Pixel-Level-Domain-Transfer论文复现","date":"2021-09-06T11:51:46.000Z","updated":"2021-09-06T15:35:42.197Z","comments":true,"path":"api/articles/Pixel-Level-Domain-Transfer论文复现.json","keywords":null,"cover":[],"text":"Pixel-Level Domain Transfer论文复现博客迁移，原文链接 Abstract.：We present an image-conditional image generation model. The model transfers an input doma...","link":"","photos":[],"count_time":{"symbolsCount":"6.9k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"csdn迁移","slug":"csdn迁移","count":1,"path":"api/tags/csdn迁移.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"YOLO-V3学习笔记","uid":"82f698705681b0bacc9c6cad3db6d88e","slug":"YOLO-V3学习笔记","date":"2021-08-30T11:59:09.000Z","updated":"2021-09-07T02:06:21.492Z","comments":true,"path":"api/articles/YOLO-V3学习笔记.json","keywords":null,"cover":[],"text":"YOLO-V3学习笔记 知识点来源于论文和网络，仅记录学习 网络结构Backbone 整个v3结构没有池化层和全连接层 输出特征图缩小到输入的1/32。所以，通常都要求输入图片是32的倍数 DBL:代码中的Darknetconv2d_BN_Leaky，是yolo_v3的基本组件。...","link":"","photos":[],"count_time":{"symbolsCount":"5.1k","symbolsTime":"5 mins."},"categories":[],"tags":[{"name":"detection","slug":"detection","count":3,"path":"api/tags/detection.json"}],"author":{"name":"Hulk Wang","slug":"blog-author","avatar":"/images/avatar_small.jpg","link":"https://github.com/TalkUHulk","description":"I'm 浩克，CV算法工程师，热衷于各种有趣的技术，此博客主要用来做学习总结，杀死拖延症。<br /> <img src=\"/images/funny.gif\" height=\"240\" width=\"360\"/>","socials":{"github":"https://github.com/TalkUHulk","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"https://weibo.com/311127773","zhihu":"https://www.zhihu.com/people/MisterAntebellum","csdn":"https://blog.csdn.net/hyqwmxsh","juejin":"","customs":{}}}}}