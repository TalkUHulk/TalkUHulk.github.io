[{"id":"48031087686b5c5ecd7460e246ad1434","title":"StyelGanåŠå…¶åº”ç”¨","content":"\n\n\n\n\n\n\n\n\nå¯¹é¡¹ç›®realworld-stylegan2-encoderç›¸å…³æŠ€æœ¯çš„æ€»ç»“ï¼Œæ¬¢è¿starï½\n\nThe demo of different style with age edit.\n\n\nStyleGan\nä¸ªäººè®¤ä¸ºï¼Œæ•ˆæœå¥½çš„ä¸»è¦ä¸¤ç‚¹æ˜¯ï¼š 1. Mapping Networkå¯¹éšè—ç©ºé—´(latent space)è¿›è¡Œè§£è€¦ 2. Synthesis Networkçš„éçº¿æ€§æ˜ å°„å±‚\näº®ç‚¹: 1. Style mixing\n\nMapping Network\n\n\n\n\n\n\n\n\n\nMapping network è¦åšçš„äº‹å°±æ˜¯æŠŠéšå‘é‡zè§£è€¦ä¸ºw(latent code)\n\n\n\n\n\n\n\n\n\nlatent code ç®€å•ç†è§£å°±æ˜¯ï¼Œä¸ºäº†æ›´å¥½çš„å¯¹æ•°æ®è¿›è¡Œåˆ†ç±»æˆ–ç”Ÿæˆï¼Œéœ€è¦å¯¹æ•°æ®çš„ç‰¹å¾è¿›è¡Œè¡¨ç¤ºï¼Œä½†æ˜¯æ•°æ®æœ‰å¾ˆå¤šç‰¹å¾ï¼Œè¿™äº›ç‰¹å¾ä¹‹é—´ç›¸äº’å…³è”ï¼Œè€¦åˆæ€§è¾ƒé«˜ï¼Œå¯¼è‡´æ¨¡å‹å¾ˆéš¾å¼„æ¸…æ¥šå®ƒä»¬ä¹‹é—´çš„å…³è”ï¼Œä½¿å¾—å­¦ä¹ æ•ˆç‡ä½ä¸‹ï¼Œå› æ­¤éœ€è¦å¯»æ‰¾åˆ°è¿™äº›è¡¨é¢ç‰¹å¾ä¹‹ä¸‹éšè—çš„æ·±å±‚æ¬¡çš„å…³ç³»ï¼Œå°†è¿™äº›å…³ç³»è¿›è¡Œè§£è€¦ï¼Œå¾—åˆ°çš„éšè—ç‰¹å¾ï¼Œå³latent codeã€‚ç”± latent codeç»„æˆçš„ç©ºé—´å°±æ˜¯ latent spaceã€‚\nä¸ºä»€ä¹ˆè§£è€¦ï¼Ÿ\n\nä¸€èˆ¬ z æ˜¯ç¬¦åˆå‡åŒ€åˆ†å¸ƒæˆ–è€…é«˜æ–¯åˆ†å¸ƒçš„éšæœºå‘é‡ï¼Œä½†åœ¨å®é™…æƒ…å†µä¸­ï¼Œå„ä¸ªå±æ€§æ„æˆçš„ç‰¹å¾ç©ºé—´å¹¶ä¸æ˜¯è¿™æ ·çš„ï¼Œä»–ä»¬å¾€å¾€å­˜åœ¨ä¸€å®šçš„å…ˆéªŒã€‚ä¾‹å¦‚æ–‡ä¸­æ‰€åˆ—ä¸¾çš„ä¾‹å­ï¼šé•¿å¤´å‘å’Œç”·å­æ°”æ¦‚å¾€å¾€ä¸ä¼šåŒæ—¶å‡ºç°ï¼Œå¦‚å›¾(a)ä¸­ï¼Œå·¦ä¸Šè§’åˆ™è¡¨ç¤ºç”·å­æ°”æ¦‚å’Œé•¿å¤´å‘åŒæ—¶å­˜åœ¨çš„åˆ†å¸ƒç©ºç¼º.é‚£ä¹ˆï¼Œåœ¨ä¼ ç»Ÿçš„ä»¥ z ä½œä¸ºéšå˜é‡çš„GANï¼ˆbï¼‰ä¸­ï¼Œç”±äº z æ¥è‡ªäºä¸€ä¸ªå¯¹ç§°çš„åˆ†å¸ƒï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸€ä¸ªåœ†å½¢ã€‚è€Œä¸ºäº†å¡«è¡¥ï¼ˆaï¼‰ä¸­å·¦ä¸Šè§’çš„ç©ºç¼ºï¼Œç‰¹å¾çš„åˆ†å¸ƒå¿…å°†è¢«æ‰­æ›²ï¼Œè¿™å°±é€ æˆäº†å½“ä»…ä»…æ”¹å˜ z çš„æŸä¸€ç»´åº¦æ—¶ï¼Œè¾“å‡ºå›¾åƒä¼šæœ‰å¤šä¸ªç‰¹å¾åŒæ—¶å‘ç”Ÿå˜åŠ¨ï¼Œè¿™å°±æ˜¯entanglementã€‚è€ŒStyleGANä¸­Mapping Networkçš„ä½œç”¨ï¼Œå°±æ˜¯å°†å›¾ï¼ˆbï¼‰æ˜ å°„æˆï¼ˆcï¼‰ï¼Œmapping networkå­¦åˆ°ä¸€ç§éçº¿æ€§å˜æ¢ï¼Œå°†åŸæœ¬å‡åŒ€çš„ç‰¹å¾ç©ºé—´æ‰­æ›²å˜å½¢ï¼Œä½¿å…¶æ¥è¿‘çœŸå®æƒ…å†µã€‚\nä½œè€…è®¤ä¸ºgeneratoråå¥½äºåŸºäºè§£è€¦çš„ç‰¹å¾å»ç”Ÿæˆ:\n\n\n\n\n\n\n\n\n\nWe posit that there is pressure for the generator to do so, as it should be easier to generate realistic images based on a disentangled representation than based on an entangled representa- tion.\nSynthesis Network\nStyleGANè®¤ä¸ºï¼Œæ‰€è°“imageå°±æ˜¯styleçš„é›†åˆï¼Œè€Œstyleæ˜¯æœ‰å±‚çº§çš„ * Coarse styles -&gt; pose, hair, face shape * Middle styles -&gt; facial features, eyes * Fine styles -&gt; color scheme\nSynthesis Networké‡Œé¢ç”¨åˆ°äº†AdaInæ¨¡å—ã€‚\n\\[AdaIN(x_i,y)=y_{s,i}\\frac{x_i-\\mu(x_i)}{\\sigma(x_i)}+y_{b,i}\\]\nä¸é£æ ¼è¿ç§»ä¸åŒï¼ŒStyleGANæ˜¯ä»å‘é‡wè€Œä¸æ˜¯é£æ ¼å›¾åƒè®¡ç®—è€Œæ¥ã€‚\nconstant input\nStyleGANç”Ÿæˆå›¾åƒçš„ç‰¹å¾æ˜¯ç”±wå’ŒAdaINæ§åˆ¶çš„ï¼Œé‚£ä¹ˆç”Ÿæˆå™¨çš„åˆå§‹è¾“å…¥å¯ä»¥è¢«å¿½ç•¥ï¼Œå¹¶ç”¨å¸¸é‡å€¼æ›¿ä»£ã€‚è¿™æ ·åšçš„ç†ç”±æ˜¯ï¼Œé¦–å…ˆå¯ä»¥é™ä½ç”±äºåˆå§‹è¾“å…¥å–å€¼ä¸å½“è€Œç”Ÿæˆå‡ºä¸€äº›ä¸æ­£å¸¸çš„ç…§ç‰‡çš„æ¦‚ç‡ï¼ˆè¿™åœ¨GANsä¸­éå¸¸å¸¸è§ï¼‰ï¼Œå¦ä¸€ä¸ªå¥½å¤„æ˜¯å®ƒæœ‰åŠ©äºå‡å°‘ç‰¹å¾çº ç¼ ï¼Œå¯¹äºç½‘ç»œåœ¨åªä½¿ç”¨wä¸ä¾èµ–äºçº ç¼ è¾“å…¥å‘é‡çš„æƒ…å†µä¸‹æ›´å®¹æ˜“å­¦ä¹ ã€‚\nStochastic variation\nstylegané€šè¿‡æ·»åŠ per-pixel noiseä¸ºç”Ÿæˆçš„å›¾åƒå¢åŠ éšæœºç»†èŠ‚ï¼Œå¦‚å¤´å‘ä¸ã€èƒ¡é¡»ã€æ¯›å­”ç­‰ã€‚åœ¨ä¸åŒå±‚æ·»åŠ å™ªå£°ä¼šæœ‰ä¸ä¸€æ ·çš„æ•ˆæœã€‚\n\nStyle mixing\nÂ Style mixing çš„æœ¬æ„æ˜¯å»æ‰¾åˆ°æ§åˆ¶ä¸åŒstyleçš„latent codeçš„åŒºåŸŸä½ç½®ï¼Œå…·ä½“åšæ³•æ˜¯å°†ä¸¤ä¸ªä¸åŒçš„latent codeÂ z1å’ŒÂ z2 è¾“å…¥åˆ° mappint network ä¸­ï¼Œåˆ†åˆ«å¾—åˆ°w1å’Œw2ï¼Œåˆ†åˆ«ä»£è¡¨ä¸¤ç§ä¸åŒçš„ styleï¼Œç„¶ååœ¨ synthesis network ä¸­éšæœºé€‰ä¸€ä¸ªä¸­é—´çš„äº¤å‰ç‚¹ï¼Œäº¤å‰ç‚¹ä¹‹å‰çš„éƒ¨åˆ†ä½¿ç”¨Â w1ï¼Œäº¤å‰ç‚¹ä¹‹åçš„éƒ¨åˆ†ä½¿ç”¨Â w2ï¼Œç”Ÿæˆçš„å›¾åƒåº”è¯¥åŒæ—¶å…·æœ‰ source A å’Œ source B çš„ç‰¹å¾ï¼Œç§°ä¸º style mixingã€‚\n\n\n\n\n\n\n\n\n\næ ¹æ®å®éªŒï¼Œç”±æ­¤å¯ä»¥å¤§è‡´æ¨æ–­ï¼Œä½åˆ†è¾¨ç‡çš„style æ§åˆ¶å§¿æ€ã€è„¸å‹ã€é…ä»¶ æ¯”å¦‚çœ¼é•œã€å‘å‹ç­‰styleï¼Œé«˜åˆ†è¾¨ç‡çš„styleæ§åˆ¶è‚¤è‰²ã€å¤´å‘é¢œè‰²ã€èƒŒæ™¯è‰²ç­‰styleã€‚\nLoss\nä»€ä¹ˆæ˜¯é¥±å’ŒæŸå¤±å‡½æ•° Non-Saturating LossFunction\n\n\n\n\n\n\n\n\n\néé¥±å’ŒæŸå¤±å‡½æ•°èƒ½åœ¨è®­ç»ƒæ—©æœŸæä¾›æ›´å¤§çš„æ¢¯åº¦\n\né¥±å’ŒLossï¼šç”Ÿæˆå™¨å¸Œæœ›æœ€å°åŒ–è¢«åˆ¤æ–­ä¸ºå‡çš„æ¦‚ç‡:\n\n\\[min\\ log(1-D(G(z)))\\]\n\néé¥±å’ŒLossï¼šç”Ÿæˆå™¨å¸Œæœ›æœ€å¤§åŒ–è¢«åˆ¤æ–­ä¸ºçœŸçš„æ¦‚ç‡:\n\n\\[max\\ log(D(G(z)))\\] or \\[min\\ -log(D(G(z)))\\]\n\n\n\n\n\n\n\n\n\nåè€…èƒ½æä¾›çš„æ¢¯åº¦ä¿¡æ¯æ›´å¥½ï¼Œä¸ºä»€ä¹ˆå‘¢ï¼Ÿ åœ¨è®­ç»ƒçš„åˆå§‹é˜¶æ®µï¼ŒGç”Ÿæˆçš„æ ·æœ¬å¾ˆå®¹æ˜“è¢«Dè¯†åˆ«å‡ºæ¥ï¼Œä¹Ÿå°±æ˜¯D(G(z)) è¶‹è¿‘äº0ï¼Œè€Œæ­¤æ—¶Loss1çš„æ¢¯åº¦ä¹Ÿè¶‹è¿‘äº0ï¼Œæ‰€ä»¥é¥±å’Œäº†ã€‚è€Œ Loss2çš„æ¢¯åº¦ä¸æ˜¯è¶‹è¿‘äº0çš„ï¼Œèƒ½å¤Ÿä¸ºç½‘ç»œçš„æƒé‡æ›´æ–°æä¾›å¥½çš„æ¢¯åº¦æ–¹å‘ï¼Œå¸®åŠ©æ”¶æ•›ï¼Œæ‰€ä»¥æ²¡é¥±å’Œã€‚\nStyleganä½¿ç”¨loss\nStyleGANå®˜æ–¹ä»£ç é‡‡ç”¨çš„æŸå¤±ä¸ºG_logistic_nonsaturatingä¸D_logistic_simplegpã€‚\n\\[Loss_G=log(exp(-D(G(z)))+1)\\]\n\\[Loss_D=log(exp(D(G(z)))+1)+log(exp(-D(x))+1)+r1_{gamma}*0.5*\\sum{\\nabla}_{T_{real}}^2+r2_{gamma}*0.5*\\sum{\\nabla}_{T_{fake}}^2\\]\nè®­ç»ƒ\nTruncation Trick\nTruncation trickçš„ç›®çš„æ˜¯ä¸ºäº†å¾—åˆ°æ›´é«˜çš„å¹³å‡FIDå€¼ã€‚ç”±äºè®­ç»ƒé›†å¿…å®šä¼šå­˜åœ¨ä¸€å®šç¨‹åº¦çš„æ ·æœ¬åˆ†å¸ƒä¸å‡åŒ€ï¼Œä½æ¦‚ç‡å¯†åº¦ï¼ˆæ ·æœ¬é‡å°‘çš„æ•°æ®ï¼‰æ²¡æœ‰å¾—åˆ°å¾ˆå¥½çš„è®­ç»ƒï¼Œå› æ­¤å½“wåˆšå¥½å¤„äºä½æ¦‚ç‡å¯†åº¦æ—¶ï¼Œç”Ÿæˆçš„å›¾åƒè´¨é‡å¾ˆå·®ï¼Œä¸ºäº†é¿å…ç”Ÿæˆè¿™äº›å½±å“FIDçš„å›¾åƒï¼Œstyleganä½¿ç”¨äº†truncation trickï¼Œå…¶å®ç°æ–¹å¼å¦‚ä¸‹ï¼š\nè®¡ç®—å¹³å‡latent code é€šè¿‡style scaleæ§åˆ¶å½“å‰wä¸å¹³å‡wçš„å æ¯”\n\\(w^-\\)æ˜¯Wä¸­å¿ƒ, \\(\\psi\\)æ˜¯ä¸€ä¸ªå®æ•°ï¼Œè¡¨ç¤ºå‹ç¼©å€æ•°,æˆªæ–­æˆ–è€…å‹ç¼©åçš„ï¼ˆtruncatedï¼‰wâ€˜å…¬å¼å¦‚ä¸‹ï¼š\n\n\næ¥æºè§æ°´å°\n\nè°ƒæ•´style scaleå¯ä½¿æœ€ç»ˆçš„latent codeæ€»åœ¨å¹³å‡wå·¦å³ï¼Œä¿è¯äº†ç”Ÿæˆå›¾åƒçš„è´¨é‡ã€‚\nå®éªŒæ•ˆæœ: \n\n\n\n\n\n\n\n\n\nstyleganä¸­truncation trcikä»…åœ¨ä½åˆ†è¾¨ç‡å±‚ä¸­ä½¿ç”¨ï¼Œè¿™æ ·å¯ä»¥ä¿è¯ç»†ç²’åº¦çš„äººè„¸ç»†èŠ‚ä¸å˜ï¼Œæ”¹å˜ç²—ç²’åº¦ä¸‹çš„äººè„¸ç‰¹å¾ï¼ˆäººè„¸æœå‘ã€é…é¥°ã€å¹´é¾„ã€å‘å‹é•¿åº¦ã€æ€§åˆ«ç­‰ï¼‰\nProgressive Growing\nprogressive growingçš„è®­ç»ƒæ–¹å¼ï¼Œå…ˆè®­ä¸€ä¸ªå°åˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆï¼Œè®­å¥½äº†ä¹‹åå†é€æ­¥è¿‡æ¸¡åˆ°æ›´é«˜åˆ†è¾¨ç‡çš„å›¾åƒã€‚ç„¶åç¨³å®šè®­ç»ƒå½“å‰åˆ†è¾¨ç‡ï¼Œå†é€æ­¥è¿‡æ¸¡åˆ°ä¸‹ä¸€ä¸ªæ›´é«˜çš„åˆ†è¾¨ç‡ã€‚\nå…¶ä»–\nPerceptual path length\n\n\n\n\n\n\n\n\n\nPerceptual path length æ˜¯ä¸€ä¸ªæŒ‡æ ‡ï¼Œç”¨äºåˆ¤æ–­ç”Ÿæˆå™¨æ˜¯å¦é€‰æ‹©äº†æœ€è¿‘çš„è·¯çº¿\nå¦‚æœlatent spaceæ˜¯å®Œå…¨çº¿æ€§çš„ï¼ˆå……åˆ†è§£è€¦ï¼‰ã€é‚£ä¹ˆä¸¤ä¸ªlatent codeè¿›è¡Œæ’å€¼å¾—åˆ°çš„å›¾åƒä¼šå¤„äºz1å’Œz2çš„è¿çº¿ä¸Šï¼ˆå¦‚ä¸Šå›¾è“è‰²çš„çº¿)ï¼Œå½“è§£è€¦ä¸å¤Ÿå……åˆ†æ—¶ï¼Œæ’å€¼ å¾—åˆ°çš„å›¾åƒå°±ä¼šå‡ºç°è¾ƒå¤§çš„åå·®ï¼Œå› æ­¤å¯ä»¥é€šè¿‡latent codeçš„æ’å€¼ç»“æœæ˜¯å¦ä¸z1ã€z2ä¹‹é—´ç›¸å·®è¾ƒå¤§è¡¡é‡GAN modelæ˜¯å¦å¯é ï¼Œå…¶ä¸­ä½¿ç”¨VGG16å¯¹å„ä¸ªå›¾åƒè¿› è¡Œç¼–ç ï¼Œè¿™å°±æ˜¯perception path lengthã€‚\n\n\næ¥æºè§æ°´å°\n\nStyleGan2\nStyleGAN V1åœ¨ç”Ÿæˆå›¾åƒæ—¶æœ‰ä¸¤ä¸ªæ˜æ˜¾çš„é—®é¢˜ï¼š * AdaINå¯¼è‡´çš„æ°´æ»´æ•ˆåº”ã€‚\n\n\nProgressive Generationå¯¼è‡´ç”Ÿæˆé«˜åˆ†è¾¨ç‡æ—¶ï¼Œç‰™é½¿ç­‰ç»†èŠ‚ä¸éšç€äººè„¸ç§»åŠ¨è€Œç§»åŠ¨ã€‚\n\n\n\nRemoving normalization artifacts\næ”¹è¿›1. å»é™¤const inputåçš„æ“ä½œï¼›Normä¸­å»é™¤meanï¼›å°†noiseå’Œbias ç§»åˆ°style blockå¤–ã€‚\nadainå¯¹æ¯ä¸ªfeature mapè¿›è¡Œå½’ä¸€åŒ–ï¼Œå› æ­¤æœ‰å¯èƒ½ä¼šç ´åæ‰featureä¹‹é—´çš„ä¿¡æ¯\né‡æ–°å®¡è§†AdaINæ¨¡å—ï¼šå°†AdaINæ‹†è§£ä¸ºNormalizationå’ŒModulationä¸¤éƒ¨åˆ†ï¼ˆå¦‚ä¸Šå›¾aä¸ºAdaINï¼Œæ‹†è§£åä¸ºbï¼‰ï¼Œç„¶åé‡ç»„ä¸€ä¸‹å¾—åˆ°style blockï¼ˆç°è‰²å—ï¼‰ã€‚é€šè¿‡å®éªŒå‘ç°ï¼Œstyle blockå†…çš„åç½®å’Œå™ªå£°ä¼šå¯¹åé¢çš„normalizationä¸­çš„æ–¹å·®å¹…åº¦æœ‰äº›è®¸å½±å“ï¼Œè€Œå¦‚æœå°†è¿™ä¸¤ä¸ªï¼ˆbiaså’Œnoiseï¼‰ç§»åˆ°style blockå¤–é¢ï¼Œç½‘ç»œç»“æœåˆ™æ›´åŠ ç¨³å®šã€‚è€Œæ­¤æ—¶normalizationå’Œmodulationçš„å‡å‡å€¼æ“ä½œä¹Ÿå¯ä»¥å»æ‰ï¼Œæœ€ç»ˆå¾—åˆ°å¦‚å›¾cçš„ç»“æ„.\n\n\n\n\n\n\n\n\n\nWe pinpoint the problem to the AdaIN operation that normalizes the mean and variance of each feature map separately, thereby potentially destroying any information found in the magnitudes of the features relative to each other.\n\n\n\n\n\n\n\n\n\n\né€šè¿‡è¿™ä¸€æ­¥ï¼Œä½œè€…å‘ç°åŸæœ¬AdaINå¯¼è‡´çš„æ°´æ»´æ•ˆåº”æ˜æ˜¾æ”¹å–„ã€‚ï¼ˆä¸»è¦å½’å› äºå»é™¤äº†Instance Normalizationï¼‰.ä½†æ˜¯styleGANçš„ä¸€ä¸ªäº®ç‚¹æ˜¯ style mixingï¼Œä»…ä»…åªæ”¹ç½‘ç»œç»“æ„ï¼Œè™½ç„¶èƒ½å»é™¤æ°´ç ï¼Œä½†æ˜¯æ— æ³•å¯¹style mixing æœ‰ scale-specificçº§åˆ«çš„æ§åˆ¶\n\n\n\n\n\n\n\n\n\nIn practice, style modulation may amplify certain feature maps by an order of magnitude or more. For style mixing towork, we must explicitly counteract this amplification on a per-sample basisâ€”otherwise the subsequent layers would not be able to operate on the data in a meaningful way. If we were willing to sacrifice scale-specific controls (see video), we could simply remove the normalization, thus removing the artifacts and also improving FID slightly. We will now propose a better alternative that removes the artifacts while retaining full controllability.\næ”¹è¿›2. weight demodulation\nå¯¹ç‰¹å¾å›¾çš„ä¸€ç³»åˆ—æ“ä½œæ”¹ä¸ºå¯¹æƒé‡çš„æ“ä½œã€‚ç‰¹å¾å›¾åªç»è¿‡å·ç§¯å¤„ç†å¹¶æ·»åŠ å™ªå£°ã€‚è¯¥æ–¹æ³•åœ¨ä¿ç•™å®Œå…¨å¯æ§æ€§çš„åŒæ—¶æ¶ˆé™¤äº†ä¼ªå½±ã€‚ ç¼©æ”¾ç‰¹å¾å›¾æ”¹ä¸ºç¼©æ”¾å·ç§¯æƒé‡ï¼ˆmodï¼‰: \\[w_{ijk}&#39;=s_i*w_{ijk}\\]\nç»è¿‡ç¼©æ”¾å’Œå·ç§¯åï¼Œè¾“å‡ºæ¿€æ´»çš„æ ‡å‡†å·®ä¸º:\n\\({\\delta}_i=\\sqrt{\\sum_{i,j}{w_{ijk}&#39;^2}}\\)\ndemodæƒé‡ï¼Œæ—¨åœ¨ä½¿è¾“å‡ºæ¢å¤åˆ°å•ä½æ ‡å‡†å·®:\n\n\n\n\n\n\n\n\n\nå°½ç®¡è¿™ç§æ–¹å¼ä¸Instance Normåœ¨æ•°å­¦ä¸Šå¹¶éå®Œå…¨ç­‰ä»·ï¼Œä½†æ˜¯weight demodulationåŒå…¶å®ƒnormalization æ–¹æ³•ä¸€æ ·ï¼Œä½¿å¾—è¾“å‡ºç‰¹å¾å›¾æœ‰ç€standardçš„unitå’Œdeviationã€‚\n\n\n\n\n\n\n\n\n\nwhere w and wâ€² are the original and modulated weights, respectively, si is the scale corresponding to the ith input feature map, and j and k enumerate the output feature maps and spatial footprint of the convolution, respectively.\n\nno Progressive growth\nProgressive growthæ˜¯å…ˆè®­ç»ƒä½åˆ†è¾¨ç‡ï¼Œç­‰è®­ç»ƒç¨³å®šåï¼Œå†åŠ å…¥é«˜ä¸€å±‚çš„åˆ†è¾¨ç‡è¿›è¡Œè®­ç»ƒï¼Œä½†è¿™æ ·å¯èƒ½ä¼šå¯¼è‡´â€œphaseâ€ artifactsã€‚\nä½œè€…ä»¬è®¤ä¸ºé—®é¢˜åœ¨äºï¼Œåœ¨é€æ­¥å¢é•¿çš„è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªåˆ†è¾¨ç‡éƒ½ä¼šç¬é—´ç”¨ä½œè¾“å‡ºåˆ†è¾¨ç‡ï¼Œè¿«ä½¿å…¶ç”Ÿæˆæœ€å¤§é¢‘ç‡ç»†èŠ‚ï¼Œç„¶åå¯¼è‡´å—è¿‡è®­ç»ƒçš„ç½‘ç»œåœ¨ä¸­é—´å±‚å…·æœ‰è¿‡é«˜çš„é¢‘ç‡ï¼Œä»è€ŒæŸå®³äº†ä½ç§»ä¸å˜æ€§ã€‚\n&lt; We believe the problem is that in progressive growing each resolution serves momentarily as the output resolution, forcing it to generate maximal frequency details, which then leads to the trained network to have excessively high frequencies in the intermediate layers, compromising shift invariance.\nä½¿ç”¨Progressive growthçš„åŸå› æ˜¯é«˜åˆ†è¾¨ç‡å›¾åƒç”Ÿæˆéœ€è¦çš„ç½‘ç»œæ¯”è¾ƒå¤§æ¯”è¾ƒæ·±ï¼Œå½“ç½‘ç»œè¿‡æ·±çš„æ—¶å€™ä¸å®¹æ˜“è®­ç»ƒï¼Œä½†æ˜¯skip connectionå¯ä»¥è§£å†³æ·±åº¦ç½‘ç»œçš„è®­ç»ƒï¼Œå› æ­¤æœ‰äº†ä¸‹å›¾ä¸­çš„ä¸‰ç§ç½‘ç»œç»“æ„ï¼Œéƒ½é‡‡ç”¨äº†skip connectionï¼Œä¸‰ç§ç½‘ç»œç»“æ„çš„æ•ˆæœä¹Ÿè¿›è¡Œäº†å®éªŒè¯„ä¼°:\n\nä¸‰ç§ç”Ÿæˆå™¨ï¼ˆè™šçº¿ä¸Šæ–¹ï¼‰å’Œåˆ¤åˆ«å™¨ä½“ç³»ç»“æ„å¦‚ä¸‹å›¾ã€‚Upå’ŒDownåˆ†åˆ«è¡¨ç¤ºåŒçº¿æ€§ä¸Šå’Œä¸‹é‡‡æ ·ã€‚ åœ¨æ®‹å·®ç½‘ç»œä¸­ï¼Œè¿™äº›è¿˜åŒ…æ‹¬1Ã—1å·ç§¯ä»¥è°ƒæ•´ç‰¹å¾å›¾çš„channelæ•°ã€‚tRGBå’ŒfRGBåœ¨RGBå’Œé«˜ç»´æ¯åƒç´ æ•°æ®ä¹‹é—´è½¬æ¢ã€‚ Config Eå’ŒFä¸­ä½¿ç”¨çš„ä½“ç³»ç»“æ„ä»¥ç»¿è‰²çªå‡ºæ˜¾ç¤ºã€‚\nå…¶ä»–ä¼˜åŒ–\nLazy regularization\nloss æ˜¯ç”±æŸå¤±å‡½æ•°å’Œæ­£åˆ™é¡¹ç»„æˆï¼Œä¼˜åŒ–çš„æ—¶å€™ä¹Ÿæ˜¯åŒæ—¶ä¼˜åŒ–è¿™ä¸¤é¡¹çš„ï¼Œlazy regularizationå°±æ˜¯æ­£åˆ™é¡¹å¯ä»¥å‡å°‘ä¼˜åŒ–çš„æ¬¡æ•°ï¼Œæ¯”å¦‚æ¯16ä¸ªminibatchæ‰ä¼˜åŒ–ä¸€æ¬¡æ­£åˆ™é¡¹ï¼Œè¿™æ ·å¯ä»¥å‡å°‘è®¡ç®—é‡ï¼ŒåŒæ—¶å¯¹æ•ˆæœä¹Ÿæ²¡ä»€ä¹ˆå½±å“ã€‚\npath lenth regularization\nä¹‹å‰æåˆ°path length æ˜¯ç”¨æ¥è¯„ä»·GANçš„ç”Ÿæˆè´¨é‡çš„ï¼Œåœ¨æ’å€¼çš„è¿‡ç¨‹ä¸­æˆ‘ä»¬å¸Œæœ›latent codeåœ¨æ½œåœ¨ç©ºé—´ä¸­ç§»åŠ¨å¤šå°‘ï¼Œå›¾åƒçš„å˜åŒ–å¹…åº¦å°±æ˜¯å¤šå°‘ï¼Œä¸å¸Œæœ›å›¾åƒå˜åŒ–å¹…åº¦å’Œæ½œåœ¨ç©ºé—´çš„ä½ç§»å­˜åœ¨è¾ƒå¤§å·®è·ï¼Œå› æ­¤é€šè¿‡æ­£åˆ™åŒ–å¯¹å¤§çš„å˜åŒ–å¹…åº¦è¿›è¡Œæƒ©ç½šï¼Œä»è€Œå®ç°ä¸Šè¿°ç›®çš„ã€‚\n\n\n\n\n\n\n\n\n\nå®ç°ï¼šåœ¨å›¾åƒä¸Šçš„æ¢¯åº¦ ç”¨å›¾åƒä¹˜ä¸Šå˜æ¢çš„æ¢¯åº¦æ¥è¡¨ç¤º\nStyleGan2-ada\næ¥æº\nTraining Generative Adversarial Networks with Limited Data\nStyleGANã€StyleGAN2çš„ç”Ÿæˆæ•ˆæœéå¸¸å¥½ï¼Œå¾ˆå¤§åŸå› æ˜¯æœ‰å¼ºå¤§çš„æ•°æ®é›†ï¼Œæ¯”å¦‚ç”Ÿæˆçš„é«˜æ¸…äººè„¸è®­ç»ƒé›†æœ‰14wå¼ ï¼ˆFFHQæœ‰7wå¼ ï¼Œå›¾åƒç¿»è½¬x2å°±æ˜¯14wå¼ ï¼‰ã€‚å¤§è§„æ¨¡çš„æ•°æ®é›†ä¸€èˆ¬æƒ…å†µä¸‹å¾ˆéš¾é‡‡é›†ï¼Œä½†æ˜¯å°æ•°æ®é›†ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆï¼Œä¸ºäº†è§£å†³è¿‡æ‹Ÿåˆï¼Œå¯ä»¥åœ¨è®­ç»ƒçš„æ—¶å€™å¯¹æ•°æ®è¿›è¡Œå›¾åƒå¢å¼ºï¼Œæ¯”å¦‚éšæœºè£å‰ªã€æ°´å¹³ç¿»è½¬ã€åŠ å™ªå£°ã€ä¸€å®šèŒƒå›´å†…æ”¹å˜è‰²è°ƒç­‰ã€‚ä½†æ˜¯ï¼Œæ•°æ®å¢å¼ºä¼šå¯¼è‡´ç”Ÿæˆå›¾ç‰‡ä¹Ÿæœ‰å¯¹åº”çš„å¢å¼ºï¼Œæ¯”å¦‚å¯¹åŸå›¾åŠ å…¥äº†å™ªå£°ï¼Œä¼šå¯¼è‡´ç”Ÿæˆå›¾ç‰‡ä¹Ÿæœ‰å™ªå£°ï¼Œè¿™æ˜¯æˆ‘ä»¬ä¸æœŸæœ›çœ‹åˆ°çš„ã€‚StyleGan2-adaè§£å†³å°æ•°æ®é›†çš„æ•°æ®å¢å¼ºå‡ºç°åœ¨ç”Ÿæˆç»“æœä¸­çš„é—®é¢˜ã€‚\n\nstylegan2-ada æ˜¯åŸºäºbCR (balanced consistency regularization) æ–¹æ³•. bCRæ–¹æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯å¯¹åŒä¸€å¼ è¾“å…¥å›¾ç‰‡ï¼Œå¦‚æœåšä¸¤ç§ä¸åŒçš„å›¾åƒå¢å¼ºï¼Œè¿™ä¸¤ç§å¢å¼ºå¾—åˆ°çš„è¾“å‡ºå›¾ç‰‡åº”è¯¥æ˜¯ä¸€æ ·çš„ã€‚æ­¤å¤–ï¼ŒbCRè¿˜åœ¨åˆ¤åˆ«å™¨æŸå¤±é‡Œå¢åŠ äº†ä¸€è‡´æ€§æ­£åˆ™é¡¹ï¼ˆconsistency regularization termsï¼‰ï¼Œå¦‚ä¸Šå›¾ï¼ˆaï¼‰æ‰€ç¤ºï¼Œè“è‰²æ¡†å¯¹åº”çš„æ˜¯å›¾åƒå¢å¼ºçš„æ“ä½œã€‚\nstylegan2-ada è®¤ä¸º bCR åªå¯¹åˆ¤åˆ«å™¨åšäº†å›¾åƒå¢å¼ºï¼Œä½†æ˜¯æ²¡å¯¹ç”Ÿæˆå™¨åšå›¾åƒå¢å¼ºï¼Œå› æ­¤æ— æ³•çº¦æŸç”Ÿæˆå™¨ï¼Œstylegan2-ada åœ¨bCR åŸºç¡€ä¸Šè¿›è¡Œæ”¹è¿›ï¼Œå¯¹æ‰€æœ‰å›¾åƒè¿›è¡Œäº†å›¾åƒå¢å¼ºï¼Œç§»é™¤äº†åœ¨æŸå¤±é‡Œå¢åŠ ä¸€è‡´æ€§æ­£åˆ™é¡¹ï¼ˆCR loss term)ï¼Œåœ¨ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨é‡Œéƒ½ç”¨å¢å¼ºåçš„å›¾åƒï¼Œstylegan2-adaçš„ç½‘ç»œè®¾è®¡å¦‚ä¸Šå›¾ï¼ˆbï¼‰.\nstylegan2-ada çš„ ada æ˜¯æŒ‡ adaptive discriminator augmentationï¼Œè§£å†³çš„ä¸»è¦æ˜¯é€šè¿‡ç½‘ç»œè‡ªé€‚åº”çš„å¾—åˆ°æ•°æ®å¢å¼ºçš„æ¦‚ç‡pã€‚ä¸€èˆ¬æˆ‘ä»¬åœ¨åšå›¾åƒå¢å¼ºæ—¶ï¼Œä¼šè®¾ç½®ä¸€ä¸ªæ¦‚ç‡pï¼Œä»¥pçš„æ¦‚ç‡å†³å®šå¯¹å›¾åƒæ˜¯å¦åšå›¾åƒå¢å¼ºã€‚è¿™ä¸ªpä¸€èˆ¬æ˜¯äººä¸ºè®¾å®šçš„è¶…å‚ï¼Œä½œè€…é€šè¿‡å‰æœŸå®éªŒè¡¨æ˜ï¼Œpçš„å–å€¼å¯¹ç”Ÿæˆç»“æœæœ‰å¾ˆå¤§å½±å“\n\n\n\n\n\n\n\n\n\nIdeally, we would like to avoid manual tuning of the augmentation strength and instead control it dynamically based on the degree of overfitting\n\næœ‰äº†è¿‡æ‹Ÿåˆçš„å¯å‘å¼æŒ‡æ ‡ï¼Œå¦‚ä½•è°ƒèŠ‚ p å‘¢ï¼Ÿæˆ‘ä»¬åˆå§‹ p ä¸º0ï¼Œç„¶ååœ¨æ¯4ä¸ªminibatchåè°ƒèŠ‚å®ƒçš„å€¼ï¼Œè°ƒèŠ‚çš„æ–¹æ³•å°±æ˜¯åŸºäº r å€¼ï¼Œå¦‚æœ r å€¼è¿‡å¤§æˆ–è€…è¿‡å°ï¼Œå°±å¯¹på¢å¤§æˆ–è€…å‡å°å›ºå®šçš„æ•°é‡ã€‚\n\n\n\n\n\n\n\n\n\nWe control the augmentation strength p as follows. We initialize p to zero and adjust its value once every four minibatches2 based on the chosen overfitting heuristic. If the heuristic indicates too much/little overfitting, we counter by incrementing/decrementing p by a fixed amount.\n\n\n\n\n\n\n\n\n\n\nå‡ºå¤„ å› ä¸ºç›®å‰StyleGANç”Ÿæˆçš„éƒ½æ˜¯è™šæ‹Ÿäººç‰©ï¼Œå¦‚æœæˆ‘ä»¬èƒ½æ‰¾åˆ°ç°å®äººç‰©åœ¨åˆå§‹åŸŸä¸­å¯¹åº”çš„ç¼–ç çš„è¯ï¼Œé‚£å°±æ„å‘³ç€å¯ä»¥å¯¹ç°å®ä¸­çš„äººç‰©è¿›è¡Œæ“ä½œå’Œå˜åŒ–ï¼Œè¿™ä¼šå¸¦æ¥ä¸€ä¸ªå¾ˆæœ‰æ„æ€çš„åœºæ™¯ï¼šæˆ‘ä»¬æ¯ä¸ªäººçš„äººè„¸éƒ½å¯ä»¥ç”¨ä¸€ä¸ªï¼ˆ18,512ï¼‰ç»´åº¦çš„å‘é‡æ¥è¡¨ç¤ºï¼Œå¹¶ä¸”åªè¦å¯¹è¿™ä¸ªå‘é‡ç¨ä½œä¸€äº›å˜åŠ¨ï¼Œå°±èƒ½ç”Ÿæˆå‡ºä¸€ä¸ªç•¥å¾®ä¸åŒäºæˆ‘ä»¬çš„æ–°çš„äººè„¸æ¨¡æ ·. è™½ç„¶æˆ‘ä»¬æ— æ³•ä¿è¯StyleGANçš„ç”Ÿæˆåˆ†å¸ƒåŸŸæ¶µç›–äº†åœ°çƒä¸Šæ‰€æœ‰äººè„¸çš„æ ·è²Œï¼Œä½†æ˜¯ç”±äºStyleGANçš„ç”ŸæˆåŸºäºåˆ†çº§æ§åˆ¶ç‰¹å¾ï¼Œå¹¶ä¸”è®­ç»ƒé›†æ¶µç›–äº†äººç§ã€æ€§åˆ«ã€å¹´é¾„ç­‰å„ç§æ ·å¼çš„äººè„¸ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åœ¨ç”Ÿæˆåˆ†å¸ƒä¸­æ‰¾åˆ°ä¸€å¼ ä¸ç°å®äººè„¸æ— æ¯”æ¥è¿‘çš„äººè„¸ï¼Œå¹¶æœ€ç»ˆè®¡ç®—å‡ºå…¶åœ¨åˆå§‹åŸŸä¸­å¯¹åº”çš„ç¼–ç ã€‚ ä»¥ä¸‹å‡ ä¸ªä½¿ç”¨é¢„è®­ç»ƒStyleGançš„ç›¸å…³åº”ç”¨ã€‚å®é™…å°±æ˜¯ä½¿ç”¨é¢„è®­ç»ƒstyleganä½œä¸ºdecoderï¼Œå¼„ä¸€ä¸ªencoderï¼Œå°±å¯ä»¥åšimage2imageã€‚\npixel2style2pixel\nEncoding in Style: a StyleGAN Encoder for Image-to-Image Translation\nç½‘ç»œç»“æ„\n\nç½‘ç»œç»“æ„å¦‚å›¾ï¼Œä½¿ç”¨é¢„è®­ç»ƒçš„Synthesis Networkä½œä¸ºdecoderï¼Œencoderä½¿ç”¨ç±»ä¼¼resnet+fpnï¼Œè¾“å‡ºlatent codeï¼ˆ18x512ï¼‰é€åˆ°decoderã€‚\nLoss\nå››éƒ¨åˆ†æ„æˆï¼š 1. pixel-wise L2 loss\n\\[L_2(x)=||x-pSp(x)||_2\\]\nç”Ÿæˆå›¾ç‰‡å’ŒåŸå›¾çš„L2.\n\nLPIPS Loss(æ„ŸçŸ¥æŸå¤±)\n\n\\[L_{LPIPS}(x)=||F(x)-F(pSp(x))||_2\\]\nF(Â·) denotes the perceptual feature extractor.\n\nregularzation loss\n\n\n\n\n\n\n\n\n\n\nTo encourage the encoder to output latent style vectors closer to the average latent vector, we additionally define the following regularization loss\n\\[L_{reg}(x)=||E(x)-\\overline w||_2\\]\n\n\n\n\n\n\n\n\n\nSimilar to the truncation trick introduced in StyleGAN, we find that adding this regularization in the training of our encoder improves image quality without harming the fidelity of our outputs, especially in some of the more am- biguous tasks explored below.\n\nID loss\n\n\n\n\n\n\n\n\n\n\nFinally, a common challenge when handling the specific task of encoding facial images is the preservation of the input identity. To tackle this, we incorporate a dedicated recognition loss measuring the cosine similarity between the output image and its source\n\\[L_{ID}(x)=1-&lt;R(x),R(pSp(x))&gt;\\]\nR is the pretrained ArcFace network.\nTotal Loss:\n\\[L(x)={\\lambda}_1L_2(x)+{\\lambda}_2L_{LPIPS}(x)+{\\lambda}_3L_{id}(x)+{\\lambda}_4L_{reg}(x)\\]\nencoder4edit\nDesigning an Encoder for StyleGAN Image Manipulation\nè¿™è¾¹è®ºæ–‡åœ¨pSpçš„åŸºç¡€ä¸Šåšäº†æ”¹è¿›ï¼Œä¸»è¦è§£å†³çš„æ˜¯distortion editabilityå’Œproper reconstructionçš„tradeoff.\n\nå¦‚pSpä¸­æ‰€è¯´ï¼Œå’Œw+ç›¸æ¯”wçš„è¡¨è¾¾èƒ½åŠ›ä¸è¶³ï¼› &gt; The expressiveness of the W latent space has been shown to be limited, in that not every image can be accurately mapped into W. &gt; The space W+ has more degrees of freedom, and is thus signifi- cantly more expressive than W.\n\n\n\n\n\n\n\n\n\n\nè¿™ç¯‡è®ºæ–‡ä¸å†ä½¿ç”¨w+ï¼› Note, that here, we depart from the commonly used W+ notation due to its ambiguity with various works referring to it as both $w_k^ and \\(w_k^*\\)\n\n\\(w_k^*\\)æœ‰æ›´å¥½çš„â€œæ‰­æ›²â€èƒ½åŠ›ï¼Œç”Ÿæˆçš„å›¾ç‰‡è´¨é‡æ›´ä½ï¼ˆå†…å®¹ä¸çœŸå®ï¼‰ï¼Œè€Œä¸”ä½œè€…å‘ç°wâ€œç¼–è¾‘â€èƒ½åŠ›æ›´å¼º\n\n\n\n\n\n\n\n\n\n\nIt is well known that \\(w_k^*\\) achieves lower, i.e. better, distortion than W. Additionally, we find that W is more editable\n\n\n\né¢„è®­ç»ƒçš„StyleGanæ˜¯åœ¨wä¸Šå®Œæˆï¼Œæ‰€ä»¥ç”Ÿæˆå›¾ç‰‡çš„è´¨é‡ï¼ˆå†…å®¹æ–¹é¢ï¼‰æ›´å¥½æ›´ç¨³å®šï¼Œ\\(w_k^*\\)ç»´åº¦æ›´é«˜ï¼ˆ18x512ï¼‰ï¼Œæ‰€ä»¥è¡¨è¾¾èƒ½åŠ›æ›´å¼º\n\n\n\n\n\n\n\n\n\n\nObserve that since StyleGAN is originally trained in the W space, it is not surprising that W is more well-behaved and has better perceptual quality compared to its \\(w_k^*\\) counterpart. On the other hand, observe that due the significantly higher dimensionality of \\(w_k^*\\) and the architecture of StyleGAN, \\(w_k^*\\) has far greater expressive power.\n\næ‰€ä»¥ç»è¿‡ä¸€é¡¿é˜è¿°å’Œå®éªŒï¼Œä½œè€…è®¾è®¡äº†å¦‚ä¸‹æ–¹æ³•ï¼š\n\n\n\n\n\n\n\n\n\n\nThe first approach for getting closer to W is to encour- age the inferred \\(w_k^*\\) latent codes to lie closer to \\(w^*\\), i.e. minimize the variance between the different style codes, or equivalently, encourage the style codes to be identical. To this end, we propose a novel â€œprogressiveâ€ training scheme.\nå³å­¦ä¹ ç›¸å¯¹å¹³å‡wçš„18ä¸ªåç§»ï¼Œè¿™æ ·18ç»´è¡¨è¾¾èƒ½åŠ›æ›´å¥½ï¼Œä¸”ä¸åŒçš„style codeæ–¹å·®æ›´å°ï¼Œæ›´æ¥è¿‘wï¼Œç”Ÿæˆå›¾ç‰‡è´¨é‡æ›´é«˜ã€‚\nç½‘ç»œç»“æ„\n\næ•´ä½“ç½‘ç»œç»“æ„å¦‚å›¾ï¼Œä¸pSpç»“æ„åŸºæœ¬ä¸€è‡´ï¼Œä¸åŒçš„è®¾è®¡æ˜¯encoderè¾“å‡ºçš„æ˜¯18ä¸ªåç§»ï¼Œç„¶åä½œç”¨åœ¨å¹³å‡wä¸Šç»„æˆ\\(w^*\\)é€å…¥decoderï¼›\nLoss\n\nDistortion\n\nID loss\n\\[L_{sim}(x)=1-&lt;C(x),C(G(e4e(x)))&gt;\\]\nC: äººè„¸å°±ç”¨äººè„¸è¯†åˆ«æ¨¡å‹ï¼Œéäººè„¸ç”¨MoCoï¼›\nL2 loss \\[L_2(x)=||x-G(e4e(x))||_2\\]\nLPIPS loss \\[L_{LPIPS}(x)=||F(x)-F(G(e4e(x)))||_2\\]\nF(Â·) denotes the perceptual feature extractor.\n\n\n\\[L_{dist}(x)=Î»_{l2}L_2(x)+Î»{lpips}L_{LPIPS}(x)+Î»_{sim}L_{sim}(x)\\]\n\nPerceptual quality and editability\n\n\n\n\n\n\n\n\n\n\nTo increase the perceptual quality and editability, First, we apply a delta-regularization loss to ensure proximity to Wâˆ— when learning the offsets âˆ†i. Second,we use an adversarial loss using our latent discriminator, which encourages each learned style code to lie within the distribution W.\n\ndelta-regularization loss\n\n\\[L_{d-reg}(w)=\\sum_{i=1}^{N-1}||{\\triangle}_i||_2\\]\nwåç§»çš„regularization lossï¼Œç›®çš„æ˜¯ä½¿\\(w_k^*\\)å°½é‡ä¸è¿œç¦»\\(w^*\\)\n\n\n\n\n\n\n\n\n\nE(x) = (\\(w_0\\),\\(w_1\\),...,\\(w_{N-1}\\)) denote the output of the encoder, where N is the number of style-modulation layers; E(x) = (w, w + \\({\\triangle}_1\\), ..., w + \\({\\triangle}_{N-1}\\)).\n\nadversarial loss\n\nå¦‚ç»“æ„å›¾ä¸­æ©˜é»„è‰²\\(D_w\\),ä½¿ç”¨éé¥±å’ŒGan lossï¼Œå¢åŠ R1æ­£åˆ™æŸå¤±\n\n\n\n\n\n\n\n\n\nwe adopt a latent discriminator which is trained in an adversarial manner to discriminate between real samples from the W space (generated by StyleGANâ€™s mapping function) and the encoderâ€™s learned latent codes.\n\n\n\n\n\n\n\n\n\n\nIn every iteration, we calculate the GAN loss for every E(x)i and average over all i-s.\n\\[L_{edit}(x)=Î»_{d-reg}L_{d-reg}(x)+Î»{adv}L_{adv}(x)\\]\n\nTotal Loss\n\n\n\n\n\n\n\n\n\n\noverall loss objective is defined as a weighted combination of the distortion and editability losses: \\[L(x)=L{dist}(x)+Î»_{edit}L_{edit}(x)\\]\nprogressive training scheme\n\n\n\n\n\n\n\n\n\nWe note that low frequency details greatly control the distortion quality. Thus, our progressive training scheme first focuses on improving the low frequency distortion by tuning the coarse-level offsets. Then, the encoder gradually complements these offsets with higher frequency details introduced by the finer-level offsets\nEditability\nInterpreting the Latent Space of GANs for Semantic Face Editing\nè¿™é‡Œä¸»è¦ä»‹ç»ä¸€ä¸‹InterFaceGANè§£è¯»çš„æ–¹æ³•ï¼Œæ¦‚æ‹¬èµ·æ¥å¦‚ä¸‹ï¼š\nå¯¹äºä¸€ä¸ªäºŒåˆ†ç±»è¯­ä¹‰ï¼ˆä¾‹å¦‚ç”·æ€§å’Œå¥³æ€§ï¼‰ï¼Œè¯­ä¹‰çš„åˆ¤å®šè¾¹ç•Œå¯¹åº”éšç©ºé—´çš„ä¸€ä¸ªè¶…å¹³é¢,åˆ†ç•Œé¢zâˆˆ\\(R^d\\),\\(n^Tz\\)=0.çš„æ³•å‘é‡ä¸ºnï¼Œåœ¨è¶…å¹³é¢ä¸€ç«¯çš„\\(n^Tz\\)çš„ç¬¦å·ç›¸åŒï¼Œå› æ­¤å¯¹åº”çš„è¯­ä¹‰ç‰¹å¾ä¸€æ ·ï¼Œè‹¥è·ç¦»\\(n^Tz\\)çš„ç¬¦å·æ”¹å˜ï¼Œé‚£ä¹ˆå¯¹åº”è¯­ä¹‰ç‰¹å¾ä¹Ÿæ”¹å˜ã€‚\n\n\nå›¾ç‰‡æ¥æº\n\nSAM\nOnly a Matter of Style: Age Transformation Using a Style-Based Regression Model\né’ˆå¯¹å¹´é¾„æäº†ä¸€ä¸ªencoderï¼Œå’Œä¸Šä¸¤ä¸ªåŸºæœ¬æ¢æ±¤ä¸æ¢è¯ã€‚ ä¸ªäººæ„Ÿè§‰æ”¹è¿›ç‚¹ï¼Œæˆ–æ˜¯è¯´æ•ˆæœå¥½çš„åŸå› ï¼š 1. é¢å¤–åˆå¢åŠ äº†ä¸€ä¸ªencoderï¼Œæ¥å­¦ä¹ ä¸€ä¸ªéçº¿æ€§çš„åç§»ï¼› 2. lossï¼šåŠ å…¥circle loss\nç½‘ç»œç»“æ„\n\nLoss\nåœ¨L2ã€ID lossã€LPIPS Losså’Œregularization lossçš„åŸºç¡€ä¸Šï¼Œå¢åŠ äº†age loss,åŒæ—¶ä¿®æ”¹äº†ID lossã€‚ï¼ˆæ¯•ç«Ÿä¸åŒå¹´é¾„çš„ä¸€ä¸ªäººä¸èƒ½ä¸€æ¯›ä¸€æ ·ï¼‰\nID Loss\n\nAge Loss\n\\[L_{age}(x_{age})=||{\\alpha}_{target-age}-A(SAM(x_{age}))||_2\\]\nA:é¢„è®­ç»ƒå¹´é¾„é¢„æµ‹æ¨¡å‹ï¼›\nåŒæ—¶ï¼Œä¸ºäº†è§£å†³èƒŒæ™¯ç­‰éå¿…è¦éƒ¨åˆ†çš„æ”¹å˜ï¼ŒåŠ å…¥å¾ªç¯ä¸€è‡´æ€§æŸå¤±ï¼Œå¦‚ä¸‹ï¼š\n\n","slug":"StyelGanåŠå…¶åº”ç”¨","date":"2021-10-30T03:52:16.000Z","categories_index":"","tags_index":"work summary","author_index":"Hulk Wang"},{"id":"66e6fbbf30cdfd5fb293d5ee17ed3935","title":"æ‰‹æ’•ä»£ç ","content":"1. IOU\npython\ndef bb_intersection_over_union(boxA, boxB):\n    boxA = [int(x) for x in boxA]\n    boxB = [int(x) for x in boxB]\n\n    xA = max(boxA[0], boxB[0])\n    yA = max(boxA[1], boxB[1])\n    xB = min(boxA[2], boxB[2])\n    yB = min(boxA[3], boxB[3])\n\n    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n\n    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n    \n    iou = interArea / float(boxAArea + boxBArea - interArea)\n\n    return iou\nc++\n#include&lt;iostream&gt;\n#include&lt;vector&gt;\n#include&lt;algorithm&gt;\nusing namespace std;\n\ntypedef struct Bbox\n{\n    int x1;\n    int y1;\n    int x2;\n    int y2;\n    float score;\n}Bbox;\n\nfloat iou(Bbox box1,Bbox box2)\n{\n    max_x = max(box1.x1,box2.x1);  // æ‰¾å‡ºå·¦ä¸Šè§’åæ ‡å“ªä¸ªå¤§\n    min_x = min(box1.x2,box2.x2);  // æ‰¾å‡ºå³ä¸Šè§’åæ ‡å“ªä¸ªå°\n    max_y = max(box1.y1,box2.y1);\n    min_y = min(box1.y2,box2.y2);\n    if(min_x&lt;=max_x || min_y&lt;=max_y) // å¦‚æœæ²¡æœ‰é‡å \n        return 0;\n    float over_area = (min_x - max_x) * (min_y - max_y);  // è®¡ç®—é‡å é¢ç§¯\n    float area_a = (box1.x2 - boxa.x1) * (box1.y2 - boxa.y1);\n    float area_b = (box2.x2 - boxb.x1) * (box2.y2 - boxb.y1);\n    float iou = over_area / (area_a + area_b - over_area);\n    return iou;\n}\n2. NMS\npython\ndef nms(det, thresh):\n    x1 = det[..., 0]\n    y1 = det[..., 1]\n    x2 = det[..., 2]\n    y2 = det[..., 3]\n    scores = det[..., 4]\n    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n    order = np.argsort(scores)[::-1]  # Returns the indices that would sort an array.\n    keep = []\n    while order.size &gt; 0:\n        i = order[0]\n        keep.append(i)\n        xx1 = np.maximum(x1[i], x1[order[1:]])\n        yy1 = np.maximum(y1[i], y1[order[1:]])\n        xx2 = np.minimum(x2[i], x2[order[1:]])\n        yy2 = np.minimum(x2[i], x2[order[1:]])\n        w = np.maximum(0, xx2 - xx1 + 1)\n        h = np.maximum(0, yy2 - yy1 + 1)\n        inter = w * h\n        union = area[i] + area[order[1:]] - inter\n        iou = inter / union\n        next_i = np.where(iou &lt;= thresh)[0]  # åªæœ‰æ¡ä»¶ (condition)ï¼Œæ²¡æœ‰xå’Œyï¼Œåˆ™è¾“å‡ºæ»¡è¶³æ¡ä»¶ (å³é0) å…ƒç´ çš„åæ ‡\n        order = order[next_i + 1]\n    return keep\nc++\n/*\n  å°†bbxæŒ‰ç…§confidenceä»é«˜åˆ°ä½æ’åº\n*/\nbool sort_score(Bbox box1,Bbox box2)\n{\n    return (box1.score &gt; box2.score);\n}\n/*\n(1) è·å–å½“å‰ç›®æ ‡ç±»åˆ«ä¸‹æ‰€æœ‰bbxçš„ä¿¡æ¯\n(2) å°†bbxæŒ‰ç…§confidenceä»é«˜åˆ°ä½æ’åº,å¹¶è®°å½•å½“å‰confidenceæœ€å¤§çš„bbx\n(3) è®¡ç®—æœ€å¤§confidenceå¯¹åº”çš„bbxä¸å‰©ä¸‹æ‰€æœ‰çš„bbxçš„IOU,ç§»é™¤æ‰€æœ‰å¤§äºIOUé˜ˆå€¼çš„bbx\n(4) å¯¹å‰©ä¸‹çš„bbxï¼Œå¾ªç¯æ‰§è¡Œ(2)å’Œ(3)ç›´åˆ°æ‰€æœ‰çš„bbxå‡æ»¡è¶³è¦æ±‚ï¼ˆå³ä¸èƒ½å†ç§»é™¤bbxï¼‰\n*/\nvector&lt;Bbox&gt; nms(vector&lt;Bbox&gt;&amp;vec_boxs, float threshold)\n{\n    vector&lt;Bbox&gt;  res;\n    while(vec_boxs.size() &gt; 0)\n    {\n        sort(vec_boxs.begin(),vec_boxs.end(),cmp);\n        res.push_back(vec_boxs[0]);\n        for(int i =0;i &lt;vec_boxs.size()-1;i++)\n        {\n            float iou_value =iou(vec_boxs[0],vec_boxs[i+1]);\n            if (iou_value &gt;threshold)\n            {\n                vec_boxs.erase(vec_boxs[i+1]);\n            }\n        }\n        vec_boxs.erase(vec_boxs[0]);  // res å·²ç»ä¿å­˜ï¼Œæ‰€ä»¥å¯ä»¥å°†æœ€å¤§çš„åˆ é™¤äº†\n \n    }\n    return res;\n}\n3. å·ç§¯\npython\ndef conv_naive(x, c_out, ksize=3, padding=0, stride=1):\n    b, c_in, h, w = x.shape\n    kernel = np.random.rand(c_out, c_in, ksize, ksize)\n    out_height = (h - ksize + 2 * padding) // stride + 1\n    out_width = (w - ksize + 2 * padding) // stride + 1\n\n    out_x = np.random.rand(b, c_out, out_height,  out_width)\n    if padding &gt; 0:\n        pad_x = np.zeros((b, c_in, h + 2 * padding, w + 2 * padding))\n        pad_x[..., padding:-padding, padding:-padding] = x\n    else:\n        pad_x = x\n\n    for y in range(out_height):\n        for x in range(out_width):\n            roi = pad_x[..., y * stride:y * stride + ksize, x * stride: x * stride + ksize]\n            conv = np.tile(np.expand_dims(roi, axis=1), (1, c_out, 1, 1, 1)) * kernel\n            # conv = np.repeat(np.expand_dims(roi, axis=1), axis=1, repeats=c_out) * kernel\n            out_x[..., y, x] = np.squeeze(np.sum(conv, axis=(2, 3, 4), keepdims=True), axis=(2, 3, 4))\n\n    return out_x\nc++\n/äºŒç»´å·ç§¯çš„å®ç°\n#include&lt;cassert&gt;\n#include&lt;vector&gt;\n\n\nvoid conv2(int** filter, int **mat, int** res, const int filter_rows, const int filter_cols, const int mat_rows, const int mat_cols);//æŒ‡é’ˆæ•°ç»„ç‰ˆæœ¬\nstd::vector&lt;std::vector&lt;int&gt; &gt; conv2(std::vector&lt;std::vector&lt;int&gt; &gt; filter, std::vector&lt;std::vector&lt;int&gt; &gt; mat);//å‘é‡ç‰ˆæœ¬\n\n\nint main(void)\n{\n    return 0;\n}//main\n\nvoid conv2(int** filter, int **mat, int** res, const int filter_rows, const int filter_cols, const int mat_rows, const int mat_cols)\n{\n    assert(filter_cols &lt; mat_cols &amp;&amp; filter_rows &lt; mat_rows);\n    for(int i = 0; i &lt; mat_rows - 1; ++i)\n        for (int j = 0; j &lt; mat_cols - 1; ++j)\n        {\n            int tmp = 0;\n            for (int m = 0; m &lt; filter_rows; ++m)\n                for (int n = 0; n &lt; filter_cols; ++n)\n                    if(0 &lt;= i -m  &amp;&amp; i - m &lt; mat_rows &amp;&amp; 0 &lt;= j - n &amp;&amp; j - n &lt; mat_cols)\n                        tmp += filter[m][n] * mat[i - m][j - n];//å·ç§¯å…¬å¼\n\n            res[i][j] = tmp;\n        }\n}\n\nstd::vector&lt;std::vector&lt;int&gt; &gt; conv2(std::vector&lt;std::vector&lt;int&gt; &gt; filter, std::vector&lt;std::vector&lt;int&gt; &gt; mat )//å‘é‡ç‰ˆæœ¬\n{\n    const int filter_rows = filter.size();\n    const int filter_cols = filter[0].size();\n\n    const int mat_rows = mat.size();\n    const int mat_cols = mat[0].size();\n\n    assert(filter_cols &lt; mat_cols &amp;&amp; filter_rows &lt; mat_rows);\n    std::vector&lt;std::vector&lt;int&gt; &gt; res(mat_rows, std::vector&lt;int&gt;(mat_cols, 0));\n\n    for (int i = 0; i &lt; mat_rows - 1; ++i)\n        for (int j = 0; j &lt; mat_cols - 1; ++j)\n        {\n            int tmp = 0;\n            for (int m = 0; m &lt; filter_rows; ++m)\n                for (int n = 0; n &lt; filter_cols; ++n)\n                    if (0 &lt;= i - m &amp;&amp; i - m &lt; mat_rows &amp;&amp; 0 &lt;= j - n &amp;&amp; j - n &lt; mat_cols)\n                        tmp += filter[m][n] * mat[i - m][j - n];//å·ç§¯å…¬å¼\n\n            res[i][j] = tmp;\n        }\n    return res;\n}\n4. Pooling\nmaxpooling\nç‰ˆæœ¬1(ç®€å•ç‰ˆ)\ndef max_pooling(x, kernel_size=2, stride=2):\n    b, c_in, h, w = x.shape\n    ow = (w - kernel_size) // stride + 1\n    oh = (h - kernel_size) // stride + 1\n\n    out = np.zeros([b, c_in, oh, ow])\n    x_input = x\n    for y in range(oh):\n        for x in range(ow):\n            roi = x_input[..., y * stride: y * stride + kernel_size, x * stride: x * stride + kernel_size]\n            max_val = np.squeeze(np.max(roi, axis=(2, 3), keepdims=True), axis=(2, 3))\n            out[..., y, x] = max_val\n    return out\nç‰ˆæœ¬2(åå‘ä¼ æ’­)\nimport numpy as np\nimport torch\nclass MaxPooling2D:\n    def __init__(self, kernel_size=(2, 2), stride=2):\n        self.kernel_size = kernel_size\n        self.w_height = kernel_size[0]\n        self.w_width = kernel_size[1]\n\n        self.stride = stride\n\n        self.x = None\n        self.in_height = None\n        self.in_width = None\n\n        self.out_height = None\n        self.out_width = None\n\n        self.arg_max = None\n\n    def __call__(self, x):\n        self.x = x\n        self.in_height = np.shape(x)[0]\n        self.in_width = np.shape(x)[1]\n\n        self.out_height = int((self.in_height - self.w_height) / self.stride) + 1\n        self.out_width = int((self.in_width - self.w_width) / self.stride) + 1\n\n        out = np.zeros((self.out_height, self.out_width))\n        self.arg_max = np.zeros_like(out, dtype=np.int32)\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                out[i, j] = np.max(x[start_i: end_i, start_j: end_j])\n                self.arg_max[i, j] = np.argmax(x[start_i: end_i, start_j: end_j])\n        self.arg_max = self.arg_max\n        return out\n\n    def backward(self, d_loss):\n        dx = np.zeros_like(self.x)\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                index = np.unravel_index(self.arg_max[i, j], self.kernel_size)\n                dx[start_i:end_i, start_j:end_j][index] = d_loss[i, j] #\n        return dx\n\ntest\n\nnp.set_printoptions(precision=8, suppress=True, linewidth=120)\nx_numpy = np.random.random((1, 1, 6, 9))\nx_tensor = torch.tensor(x_numpy, requires_grad=True)\n\nmax_pool_tensor = torch.nn.MaxPool2d((2, 2), 2)\nmax_pool_numpy = MaxPooling2D((2, 2), stride=2)\n\nout_numpy = max_pool_numpy(x_numpy[0, 0])\nout_tensor = max_pool_tensor(x_tensor)\n\nd_loss_numpy = np.random.random(out_tensor.shape)\nd_loss_tensor = torch.tensor(d_loss_numpy, requires_grad=True)\nout_tensor.backward(d_loss_tensor)\n\ndx_numpy = max_pool_numpy.backward(d_loss_numpy[0, 0])\ndx_tensor = x_tensor.grad\n# print('input \\n', x_numpy)\nprint(\"out_numpy \\n\", out_numpy)\nprint(\"out_tensor \\n\", out_tensor.data.numpy())\n\nprint(\"dx_numpy \\n\", dx_numpy)\nprint(\"dx_tensor \\n\", dx_tensor.data.numpy())\ndef pooling(feature_map, size=2, stride=2):\n    channel=feature_map.shape[0]\n    height=feature_map.shape[1]\n    width=feature_map.shape[2]\n    padding_height=np.uint16(round((height-size+1)/stride))\n    padding_width=np.uint16(round((width-size+1)/stride))\n    print(padding_height,padding_width)\n\n    pool_out = np.zeros((channel,padding_height,padding_width),dtype=np.uint8)\n    \n    for map_num in range(channel):  \n        out_height = 0  \n        for r in np.arange(0,height, stride):  \n            out_width = 0  \n            for c in np.arange(0, width, stride):  \n                pool_out[map_num,out_height, out_width] = np.max(feature_map[map_num,r:r+size,c:c+size])  \n                out_width=out_width+1\n            out_height=out_height+1\n    return pool_out\navg-pooling\nç‰ˆæœ¬1(ç®€å•ç‰ˆ)\ndef avg_pooling(x, kernel_size=2, stride=2): b, c_in, h, w = x.shape ow = (w - kernel_size) // stride + 1 oh = (h - kernel_size) // stride + 1\nout = np.zeros([b, c_in, oh, ow])\nx_input = x\nfor y in range(oh):\n    for x in range(ow):\n        roi = x_input[..., y * stride: y * stride + kernel_size, x * stride: x * stride + kernel_size]\n        max_val = np.average(roi, axis=(2, 3))\n        out[..., y, x] = max_val\nreturn out\nç‰ˆæœ¬2(åå‘ä¼ æ’­)\nimport numpy as np\nimport torch\n\nclass AvgPooling2D:\n    def __init__(self, kernel_size=(2, 2), stride=2):\n        self.stride = stride\n        self.kernel_size = kernel_size\n        self.w_height = kernel_size[0]\n        self.w_width = kernel_size[1]\n\n    def __call__(self, x):\n        self.x = x\n        self.in_height = x.shape[0]\n        self.in_width = x.shape[1]\n\n        self.out_height = int((self.in_height - self.w_height) / self.stride) + 1\n        self.out_width = int((self.in_width - self.w_width) / self.stride) + 1\n        out = np.zeros((self.out_height, self.out_width))\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                out[i, j] = np.mean(x[start_i: end_i, start_j: end_j])\n        return out\n\n    def backward(self, d_loss):\n        dx = np.zeros_like(self.x)\n\n        for i in range(self.out_height):\n            for j in range(self.out_width):\n                start_i = i * self.stride\n                start_j = j * self.stride\n                end_i = start_i + self.w_height\n                end_j = start_j + self.w_width\n                dx[start_i: end_i, start_j: end_j] = d_loss[i, j] / (self.w_width * self.w_height)\n        return dx\n\n\ntest\n\nnp.set_printoptions(precision=8, suppress=True, linewidth=120)\nx_numpy = np.random.random((1, 1, 6, 9))\nx_tensor = torch.tensor(x_numpy, requires_grad=True)\n\navg_pool_tensor = torch.nn.AvgPool2d((2, 2), 2)\navg_pool_numpy = AvgPooling2D((2, 2), stride=2)\n\nout_numpy = avg_pool_numpy(x_numpy[0, 0])\nout_tensor = avg_pool_tensor(x_tensor)\n\nd_loss_numpy = np.random.random(out_tensor.shape)\nd_loss_tensor = torch.tensor(d_loss_numpy, requires_grad=True)\nout_tensor.backward(d_loss_tensor)\n\ndx_numpy = avg_pool_numpy.backward(d_loss_numpy[0, 0])\ndx_tensor = x_tensor.grad\n# print('input \\n', x_numpy)\nprint(\"out_numpy \\n\", out_numpy)\nprint(\"out_tensor \\n\", out_tensor.data.numpy())\n\nprint(\"dx_numpy \\n\", dx_numpy)\nprint(\"dx_tensor \\n\", dx_tensor.data.numpy())\n5. mAP\npython\nc++\n6. softnms\npython\nç‰ˆæœ¬1\nsoft_nmsæ“ä½œï¼Œè¿™é‡Œå‡è®¾boxesæ˜¯æ— åº(æœªæŒ‰scoreåšé™åº)çš„ï¼Œæ‰€ä»¥æ¯è½®soft_nmsè¿­ä»£éƒ½éœ€è¦ç±»ä¼¼å†’æ³¡æ’åºæ“ä½œï¼Œé€‰æ‹©å½“å‰top-1 bboxåšNMS\nNtï¼šè®¡ç®—IoUçš„é˜ˆå€¼ï¼ŒIoU &gt; Ntï¼Œå¯¹åº”bboxçš„scoreæƒé‡å°±è¦é™ä½\nthresholdï¼šé™æƒåé€šè¿‡thresholdè¿›ä¸€æ­¥å‰”é™¤ä½æƒé‡bbox\ndef cpu_soft_nms(boxes, sigma=0.5, Nt=0.3, threshold=0.001, method=0): N = boxes.shape[0] for i in range(N): maxscore = boxes[i, 4] # è·å–å½“å‰indexä¸‹çš„bbox maxpos = i\n    tx1 = boxes[i, 0]\n    ty1 = boxes[i, 1]\n    tx2 = boxes[i, 2]\n    ty2 = boxes[i, 3]\n    ts = boxes[i, 4]\n\n    pos = i + 1  # ä¸‹é¢æ“ä½œå°±å¾ˆå¸¸è§„äº†ï¼Œæ‰¾åˆ°å½“å‰index iä¹‹åæ‰€æœ‰bboxesä¸­ï¼Œscoreæœ€å¤§çš„bboxï¼Œå¹¶å°†ä¹‹èµ‹å€¼ç»™maxscoreã€maxpos\n    while pos &lt; N:\n        if maxscore &lt; boxes[pos, 4]:\n            maxscore = boxes[pos, 4]\n            maxpos = pos\n        pos = pos + 1\n\n    # ä¸‹é¢æ“ä½œæ›´ç®€å•ï¼Œæƒ³æƒ³æˆ‘ä»¬æœ€å¼€å§‹å­¦Cè¯­è¨€ï¼Œaã€bä¸¤å˜é‡å¦‚ä½•äº¤æ¢\n    # add max box as a detection\n    boxes[i, 0] = boxes[maxpos, 0]  # maxposå†…çš„ä¿¡æ¯ï¼Œæ”¾åˆ°index iå¤„ï¼Œä¹Ÿæ˜¯å½“å‰éœ€è¦å¤„ç†çš„bbox\n    boxes[i, 1] = boxes[maxpos, 1]\n    boxes[i, 2] = boxes[maxpos, 2]\n    boxes[i, 3] = boxes[maxpos, 3]\n    boxes[i, 4] = boxes[maxpos, 4]\n\n    # swap ith box with position of max box\n    boxes[maxpos, 0] = tx1  # åˆ«å¿˜äº†tx1ä¸­å¯æ˜¯ä¿å­˜äº†boxes[i,0]å¤‡ä»½çš„\n    boxes[maxpos, 1] = ty1\n    boxes[maxpos, 2] = tx2\n    boxes[maxpos, 3] = ty2\n    boxes[maxpos, 4] = ts\n\n    tx1 = boxes[i, 0]  # æ­¤æ—¶tx1å°±ä¿å­˜çš„maxposä½ç½®çš„bboxä¿¡æ¯äº†\n    ty1 = boxes[i, 1]\n    tx2 = boxes[i, 2]\n    ty2 = boxes[i, 3]\n    ts = boxes[i, 4]\n\n    pos = i + 1\n    # NMS iterations, note that N changes if detection boxes fall below thresholdï¼ŒNå€¼æ˜¯åŠ¨æ€å˜åŒ–çš„\n    while pos &lt; N:  # å‘ååšNMSæ¯”è¾ƒ\n        x1 = boxes[pos, 0]  # å½“å‰ä½ç½®çš„bbox\n        y1 = boxes[pos, 1]\n        x2 = boxes[pos, 2]\n        y2 = boxes[pos, 3]\n        s = boxes[pos, 4]\n\n        area = (x2 - x1 + 1) * (y2 - y1 + 1)  # posä¸‹boxçš„é¢ç§¯\n        iw = (min(tx2, x2) - max(tx1, x1) + 1)  # è®¡ç®—Insectionçš„å®½iwï¼Œå¦‚æœiw &lt; 0ï¼Œè¯´æ˜æ²¡ç›¸äº¤ï¼Œå¯ä»¥ç›´æ¥å¿½ç•¥äº†\n        if iw &gt; 0:\n            ih = (min(ty2, y2) - max(ty1, y1) + 1)  # è®¡ç®—Insectionçš„å®½ihï¼Œå¦‚æœih &lt; 0ï¼Œè¯´æ˜æ²¡ç›¸äº¤ï¼Œå¯ä»¥ç›´æ¥å¿½ç•¥äº†\n            if ih &gt; 0:\n                ua = float((tx2 - tx1 + 1) * (ty2 - ty1 + 1) + area - iw * ih)  # Uçš„é¢ç§¯\n                ov = iw * ih / ua  # iou between max box and detection box\n\n                if method == 1:  # soft_nmsä¸­linearé™æƒæ“ä½œï¼Œä¸ovè´Ÿç›¸å…³\n                    if ov &gt; Nt:\n                        weight = 1 - ov\n                    else:\n                        weight = 1\n                elif method == 2:  # soft_nmsä¸­gaussiané™æƒæ“ä½œ\n                    weight = np.exp(-(ov * ov) / sigma)\n                else:  # original NMSï¼Œweight = 0å°±ç›´æ¥æŠŠscoreç½®0\n                    if ov &gt; Nt:\n                        weight = 0\n                    else:\n                        weight = 1\n\n                boxes[pos, 4] = weight * boxes[pos, 4]  # æƒé‡é‡æ–°è°ƒæ•´\n\n                # if box score falls below threshold, discard the box by swapping with last boxï¼Œupdate N\n                # å¦‚æœbboxè°ƒæ•´åçš„æƒé‡ï¼Œå·²ç»å°äºé˜ˆå€¼thresholdï¼Œé‚£ä¹ˆè¿™ä¸ªbboxå°±å¯ä»¥å¿½ç•¥äº†ï¼Œ\n                # æ“ä½œæ–¹å¼æ˜¯ç›´æ¥ç”¨æœ€åä¸€ä¸ªæœ‰æ•ˆçš„bboxæ›¿æ¢å½“å‰posä¸Šçš„bbox\n                if boxes[pos, 4] &lt; threshold:\n                    boxes[pos, 0] = boxes[N - 1, 0]\n                    boxes[pos, 1] = boxes[N - 1, 1]\n                    boxes[pos, 2] = boxes[N - 1, 2]\n                    boxes[pos, 3] = boxes[N - 1, 3]\n                    boxes[pos, 4] = boxes[N - 1, 4]\n                    N = N - 1  # N-1ä½ç½®ä¸Šçš„bboxå·²ç»èµ‹å€¼åˆ°å‰é¢äº†ï¼Œè¯¥bboxå°±å¯ä»¥å¿½ç•¥äº†ï¼›\n                    pos = pos - 1  # posä½ç½®ä¸Šå¼•å…¥äº†æ–°çš„æœ‰æ•ˆbbox(N-1)ï¼Œå°±éœ€è¦å†è®¡ç®—ä¸€éäº†\n\n        pos = pos + 1  # å½“å‰pos bboxè®¡ç®—å®Œæ¯•\n\n# æ±‚æ»¡è¶³soft_nmsç­›é€‰æ¡ä»¶çš„æ‰€æœ‰bboxæ•°é‡ï¼Œå¹¶æ‰“æ•£ä¸ºlistï¼Œä½†ä¸€ä¸ªé—®é¢˜æ˜¯ï¼šå¦‚ä½•ä¸bbox indexå¯¹åº”èµ·æ¥ï¼Ÿ\n# æ–¹å¼å¾ˆç®€å•ï¼Œbboxä¹Ÿåšäº†å¯¹åº”çš„è°ƒæ•´ã€ç­›é€‰ï¼Œbbox listä¸­top-Nå°±å¯¹åº”ç€æœ€é«˜scoreï¼Œä¸”soft-nmsç­›é€‰é€šè¿‡çš„bboxï¼Œ\n# ä¸è¿‡æ¯ä¸ªbboxçš„scoreä¹ŸåŒæ ·ç»è¿‡soft-nmsè°ƒæ•´äº†\nkeep = [i for i in range(N)]\n\nreturn keep\nç‰ˆæœ¬2\ndef py_cpu_softnms(dets, sc, Nt=0.3, sigma=0.5, thresh=0.001, method=2):\n    \"\"\"\n    py_cpu_softnms\n    :param dets:   boexs åæ ‡çŸ©é˜µ format [y1, x1, y2, x2]\n    :param sc:     æ¯ä¸ª boxes å¯¹åº”çš„åˆ†æ•°\n    :param Nt:     iou äº¤å é—¨é™\n    :param sigma:  ä½¿ç”¨ gaussian å‡½æ•°çš„æ–¹å·®\n    :param thresh: æœ€åçš„åˆ†æ•°é—¨é™\n    :param method: ä½¿ç”¨çš„æ–¹æ³•\n    :return:       ç•™ä¸‹çš„ boxes çš„ index\n    \"\"\"\n\n    # indexes concatenate boxes with the last column\n    N = dets.shape[0]\n    indexes = np.array([np.arange(N)])\n    dets = np.concatenate((dets, indexes.T), axis=1)\n\n    # the order of boxes coordinate is [y1,x1,y2,x2]\n    y1 = dets[:, 0]\n    x1 = dets[:, 1]\n    y2 = dets[:, 2]\n    x2 = dets[:, 3]\n    scores = sc\n    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n\n    for i in range(N):\n        # intermediate parameters for later parameters exchange\n        tBD = dets[i, :].copy()\n        tscore = scores[i].copy()\n        tarea = areas[i].copy()\n        pos = i + 1\n\n        #\n        if i != N-1:\n            maxscore = np.max(scores[pos:], axis=0)\n            maxpos = np.argmax(scores[pos:], axis=0)\n        else:\n            maxscore = scores[-1]\n            maxpos = 0\n        if tscore &lt; maxscore:\n            dets[i, :] = dets[maxpos + i + 1, :]\n            dets[maxpos + i + 1, :] = tBD\n            tBD = dets[i, :]\n\n            scores[i] = scores[maxpos + i + 1]\n            scores[maxpos + i + 1] = tscore\n            tscore = scores[i]\n\n            areas[i] = areas[maxpos + i + 1]\n            areas[maxpos + i + 1] = tarea\n            tarea = areas[i]\n\n        # IoU calculate\n        xx1 = np.maximum(dets[i, 1], dets[pos:, 1])\n        yy1 = np.maximum(dets[i, 0], dets[pos:, 0])\n        xx2 = np.minimum(dets[i, 3], dets[pos:, 3])\n        yy2 = np.minimum(dets[i, 2], dets[pos:, 2])\n\n        w = np.maximum(0.0, xx2 - xx1 + 1)\n        h = np.maximum(0.0, yy2 - yy1 + 1)\n        inter = w * h\n        ovr = inter / (areas[i] + areas[pos:] - inter)\n\n        # Three methods: 1.linear 2.gaussian 3.original NMS\n        if method == 1:  # linear\n            weight = np.ones(ovr.shape)\n            weight[ovr &gt; Nt] = weight[ovr &gt; Nt] - ovr[ovr &gt; Nt]\n        elif method == 2:  # gaussian\n            weight = np.exp(-(ovr * ovr) / sigma)\n        else:  # original NMS\n            weight = np.ones(ovr.shape)\n            weight[ovr &gt; Nt] = 0\n\n        scores[pos:] = weight * scores[pos:]\n\n    # select the boxes and keep the corresponding indexes\n    inds = dets[:, 4][scores &gt; thresh]\n    keep = inds.astype(int)\n\n    return keep\ndef test():\n    # boxes and scores\n    boxes = np.array([[200, 200, 400, 400], [220, 220, 420, 420], [200, 240, 400, 440], [240, 200, 440, 400], [1, 1, 2, 2]], dtype=np.float32)\n    boxscores = np.array([0.9, 0.8, 0.7, 0.6, 0.5], dtype=np.float32)\n    index = py_cpu_softnms(boxes, boxscores, method=3)\nc++\n\n#include &lt;bits/stdc++.h&gt;\n\nnamespace nms\n{\nstruct proposal\n{\n  float score, x1, y1, x2, y2;\n};\n\ninline static bool cmp(const proposal&amp; a, const proposal&amp; b)\n{\n  return a.score &lt; b.score;\n}\n\ninline static float iou(const proposal&amp;, const proposal&amp;) __attribute__((always_inline));\n\nstatic float iou(const proposal&amp; a, const proposal&amp; b)\n{\n  auto overlap = 0.f;\n  float iw  = std::min(b.x2, a.x2) - std::max(b.x1, a.x1) + 1;\n  if (iw &gt; 0) {\n    float ih = std::min(b.y2, a.y2) - std::max(b.y1, a.y1) + 1;\n    if (ih &gt; 0) {\n      float ab = (b.x2 - b.x1 + 1) * (b.y2 - b.y1 + 1);\n      float aa = (a.x2 - a.x1 + 1) * (a.y2 - a.y1 + 1);\n      float inter = iw * ih;\n      overlap = inter / (aa + ab - inter);\n    }\n  }\n  return overlap;\n}\n\nenum class Method : uint32_t\n{\n  LINEAR = 0,\n  GAUSSIAN,\n  HARD\n};\n\nsize_t soft_nms(float* boxes,\n                int32_t* index,\n                size_t count,\n                Method method,\n                float Nt,\n                float sigma,\n                float threshold)\n{\n  std::iota(index, index + count, 0);  // np.arange()\n  auto p = reinterpret_cast&lt;proposal*&gt;(boxes);\n\n  auto N = count;\n  for (size_t i = 0; i &lt; N; ++i) {\n    auto max = std::max_element(p + i, p + N, cmp);\n    std::swap(p[i], *max);\n    std::swap(index[i], index[max - p]);\n\n    auto j      = i + 1;\n    auto weight = 0.f;\n    while (j &lt; N) {\n      auto ov = iou(p[i], p[j]);\n      switch (method) {\n        case Method::LINEAR:\n          weight = ov &gt; Nt ? 1.f - ov : 1.f;\n          break;\n        case Method::GAUSSIAN:\n          weight = std::exp(-(ov * ov) / sigma);\n          break;\n        case Method::HARD:\n          weight = ov &gt; Nt ? 0.f : 1.f;\n          break;\n      }\n      p[j].score *= weight;\n      if (p[j].score &lt; threshold) {\n        N--;\n        std::swap(p[j], p[N]);\n        std::swap(index[j], index[N]);\n        j--;\n      }\n      j++;\n    }\n  };\n\n  return N;\n}\n} /* namespace nms */\n\n7. å®ç°one-hotç‰¹å¾\npython\none_hot_t= np.zeros_like(y)  #ç”Ÿæˆå’Œyå½¢çŠ¶ä¸€æ ·çš„å…ƒç´ ä¸ºé›¶çš„æ•°ç»„\nfor j, i in zip(range(t.size), t):\n    #æœ‰å¤šå°‘ä¸ªæ ·æœ¬å°±åº”è¯¥å¯¹åº”å¤šå°‘ä¸ªæ ‡ç­¾\n    one_hot_t[j][i] = 1      #å˜ä¸ºone-hotç±»å‹æ ‡ç­¾ï¼šjè¡¨ç¤ºæ ·æœ¬ï¼Œiè¡¨ç¤ºæ ‡ç­¾ç´¢å¼•\n\n8. softmax\npython\nç”±äºæŒ‡æ•°å‡½æ•°çš„æ”¾å¤§ä½œç”¨è¿‡äºæ˜æ˜¾ï¼Œå¦‚æœç›´æ¥ä½¿ç”¨softmaxè®¡ç®—å…¬å¼ğ‘ ğ‘œğ‘“ğ‘¡ğ‘šğ‘ğ‘¥(ğ‘¥ğ‘–)=ğ‘’ğ‘¥ğ‘(ğ‘¥ğ‘–)/âˆ‘ğ‘’ğ‘¥ğ‘(ğ‘¥ğ‘—)è¿›è¡Œå‡½æ•°å®ç°ï¼Œå®¹æ˜“å¯¼è‡´æ•°æ®æº¢å‡º(ä¸Šæº¢)ã€‚æ‰€ä»¥æˆ‘ä»¬åœ¨å‡½æ•°å®ç°æ—¶åˆ©ç”¨å…¶æ€§è´¨ï¼šå…ˆå¯¹è¾“å…¥æ•°æ®è¿›è¡Œå¤„ç†ï¼Œä¹‹åå†åˆ©ç”¨è®¡ç®—å…¬å¼è®¡ç®—ã€‚å…·ä½“ä½¿å¾—å®ç°æ­¥éª¤ä¸ºï¼š æŸ¥æ‰¾æ¯ä¸ªå‘é‡xçš„æœ€å¤§å€¼cï¼› æ¯ä¸ªå‘é‡å‡å»å…¶æœ€å¤§å€¼c, å¾—åˆ°å‘é‡y = x-c; åˆ©ç”¨å…¬å¼è¿›è¡Œè®¡ç®—,softmax(x) = softmax(x-c) = softmax(y)\nimport numpy as np\n\ndef softmax(x: np.array):\n    x_max = np.max(x, axis=-1, keepdims=True)\n    x -= x_max\n    x_exp = np.exp(x)\n    s = x_exp / np.sum(x_exp, axis=-1, keepdims=True)\n    return s\n\n9. å„ç§æ»¤æ³¢\né©¬èµ›å…‹\né©¬èµ›å…‹çš„å®ç°åŸç†æ˜¯æŠŠå›¾åƒä¸ŠæŸä¸ªåƒç´ ç‚¹ä¸€å®šèŒƒå›´é‚»åŸŸå†…çš„æ‰€æœ‰ç‚¹ç”¨é‚»åŸŸå†…å·¦ä¸Šåƒç´ ç‚¹çš„é¢œè‰²ä»£æ›¿ï¼Œè¿™æ ·å¯ä»¥æ¨¡ç³Šç»†èŠ‚ï¼Œä½†æ˜¯å¯ä»¥ä¿ç•™å¤§ä½“çš„è½®å»“ã€‚ import cv2\n\ndef do_mosaic(frame, x, y, w, h, neighbor=9):\n    \"\"\"\n    :param frame: opencv frame\n    :param int x :  é©¬èµ›å…‹å·¦é¡¶ç‚¹\n    :param int y:  é©¬èµ›å…‹å³é¡¶ç‚¹\n    :param int w:  é©¬èµ›å…‹å®½\n    :param int h:  é©¬èµ›å…‹é«˜\n    :param int neighbor:  é©¬èµ›å…‹æ¯ä¸€å—çš„å®½\n    \"\"\"\n    fh, fw = frame.shape[0], frame.shape[1]\n    if (y + h &gt; fh) or (x + w &gt; fw):\n        return\n    for i in range(0, h - neighbor, neighbor):  # å…³é”®ç‚¹0 å‡å»neightbour é˜²æ­¢æº¢å‡º\n        for j in range(0, w - neighbor, neighbor):\n            rect = [j + x, i + y, neighbor, neighbor]\n            color = frame[i + y][j + x].tolist()  # å…³é”®ç‚¹1 tolist\n            left_up = (rect[0], rect[1])\n            right_down = (rect[0] + neighbor - 1, rect[1] + neighbor - 1)  # å…³é”®ç‚¹2 å‡å»ä¸€ä¸ªåƒç´ \n            cv2.rectangle(frame, left_up, right_down, color, -1)\n\n\nim = cv2.imread('test.jpg', 1)\ndo_mosaic(im, 219, 61, 460 - 219, 412 - 61)\né«˜æ–¯æ»¤æ³¢\nå‡ºå¤„\n\näºŒç»´é«˜æ–¯å‡½æ•°\n\nimport cv2\nimport numpy as np\n\ndef gaussian_filter(img, K_size=3, sigma=1.3):\n\n    if len(img.shape) == 3:\n        H, W, C = img.shape\n    else:\n        img = np.expand_dims(img, axis=-1)\n        H, W, C = img.shape\n\n    ## Zero padding\n    pad = K_size // 2\n    out = np.zeros((H + pad * 2, W + pad * 2, C), dtype=np.float)\n    out[pad: pad + H, pad: pad + W] = img.copy().astype(np.float)\n\n    ## prepare Kernel\n    K = np.zeros((K_size, K_size), dtype=np.float)\n    for x in range(-pad, -pad + K_size):\n        for y in range(-pad, -pad + K_size):\n            K[y + pad, x + pad] = np.exp( -(x ** 2 + y ** 2) / (2 * (sigma ** 2)))\n\n    K /= (2 * np.pi * sigma * sigma)\n    K /= K.sum()\n    tmp = out.copy()\n\n    # filtering\n    for y in range(H):\n        for x in range(W):\n            for c in range(C):\n                out[pad + y, pad + x, c] = np.sum(K * tmp[y: y + K_size, x: x + K_size, c])\n\n    out = np.clip(out, 0, 255)\n    out = out[pad: pad + H, pad: pad + W].astype(np.uint8)\n    return out\n\nå‡å€¼æ»¤æ³¢\nimport numpy as np\n\n\ndef means_filter(input_image, filter_size):\n    '''\n    å‡å€¼æ»¤æ³¢å™¨\n    :param input_image: è¾“å…¥å›¾åƒ\n    :param filter_size: æ»¤æ³¢å™¨å¤§å°\n    :return: è¾“å‡ºå›¾åƒ\n\n    æ³¨ï¼šæ­¤å®ç°æ»¤æ³¢å™¨å¤§å°å¿…é¡»ä¸ºå¥‡æ•°ä¸” &gt;= 3\n    '''\n    input_image_cp = np.copy(input_image)  # è¾“å…¥å›¾åƒçš„å‰¯æœ¬\n    filter_template = np.ones((filter_size, filter_size))  # ç©ºé—´æ»¤æ³¢å™¨æ¨¡æ¿\n    pad_num = int((filter_size - 1) / 2)  # è¾“å…¥å›¾åƒéœ€è¦å¡«å……çš„å°ºå¯¸\n    input_image_cp = np.pad(input_image_cp, (pad_num, pad_num), mode=\"constant\", constant_values=0)  # å¡«å……è¾“å…¥å›¾åƒ\n    m, n = input_image_cp.shape  # è·å–å¡«å……åçš„è¾“å…¥å›¾åƒçš„å¤§å°\n    output_image = np.copy(input_image_cp)  # è¾“å‡ºå›¾åƒ\n\n    # ç©ºé—´æ»¤æ³¢\n    for i in range(pad_num, m - pad_num):\n        for j in range(pad_num, n - pad_num):\n            output_image[i, j] = np.sum(filter_template * input_image_cp[i - pad_num:i + pad_num + 1, j - pad_num:j + pad_num + 1]) / (filter_size ** 2)\n    output_image = output_image[pad_num:m - pad_num, pad_num:n - pad_num]  # è£å‰ª\n\n    return output_image\nä¸­å€¼æ»¤æ³¢\n# ä¸­å€¼æ»¤æ³¢#\nimport cv2\nimport numpy as np\n\ndef MedianFilter(img,k=3,padding=None):\n    imarray=img\n    height = imarray.shape[0]\n    width = imarray.shape[1]\n    if not padding:\n        edge = int((k - 1) / 2)\n        if height - 1 - edge &lt;= edge or width - 1 - edge &lt;= edge:\n            print(\"The parameter k is to large.\")\n            return None\n        new_arr = np.zeros((height, width), dtype=\"uint8\")\n        for i in range(edge,height-edge):\n            for j in range(edge,width-edge):\n                new_arr[i, j] = np.median(imarray[i - edge:i + edge + 1, j - edge:j + edge + 1])# è°ƒç”¨np.medianæ±‚å–ä¸­å€¼\n    return new_arr\n\nKmeans\nhttps://zhuanlan.zhihu.com/p/35959301 #### ç§¯åˆ†å›¾å‡å€¼æ»¤æ³¢ https://blog.csdn.net/weixin_40647819/article/details/88775598\n","slug":"æ‰‹æ’•ä»£ç ","date":"2021-10-19T03:41:08.000Z","categories_index":"","tags_index":"interview summary","author_index":"Hulk Wang"},{"id":"2d84f3892209cec11720cffbf464a897","title":"CVé¢è¯•åŸºç¡€æ€»ç»“","content":"1. è¯„æµ‹æŒ‡æ ‡\n1.1 åŸºæœ¬æ¦‚å¿µ\n\nTP TN FP FN\n\n\nT-Ture;F-False è¡¨ç¤ºé¢„æµ‹ç»“æœçš„æ­£ç¡®æ€§ï¼ŒTè¡¨ç¤ºé¢„æµ‹æ­£ç¡®ï¼ŒFè¡¨ç¤ºé¢„æµ‹é”™è¯¯ï¼› P-positive;N-negative è¡¨ç¤ºé¢„æµ‹çš„æ­£è´Ÿæ€§ï¼ŒPè¡¨ç¤ºé¢„æµ‹ä¸ºæ­£æ ·æœ¬ï¼ŒNè¡¨ç¤ºé¢„æµ‹ä¸ºè´Ÿæ ·æœ¬ï¼›\n\n\n\n---\n---\n\n\n\n\nTPâ€”â€”True Positive\nçœŸæ­£ä¾‹ï¼Œè¡¨ç¤ºæ ·æœ¬ä¸ºæ­£ï¼Œé¢„æµ‹å€¼ä¸ºæ­£â€”â€”é¢„æµ‹æ­£ç¡®T\n\n\nFPâ€”â€”False Positive\nå‡æ­£ä¾‹ï¼Œè¡¨ç¤ºæ ·æœ¬ä¸ºè´Ÿï¼Œé¢„æµ‹å€¼ä¸ºæ­£â€”â€”é¢„æµ‹é”™è¯¯F\n\n\nFNâ€”â€”False Negative\nå‡è´Ÿä¾‹ï¼Œè¡¨ç¤ºæ ·æœ¬ä¸ºæ­£ï¼Œé¢„æµ‹å€¼ä¸ºè´Ÿâ€”â€”é¢„æµ‹é”™è¯¯F\n\n\nTNâ€”â€”True Negative\nçœŸè´Ÿä¾‹ï¼Œè¡¨ç¤ºæ ·æœ¬ä¸ºè´Ÿï¼Œé¢„æµ‹å€¼ä¸ºè´Ÿâ€”â€”é¢„æµ‹æ­£ç¡®T\n\n\n\n\nAccuracy Precision Recall\n\n\nAccuracy:\n\nç”¨äºåˆ¤å®šé¢„æµ‹ç»“æœçš„å‡†ç¡®ç¨‹åº¦ï¼Œå³é¢„æµ‹æ­£ç¡®çš„æ€»æ•°/æ ·æœ¬æ€»æ•°ã€‚ é¢„æµ‹æ­£ç¡®åˆåˆ†ä¸ºä¸¤ç§æƒ…å†µï¼šæ ·æœ¬ä¸ºæ­£ã€é¢„æµ‹ä¸ºæ­£å’Œæ ·æœ¬ä¸ºè´Ÿã€é¢„æµ‹ä¸ºè´Ÿï¼Œå³TP+TNã€‚\n\n\nPrecision:\n\nç²¾ç¡®ç‡ç”¨äºæè¿°åœ¨æ‰€æœ‰é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œé¢„æµ‹æ­£ç¡®çš„æ¯”ä¾‹,åœ¨æœ‰çš„ç¿»è¯‘ä¸­ï¼ŒPrecisionä¹Ÿè¢«ç§°ä¸ºæŸ¥å‡†ç‡ã€‚ æŸ¥å‡†ç‡é’ˆå¯¹çš„æ˜¯é¢„æµ‹ï¼Œé¡¾åæ€ä¹‰ï¼ŒæŸ¥å‡†ç‡ä¸»è¦ç”¨æ¥åˆ¤æ–­â€œæŸ¥çš„å‡†ä¸å‡†â€ï¼Œå…¶ä¾æ®æ˜¯æŸ¥å‡ºçš„æ­£ä¾‹å æ‰€æœ‰æ­£ä¾‹é¢„æµ‹çš„æ¯”ç‡ã€‚\n\n\nRecall:\n\nå’Œç²¾ç¡®ç‡ä¸åŒï¼ŒPrecisoné’ˆå¯¹çš„æ˜¯é¢„æµ‹ï¼ŒRecallé’ˆå¯¹çš„æ˜¯æ ·æœ¬ã€‚å¬å›ç‡è¡¨ç¤ºåœ¨æ‰€æœ‰æ­£ä¾‹çš„æ ·æœ¬ä¸­ï¼Œæœ‰å¤šå°‘è¢«é¢„æµ‹/æ£€æµ‹äº†å‡ºæ¥ï¼Œæ‰€ä»¥åœ¨æœ‰çš„ç¿»è¯‘ä¸­ï¼ŒRecallä¹Ÿè¢«ç§°ä¸ºæŸ¥å…¨ç‡ã€‚ æŸ¥å…¨ç‡é’ˆå¯¹çš„æ˜¯æ ·æœ¬ï¼Œå³å¯¹æ ·æœ¬è€Œè¨€ï¼Œæœ‰å¤šå°‘æ¯”ä¾‹çš„æ­£ä¾‹æ ·æœ¬åœ¨é¢„æµ‹ä¸­è¢«æ£€å‡ºã€‚\n\n\n\n\n\n\n\n\n\n\næœ€ä¼˜ç›®æ ‡æ˜¯å¸Œæœ›æŸ¥å‡†ç‡å’ŒæŸ¥å…¨ç‡éƒ½æ¥è¿‘100%ï¼Œä½†é€šå¸¸è¿™äºŒè€…çš„å…³ç³»æ˜¯è´Ÿç›¸å…³.\n\nF1-score\n\nF1 scoreæ˜¯å›´ç»•Recallå’ŒPrecisionè¡ç”Ÿå‡ºæ¥çš„ä¸€ä¸ªå‚è€ƒå€¼ï¼Œå…¬å¼ = Precisionå’ŒRecallçš„è°ƒå’Œå¹³å‡å€¼\n\n\n\n\n\n\n\n\n\n\nå…¶æ•°å€¼å¤§å°é€šå¸¸æ¥è¿‘äºŒè€…ä¸­çš„è¾ƒå°æ•°ã€å½“recall = precisionæ—¶ï¼ŒF1 = recall = precisionï¼Œå¦‚æœF1å€¼è¾ƒé«˜ï¼Œè¯´æ˜recallå’Œprecisionéƒ½è¾ƒé«˜,æˆ‘ä»¬å¸Œæœ›å–åˆ°è¾ƒé«˜çš„F1å€¼ã€‚\n\nPRæ›²çº¿\n\nPrecision-Recall curveï¼Œå³PRæ›²çº¿ï¼Œæ˜¯åœ¨PrecisionæŸ¥å‡†ç‡å’ŒRecallæŸ¥å…¨ç‡æ¦‚å¿µä¸Šè¡ç”Ÿå‡ºçš„æ›²çº¿ï¼ŒXè½´ä¸ºRecallï¼ŒYè½´ä¸ºPrecisionã€‚å¦‚ä¸‹å›¾A,B,Cä¸‰ä¸ªæ¨¡å‹ï¼Œç»˜åˆ¶å‡ºçš„PRæ›²çº¿ï¼š\n\n\n\n\n\n\n\n\n\n\næˆ‘ä»¬å¯ä»¥é€šè¿‡PRæ›²çº¿ï¼Œæ‰¾åˆ°æœ€ä¼˜åŒ–çš„æ¨¡å‹ã€‚æ¯”è¾ƒä¸Šå›¾Aå’ŒCæ¨¡å‹ï¼Œå¾ˆå®¹æ˜“æ¯”è¾ƒå‡ºAæ¨¡å‹æ›´ä¼˜ï¼Œå¯¹äºæ¨¡å‹çš„PRæ›²çº¿æ¥è¯´ï¼Œå¦‚æœè¿™æ¡æ›²çº¿èƒ½åŒ…ä½å¦ä¸€æ¡æ¨¡å‹æ›²çº¿ï¼Œåˆ™å¯ä»¥è‚¯å®šè¿™æ¡æ›²çº¿ä¸‹çš„æ¨¡å‹æ›´ä¼˜ç§€ï¼ˆå› ä¸ºå…¶å®Œå…¨è¦†&gt; ç›–äº†æ¨¡å‹C,æ•…å¯ä»¥è½»æ˜“å–åˆ°PRå€¼éƒ½æ¥è¿‘ç†æƒ³è¯ï¼ˆ1,1ï¼‰çš„ç‚¹ï¼‰ä½†å½“æ¨¡å‹çš„PRå›¾æœ‰äº¤å‰æ—¶ï¼Œå°±ä¸å¤ªå®¹æ˜“é€šè¿‡è‚‰çœ¼æ¯”è¾ƒäº†ï¼Œè­¬å¦‚è¿™é‡ŒAå’ŒBã€‚ å¯¹äºæ¨¡å‹PRæ›²çº¿æœ‰äº¤å‰çš„æƒ…å†µï¼Œæˆ‘ä»¬å¯ä»¥è€ƒå¯Ÿå…¶F1å€¼ï¼ŒF1å€¼è¶Šå¤§ï¼Œæ¨¡å‹è¶Šä¼˜ï¼ï¼ˆå› ä¸ºé€šå¸¸F1å€¼è¶Šé«˜ï¼Œååº”åˆ°å›¾åƒä¸Šï¼Œè¡¨æ˜æ­¤æ¨¡å‹æ›²çº¿å›´ç»•Xè½´è¦†ç›–çš„é¢ç§¯æ›´å¤§ï¼Œè€Œé¢ç§¯è¶Šæ¥è¿‘1ï¼Œè¡¨æ˜Få’ŒPä¸¤è€…éƒ½å¾ˆé«˜ï¼‰ä¸Šå›¾Aå’ŒBæ¨¡å‹ï¼Œæ¨¡å‹Açš„F1&gt;æ¨¡å‹Bçš„F1å€¼ï¼Œæ•…æ¨¡å‹Aæ›´ä¼˜ç§€ã€‚\n\nROCæ›²çº¿\n\nReceiver Operating Characteristic curveï¼Œå³ROCæ›²çº¿ï¼Œè¯‘ä¸ºï¼šå—è¯•è€…å·¥ä½œç‰¹å¾æ›²çº¿ã€‚ROCæ›²çº¿èµ·æºäºâ€œäºŒæˆ˜â€ï¼Œæ˜¯ä¸€ä¸ªç”¨äºæ•Œæœºæ£€æµ‹çš„é›·è¾¾ä¿¡å·åˆ†ææŠ€æœ¯ï¼Œåæ¥åº”ç”¨åˆ°äº†åŒ»ç–—æ£€æµ‹ã€å¿ƒç†å­¦ç­‰é¢†åŸŸï¼Œ1989å¹´è¢«å¼•å…¥æœºå™¨å­¦ä¹ é¢†åŸŸã€‚åœ¨ROCæ›²çº¿ä¸­ï¼ŒXè½´ä¸ºFPRï¼ˆå‡æ­£ä¾‹ç‡ï¼‰,Yè½´ä¸ºTPRï¼ˆçœŸæ­£ä¾‹ç‡ï¼‰ã€‚å…¶ä¸­FPRæ˜¯False Positive Rateç¼©å†™ï¼Œå³FPç‡ï¼ˆå‡æ­£ä¾‹ç‡ï¼‰ï¼ŒTPRæ˜¯True Positive Rateçš„ç¼©å†™ï¼Œå³TPç‡ï¼ˆçœŸæ­£ä¾‹ç‡ï¼‰ã€‚ç»“åˆå›¾ç¤ºæ›´æ¸…æ™°ï¼š\nTPRåˆ†å­ï¼šTP,å³é¢„æµ‹ä¸ºæ­£ä¾‹ï¼Œå®é™…ä¸ºæ­£ç†ä¾‹ï¼ˆé¢„æµ‹æ­£ç¡®ï¼‰ï¼› TPRåˆ†æ¯ï¼šæ‰€æœ‰æ­£ä¾‹æ ·æœ¬ = TP + FN\nFPRåˆ†å­ï¼šFP,å³é¢„æµ‹ä¸ºæ­£ä¾‹ï¼Œå®é™…ä¸ºè´Ÿä¾‹ï¼ˆé¢„æµ‹é”™è¯¯ï¼‰ï¼› FPRåˆ†æ¯ï¼šæ‰€æœ‰è´Ÿä¾‹æ ·æœ¬æ•° = FP + TN\n\n\n\n\n\n\n\n\n\nå¯ä»¥çœ‹å‡ºï¼ŒTPRå®é™…ä¸Šå°± = RecallæŸ¥å…¨ç‡,FPRå®é™…ä¸Šå°± = PrecisionæŸ¥å‡†ç‡ï¼Œåªæ˜¯ä¸¤è€…Xè½´å’ŒYè½´æ¬¡åºç›¸å\n\n\n\n\n\n\n\n\n\n\nå’ŒPRæ›²çº¿ç±»ä¼¼ï¼Œå¦‚æœä¸€ä¸ªæ¨¡å‹æ›²çº¿å°†å¦ä¸€æ¡æ¨¡å‹æ›²çº¿â€œå®Œå…¨åŒ…ä½â€ï¼Œåˆ™å¯ä»¥æ–­å®šæ­¤æ¨¡å‹æ€§èƒ½æ›´ä¼˜ï¼å¦åˆ™ï¼Œè¿˜æ˜¯éœ€è¦é€šè¿‡ROCæ›²çº¿å›´Xè½´çš„é¢ç§¯æ¥ç¡®å®šæ¨¡å‹ä¼˜åŠ£ï¼Œæ­¤é¢ç§¯å³AUC(Area Under ROC Curve)\n\nAUC\n\nAUCï¼Œå³Area Under ROC Curveï¼Œè¡¨ç¤ºROCæ›²çº¿ä¸­ï¼Œæ›²çº¿å’ŒXè½´å›´æˆçš„é¢ç§¯ï¼Œé€šå¸¸æ¯”è¾ƒä¸¤ä¸ªæ¨¡å‹çš„AUCå¤§å°ï¼ŒAUCå¤§è€…ï¼Œè¡¨æ˜å…¶é¢ç§¯å¤§ï¼Œæ›´æ¥è¿‘1,æ¨¡å‹çš„TPRå’ŒFPRä¸¤è€…éƒ½ç›¸å¯¹è¾ƒé«˜ï¼Œæ¨¡å‹æ›´ä¼˜ã€‚\n\nAP,mAP\n\nAverage Precisionå¹³å‡ç²¾å‡†ç‡ = ï¼ˆæŸä¸€ä¸ªç±»åˆ«ï¼‰æ¯ä¸ªæ ·æœ¬çš„ç²¾ç¡®ç‡æ±‚å’Œ/æ ·æœ¬æ€»æ•°Nã€‚ çœ‹ä¸€ä¸ªä¾‹å­ï¼Œå‡è®¾VOCæ•°æ®é›†ä¸­ï¼Œåˆ†åˆ«æœ‰person,train,cat,dog...æ€»è®¡20ä¸ªåˆ†ç±»ç±»åˆ«ï¼Œæµ‹è¯•é›†æœ‰1000å¼ å›¾ç‰‡ï¼Œåˆ™é’ˆå¯¹å…¶ä¸­æŸä¸€ç±»ï¼Œè­¬å¦‚catç±»ï¼Œæˆ‘ä»¬è®¡ç®—å…¶å¹³å‡ç²¾å‡†ç‡APå³å¯ç”¨ï¼š,ä¸ºä»€ä¹ˆæ˜¯1000å¼ å›¾ç‰‡çš„Precisionç´¯åŠ ï¼Ÿå› ä¸ºæ¯ä¸€å¼ å›¾éƒ½æ˜¯æ½œåœ¨çš„å¾…åˆ†ç±»å›¾ç‰‡ï¼Œå¯èƒ½åŒ…å«20ä¸ªç±»åˆ«ä¸­çš„1ï½å¤šä¸ªåˆ†ç±»ï¼Œä¸”å¯èƒ½åŒ…å«è¿™äº›åˆ†ç±»ä¸‹çš„1ï½nä¸ªbounding boxï¼Œæ•…å¯¹äºæŸä¸ªåˆ†ç±»ï¼Œå•ç‹¬ä¸€å¼ å›¾ç‰‡æœ‰éœ€è¦ç‹¬ç«‹è®¡ç®—å…¶ç²¾å‡†åº¦ã€‚\nMean Average Precisionå‡å€¼å¹³å‡ç²¾å‡†ç‡ = æ‰€æœ‰ç±»åˆ«çš„APå€¼ç´¯åŠ æ±‚å’Œ/ç±»åˆ«æ•°\n\n\nIS(inception score)\n\n\n\n\n\n\n\n\n\n\nè¡¡é‡å›¾ç‰‡çš„ç”Ÿæˆè´¨é‡æ˜¯ä¸€ä¸ªæ¯”è¾ƒéš¾çš„é—®é¢˜ï¼Œä¸€ç›´ä»¥æ¥ä¹Ÿæ²¡æœ‰ä¸€ä¸ªç‰¹åˆ«å¥½çš„åº¦é‡æ–¹å¼ï¼Œinception scoreçš„æ€æƒ³ï¼Œæ˜¯é€šè¿‡å°†ç”Ÿæˆæ¨¡å‹çš„è¯„ä¼°é—®é¢˜ï¼Œé€šè¿‡æ˜ å°„åˆ°åˆ†ç±»å™¨ä¸Šï¼Œä»¥æ­¤æ¥ç®€åŒ–è¯„ä¼°çš„éš¾æ˜“ç¨‹åº¦ï¼Œæ˜¯ä¸€ä¸ªéå¸¸å¥½çš„åˆ›æ–°ã€‚å½“ç„¶è¿™ç§æ˜ å°„å¿…ç„¶å­˜åœ¨çš„é—®é¢˜å°±æ˜¯ä¿¡æ¯çš„ä¸¢å¤±ã€‚çœŸå®å›¾ç‰‡çš„inception_scoreæ˜¯è‚¯å®šæ¯”è¾ƒé«˜çš„ï¼Œä½†æ˜¯inception scoreé«˜å¹¶ä¸èƒ½ä»£è¡¨ç”Ÿæˆçš„è´¨é‡å°±å¥½ã€‚(æœ€ç®€å•çš„ä¾‹å­å°±æ˜¯é€šè¿‡adversarial samples,å¯ä»¥é€šè¿‡ç®€å•çš„ç”Ÿæˆæ¯ä¸ªç±»çš„ç‰¹å¾å›¾è°±ï¼Œçœ‹ä¼¼å™ªå£°çš„å›¾åƒï¼Œä½†æ˜¯å…¶inception scoreä¼šå¾ˆé«˜ã€‚)\n\n\n\n\n\n\n\n\n\nISå€¼è¶Šé«˜ï¼Œå›¾ç‰‡è´¨é‡å’Œå¤šæ ·æ€§åˆ™å¥½\nISç”¨æ¥è¡¡é‡GANç½‘ç»œçš„ä¸¤ä¸ªæŒ‡æ ‡ï¼š * ç”Ÿæˆå›¾ç‰‡çš„è´¨é‡ * å¤šæ ·æ€§\n8.1 å›¾ç‰‡çš„è´¨é‡ ç†µï¼ˆentropyï¼‰å¯ä»¥ç”¨æ¥æè¿°éšæœºæ€§ï¼šå¦‚æœä¸€ä¸ªéšæœºå˜é‡æ˜¯é«˜åº¦å¯é¢„æµ‹çš„ï¼Œé‚£ä¹ˆå®ƒå°±æœ‰è¾ƒä½çš„ç†µï¼›ç›¸åï¼Œå¦‚æœå®ƒæ˜¯é«˜åº¦ä¸å¯é¢„æµ‹ï¼Œé‚£ä¹ˆå®ƒå°±ç”¨è¾ƒé«˜çš„ç†µã€‚ å¦‚ä¸‹å›¾ï¼Œæˆ‘ä»¬æœ‰ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œp2æ¯”p1æœ‰æ›´é«˜çš„ç†µå€¼ï¼Œå› ä¸ºp2æ˜¯ä¸€ä¸ªå‡åŒ€åˆ†å¸ƒï¼Œæˆ‘ä»¬å¾ˆéš¾é¢„æµ‹xçš„å€¼ã€‚\n\nåœ¨GANä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ¡ä»¶æ¦‚ç‡ï½œå¯ä»¥è¢«é«˜åº¦é¢„æµ‹xè¡¨ç¤ºç»™å®šçš„å›¾ç‰‡ï¼Œyè¡¨ç¤ºè¿™ä¸ªå›¾ç‰‡åŒ…å«çš„ä¸»è¦ç‰©ä½“ï¼Œçœ‹åˆ°åé¢ä½ ä¼šæ›´åŠ æ¸…æ¥šè¿™ä¸ªæ¦‚ç‡æ˜¯ä»€ä¹ˆæ„æ€ï¼‰ï¼Œä¹Ÿå°±æ˜¯å¸Œæœ›å®ƒçš„ç†µå€¼è¾ƒä½ã€‚ä¾‹å¦‚ï¼Œç»™å®šä¸€ä¸ªå›¾ç‰‡ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“çš„çŸ¥é“å…¶ä¸­åŒ…å«ä»€ä¹ˆç‰©ä½“ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨inception networkï¼ˆå¯ä»¥ç†è§£è¿™æ˜¯ä¸€ä¸ªå›ºå®šçš„åˆ†ç±»ç½‘ç»œï¼‰æ¥å¯¹ç”Ÿæˆçš„å›¾åƒè¿›è¡Œåˆ†ç±»ã€‚ï¼ˆè¿™é‡Œéƒ½æ˜¯é’ˆå¯¹ImageNetæ•°æ®é›†è€Œè¨€ï¼‰ç„¶åé¢„æµ‹ ï½œï¼Œ è¿™é‡Œyå°±æ˜¯æ ‡ç­¾ã€‚ç”¨è¿™ä¸ªæ¦‚ç‡æ¥ååº”å›¾ç‰‡çš„è´¨é‡ã€‚ ç®€å•æ¥è¯´ï¼Œå‡å¦‚inception networkèƒ½å¤Ÿä»¥è¾ƒé«˜çš„æ¦‚ç‡é¢„æµ‹å›¾ç‰‡ä¸­åŒ…å«çš„ç‰©ä½“ï¼Œä¹Ÿå°±æ˜¯æœ‰å¾ˆé«˜çš„æŠŠæ¡å¯¹å…¶è¿›è¡Œæ­£ç¡®åˆ†ç±»ï¼Œè¿™å°±è¯´æ˜å›¾ç‰‡è´¨é‡è¾ƒé«˜ã€‚ç›¸åï¼Œæ¯”å¦‚æˆ‘ä»¬äººçœ¼å¹¶æ— æ³•çœ‹å‡ºè¿™å¼ å›¾ç‰‡æ˜¯ä»€ä¹ˆï¼Œå°±è¯´æ˜è¿™ä¸ªå›¾ç‰‡è´¨é‡ä¸é«˜ã€‚\n\n\n\n\n\n\n\n\n\nç»¼ä¸Šï¼Œæˆ‘ä»¬çŸ¥é“æ¦‚ç‡ï½œä»£è¡¨äº†å›¾ç‰‡çš„è´¨é‡ï¼Œæ¦‚ç‡è¶Šå¤§ï¼Œè´¨é‡åˆ™è¶Šé«˜ã€‚\n8.2 å¤šæ ·æ€§ å¦‚æœç”Ÿæˆçš„å›¾åƒå¤šæ ·åŒ–å¾ˆå¥½ï¼Œé‚£ä¹ˆé¢„æµ‹çš„æ ‡ç­¾yçš„åˆ†å¸ƒåˆ™ä¼šæœ‰è¾ƒé«˜çš„ç†µï¼Œå› ä¸ºæ•°é‡å¤šäº†ï¼Œæˆ‘ä»¬å°±æ›´éš¾å‡†ç¡®é¢„æµ‹ yã€‚\nç»“åˆä»¥ä¸Šä¸¤ä¸ªæŒ‡æ ‡æ¥è¯´ï¼Œæˆ‘ä»¬çš„ç›®æ ‡åº”è¯¥å°±æ˜¯è¿™æ ·çš„ï¼š 1. å›¾ç‰‡è´¨é‡ï¼šé’ˆå¯¹æ¯ä¸€å¼ ç”Ÿæˆçš„å›¾ç‰‡ï¼Œå·²çŸ¥çš„åˆ†ç±»å™¨åº”è¯¥å¾ˆç¡®ä¿¡çš„çŸ¥é“å®ƒå±äºå“ªä¸€ç±»ã€‚è€Œè¿™å¯ä»¥ç”¨æ¡ä»¶æ¦‚ç‡ï½œæ¥è¡¨ç¤ºï¼Œå®ƒè¶Šå¤§è¶Šå¥½ã€‚è€Œï½œç†µåº”è¯¥æ˜¯è¶Šå°è¶Šå¥½ã€‚\n2. å›¾ç‰‡çš„å¤šæ ·æ€§ï¼šæˆ‘ä»¬è¿™æ—¶å€™è€ƒè™‘çš„æ˜¯æ ‡ç­¾çš„åˆ†å¸ƒæƒ…å†µï¼Œæˆ‘ä»¬å¸Œæœ›æ ‡ç­¾åˆ†å¸ƒå‡ä¸ï¼Œè€Œä¸å¸Œæœ›æ¨¡å‹ç”Ÿæˆçš„éƒ½æ˜¯æŸä¸€ç±»å›¾ç‰‡ã€‚è¿™æ—¶å€™æˆ‘ä»¬è€ƒè™‘çš„ä¸æ˜¯æ¡ä»¶æ¦‚ç‡äº†ï¼Œè€Œæ˜¯è¾¹ç¼˜æ¦‚ç‡ï¼Œä¹Ÿå°±æ˜¯P(y),å±•å¼€æ¥å†™åº”è¯¥æ˜¯ ï¼Œè¿™é‡Œçš„nå°±æ˜¯åŸè®­ç»ƒæ•°æ®çš„ç±»æ•°ã€‚æˆ‘ä»¬å¸Œæœ›ï¼Œä»ç†µçš„è§’åº¦æ¥è¯´ï¼Œæˆ‘ä»¬å¸Œæœ› P(y)ç†µè¶Šå¤§è¶Šå¥½ã€‚\n\n\n\n\n\n\n\n\n\n1.æœ€å¤§åŒ–H(y);ä¹Ÿå°±æ˜¯å¯¹äºè¾“å…¥çš„æ ·æœ¬ï¼Œé€šè¿‡inception_v3æ¨¡å‹åçš„ç±»åˆ«è¦å‡è¡¡ï¼Œè¡¡é‡æ¨¡å¼åå¡Œã€‚ 2.æœ€å°åŒ–H(y|x);è¯´æ˜å¯¹äºè¾“å…¥çš„æ ·æœ¬ï¼Œé€šè¿‡inception_v3æ¨¡å‹åé¢„æµ‹æŸç±»åˆ«çš„ç½®ä¿¡åº¦è¦é«˜ï¼Œè¡¡é‡å›¾ç‰‡ç”Ÿæˆçš„è´¨é‡ã€‚\nISç¼ºç‚¹ï¼šå½“åªäº§ç”Ÿä¸€ç§ç‰©ä½“çš„å›¾åƒæ—¶ï¼Œæˆ‘ä»¬ä»ä¼šè®¤ä¸ºè¿™æ˜¯å‡åŒ€åˆ†å¸ƒï¼Œè€Œå¯¼è‡´è¯„ä»·ä¸æ­£ç¡®ã€‚å½“æ¨¡å‹åå¡Œæ—¶ï¼Œç»“æœå°±å¯èƒ½äº§ç”ŸåŒæ ·çš„å›¾ç‰‡ã€‚\n\nFID\n\nåœ¨è®¡ç®—FIDä¸­æˆ‘ä»¬ä¹ŸåŒæ ·ä½¿ç”¨inception networkç½‘ç»œã€‚æˆ‘ä»¬è¿˜æ˜¯å…ˆæ¥ç®€å•å›é¡¾ä¸€ä¸‹ä»€ä¹ˆæ˜¯inception networkï¼Œå®ƒå°±æ˜¯ä¸€ä¸ªç‰¹å¾æå–çš„æ·±åº¦ç½‘ç»œï¼Œæœ€åä¸€å±‚æ˜¯ä¸€ä¸ªpoolingå±‚ï¼Œç„¶åå¯ä»¥è¾“å‡ºä¸€å¼ å›¾åƒçš„ç±»åˆ«ã€‚åœ¨è®¡ç®—FIDæ—¶ï¼Œæˆ‘ä»¬å»æ‰è¿™ä¸ªæœ€åä¸€å±‚poolingå±‚ï¼Œå¾—åˆ°çš„æ˜¯ä¸€ä¸ª2048ç»´çš„é«˜å±‚ç‰¹å¾ï¼Œä»¥ä¸‹ç®€ç§°nç»´ç‰¹å¾ã€‚æˆ‘ä»¬ç»§ç»­ç®€åŒ–ä¸€ä¸‹ï¼Œé‚£ä¹ˆè¿™ä¸ªnç»´ç‰¹å¾æ˜¯ä¸€ä¸ªå‘é‡ã€‚åˆ™æœ‰ï¼šå¯¹äºæˆ‘ä»¬å·²ç»æ‹¥æœ‰çš„çœŸå®å›¾åƒï¼Œè¿™ä¸ªå‘é‡æ˜¯æœä»ä¸€ä¸ªåˆ†å¸ƒçš„ï¼Œï¼ˆæˆ‘ä»¬å¯ä»¥å‡è®¾å®ƒæ˜¯æœä»ä¸€ä¸ªé«˜æ–¯åˆ†å¸ƒï¼‰ï¼›å¯¹äºé‚£äº›ç”¨GANæ¥ç”Ÿæˆçš„nç»´ç‰¹å¾å®ƒä¹Ÿæ˜¯ä¸€ä¸ªåˆ†å¸ƒï¼›æˆ‘ä»¬åº”è¯¥ç«‹é©¬èƒ½å¤ŸçŸ¥é“äº†ï¼ŒGANçš„ç›®æ ‡å°±æ˜¯ä½¿å¾—ä¸¤ä¸ªåˆ†å¸ƒå°½é‡ç›¸åŒã€‚å‡å¦‚ä¸¤ä¸ªåˆ†å¸ƒç›¸åŒï¼Œé‚£ä¹ˆç”Ÿæˆå›¾åƒçš„çœŸå®æ€§å’Œå¤šæ ·æ€§å°±å’Œè®­ç»ƒæ•°æ®ç›¸åŒäº†ã€‚ äºæ˜¯ï¼Œç°åœ¨çš„é—®é¢˜å°±æ˜¯ï¼Œæ€ä¹ˆè®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„è·ç¦»å‘¢ï¼Ÿæˆ‘ä»¬éœ€è¦æ³¨æ„åˆ°è¿™ä¸¤ä¸ªåˆ†å¸ƒæ˜¯å¤šå˜é‡çš„ï¼Œä¹Ÿå°±æ˜¯å‰é¢æåˆ°çš„nç»´ç‰¹å¾ã€‚ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬è®¡ç®—çš„æ˜¯ä¸¤ä¸ªå¤šç»´å˜é‡åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ï¼Œæ•°å­¦ä¸Šå¯ä»¥ç”¨Wasserstein-2 distanceæˆ–è€…Frechet distanceæ¥è¿›è¡Œè®¡ç®—ã€‚ä»¥ä¸‹ç®€å•ä»‹ç»ä¸€ä¸‹å¦‚ä½•è®¡ç®—è¿™ä¸ªè·ç¦»ã€‚\n\n\n\n\n\n\n\n\n\nå‡å¦‚ä¸€ä¸ªéšæœºå˜é‡æœä»é«˜æ–¯åˆ†å¸ƒï¼Œè¿™ä¸ªåˆ†å¸ƒå¯ä»¥ç”¨ä¸€ä¸ªå‡å€¼å’Œæ–¹å·®æ¥ç¡®å®šã€‚é‚£ä¹ˆä¸¤ä¸ªåˆ†å¸ƒåªè¦å‡å€¼å’Œæ–¹å·®ç›¸åŒï¼Œåˆ™ä¸¤ä¸ªåˆ†å¸ƒç›¸åŒã€‚æˆ‘ä»¬å°±åˆ©ç”¨è¿™ä¸ªå‡å€¼å’Œæ–¹å·®æ¥è®¡ç®—è¿™ä¸¤ä¸ªå•å˜é‡é«˜æ–¯åˆ†å¸ƒä¹‹é—´çš„è·ç¦»ã€‚ä½†æˆ‘ä»¬è¿™é‡Œæ˜¯å¤šç»´çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬çŸ¥é“åæ–¹å·®çŸ©é˜µå¯ä»¥ç”¨æ¥è¡¡é‡ä¸¤ä¸ªç»´åº¦ä¹‹é—´çš„ç›¸å…³æ€§ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬ä½¿ç”¨å‡å€¼å’Œåæ–¹å·®çŸ©é˜µæ¥è®¡ç®—ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´çš„è·ç¦»ã€‚å‡å€¼çš„ç»´åº¦å°±æ˜¯å‰é¢nç»´ç‰¹å¾çš„ç»´åº¦ï¼Œä¹Ÿå°±æ˜¯nç»´ï¼›åæ–¹å·®çŸ©é˜µåˆ™æ˜¯n*nçš„çŸ©é˜µã€‚\nFIDå…¬å¼ï¼š \nå…¬å¼ä¸­ï¼ŒTrè¡¨ç¤ºçŸ©é˜µå¯¹è§’çº¿ä¸Šå…ƒç´ çš„æ€»å’Œï¼ŒçŸ©é˜µè®ºä¸­ä¿—ç§°â€œè¿¹â€ï¼ˆtraceï¼‰ã€‚å‡å€¼ä¸ºÎ¼,åæ–¹å·®ä¸ºÎ£ ã€‚æ­¤å¤–xè¡¨ç¤ºçœŸå®çš„å›¾ç‰‡ï¼Œgæ˜¯ç”Ÿæˆçš„å›¾ç‰‡ã€‚ è¾ƒä½çš„FIDæ„å‘³ç€ä¸¤ä¸ªåˆ†å¸ƒä¹‹é—´æ›´æ¥è¿‘ï¼Œä¹Ÿå°±æ„å‘³ç€ç”Ÿæˆå›¾ç‰‡çš„è´¨é‡è¾ƒé«˜ã€å¤šæ ·æ€§è¾ƒå¥½ã€‚ FIDå¯¹æ¨¡å‹åå¡Œæ›´åŠ æ•æ„Ÿã€‚ç›¸æ¯”è¾ƒISæ¥è¯´ï¼ŒFIDå¯¹å™ªå£°æœ‰æ›´å¥½çš„é²æ£’æ€§ã€‚å› ä¸ºå‡å¦‚åªæœ‰ä¸€ç§å›¾ç‰‡æ—¶ï¼ŒFIDè¿™ä¸ªè·ç¦»å°†ä¼šç›¸å½“çš„é«˜ã€‚å› æ­¤ï¼ŒFIDæ›´é€‚åˆæè¿°GANç½‘ç»œçš„å¤šæ ·æ€§ã€‚\n\n\n\n\n\n\n\n\n\nåŒæ ·çš„ï¼ŒFIDå’ŒISéƒ½æ˜¯åŸºäºç‰¹å¾æå–ï¼Œä¹Ÿå°±æ˜¯ä¾èµ–äºæŸäº›ç‰¹å¾çš„å‡ºç°æˆ–è€…ä¸å‡ºç°ã€‚ä½†æ˜¯ä»–ä»¬éƒ½æ— æ³•æè¿°è¿™äº›ç‰¹å¾çš„ç©ºé—´å…³ç³»ã€‚å¦‚ä¸‹å›¾,è¿™é‡Œæˆ‘ä»¬æˆ‘ä»¬äººä¸ä¼šè®¤ä¸ºè¿™æ˜¯ä¸€å¼ å¥½çš„äººè„¸å›¾ç‰‡ã€‚ä½†æ˜¯æ ¹æ®FIDå’ŒISï¼Œä»–ä»¬å°±æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„äººè„¸å›¾ç‰‡ã€‚å› ä¸ºå®ƒæœ‰äººè„¸å¿…è¦çš„ç‰¹å¾ï¼Œè™½ç„¶è¿™äº›ç‰¹å¾çš„ç©ºé—´å…³ç³»ä¸å¥½ã€‚\n\n1.2 å®é™…é—®é¢˜\n\næ ·æœ¬ä¸å‡è¡¡çš„æƒ…å†µä¸‹Accuracyã€ROCå’ŒPRæ›²çº¿çš„å·®åˆ«å’Œè¡¨ç°\n\n\n\nå…¼é¡¾æ­£ä¾‹å’Œè´Ÿä¾‹çš„æƒè¡¡ã€‚å› ä¸ºTPRèšç„¦äºæ­£ä¾‹ï¼ŒFPRèšç„¦äºä¸è´Ÿä¾‹ï¼Œä½¿å…¶æˆä¸ºä¸€ä¸ªæ¯”è¾ƒå‡è¡¡çš„è¯„ä¼°æ–¹æ³•ã€‚\nROCæ›²çº¿é€‰ç”¨çš„ä¸¤ä¸ªæŒ‡æ ‡,éƒ½ä¸ä¾èµ–äºå…·ä½“çš„ç±»åˆ«åˆ†å¸ƒã€‚\n\næ³¨æ„TPRç”¨åˆ°çš„TPå’ŒFNåŒå±Påˆ—ï¼ŒFPRç”¨åˆ°çš„FPå’ŒTNåŒå±Nåˆ—ï¼Œæ‰€ä»¥å³ä½¿Pæˆ–Nçš„æ•´ä½“æ•°é‡å‘ç”Ÿäº†æ”¹å˜ï¼Œä¹Ÿä¸ä¼šå½±å“åˆ°å¦ä¸€åˆ—ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œ**å³ä½¿æ­£ä¾‹ä¸è´Ÿä¾‹çš„æ¯”ä¾‹å‘ç”Ÿäº†å¾ˆå¤§å˜åŒ–ï¼ŒROCæ›²çº¿ä¹Ÿä¸ä¼šäº§ç”Ÿå¤§çš„å˜åŒ–ï¼Œè€ŒåƒPrecisionä½¿ç”¨çš„TPå’ŒFPå°±åˆ†å±ä¸¤åˆ—ï¼Œåˆ™æ˜“å—ç±»åˆ«åˆ†å¸ƒæ”¹å˜çš„å½±å“***ã€‚\nä¸Šé¢æåˆ°ROCæ›²çº¿çš„ä¼˜ç‚¹æ˜¯ä¸ä¼šéšç€ç±»åˆ«åˆ†å¸ƒçš„æ”¹å˜è€Œæ”¹å˜ï¼Œä½†è¿™åœ¨æŸç§ç¨‹åº¦ä¸Šä¹Ÿæ˜¯å…¶ç¼ºç‚¹ã€‚å› ä¸ºè´Ÿä¾‹Nå¢åŠ äº†å¾ˆå¤šï¼Œè€Œæ›²çº¿å´æ²¡å˜ï¼Œè¿™ç­‰äºäº§ç”Ÿäº†å¤§é‡FPã€‚åƒä¿¡æ¯æ£€ç´¢ä¸­å¦‚æœä¸»è¦å…³å¿ƒæ­£ä¾‹çš„é¢„æµ‹å‡†ç¡®æ€§çš„è¯ï¼Œè¿™å°±ä¸å¯æ¥å—äº†ã€‚åœ¨ç±»åˆ«ä¸å¹³è¡¡çš„èƒŒæ™¯ä¸‹ï¼Œè´Ÿä¾‹çš„æ•°ç›®ä¼—å¤šè‡´ä½¿FPRçš„å¢é•¿ä¸æ˜æ˜¾ï¼Œå¯¼è‡´ROCæ›²çº¿å‘ˆç°ä¸€ä¸ªè¿‡åˆ†ä¹è§‚çš„æ•ˆæœä¼°è®¡ã€‚\n\n\n\n\n\n\n\n\n\nTPRè€ƒè™‘çš„æ˜¯ç¬¬ä¸€è¡Œï¼Œå®é™…éƒ½æ˜¯æ­£ä¾‹ï¼ŒFPRè€ƒè™‘çš„æ˜¯ç¬¬äºŒè¡Œï¼Œå®é™…éƒ½æ˜¯è´Ÿä¾‹ã€‚å› æ­¤ï¼Œåœ¨æ­£è´Ÿæ ·æœ¬æ•°é‡ä¸å‡è¡¡çš„æ—¶å€™ï¼Œæ¯”å¦‚è´Ÿæ ·æœ¬çš„æ•°é‡å¢åŠ åˆ°åŸæ¥çš„10å€ï¼Œé‚£TPRä¸å—å½±å“ï¼ŒFPRçš„å„é¡¹ä¹Ÿæ˜¯æˆæ¯”ä¾‹çš„å¢åŠ ï¼Œå¹¶ä¸ä¼šæœ‰å¤ªå¤§çš„å˜åŒ–ã€‚å› æ­¤ï¼Œåœ¨æ ·æœ¬ä¸å‡è¡¡çš„æƒ…å†µä¸‹ï¼ŒåŒæ ·ROCæ›²çº¿ä»ç„¶èƒ½è¾ƒå¥½åœ°è¯„ä»·åˆ†ç±»å™¨çš„æ€§èƒ½ï¼Œè¿™æ˜¯ROCçš„ä¸€ä¸ªä¼˜è‰¯ç‰¹æ€§ï¼Œä¹Ÿæ˜¯ä¸ºä»€ä¹ˆä¸€èˆ¬ROCæ›²çº¿ä½¿ç”¨æ›´å¤šçš„åŸå› ã€‚\n\n\n\n\n\n\n\n\n\nROCæ›²çº¿å’ŒPRæ›²çº¿çš„åŒºåˆ« 1.å½“æ­£è´ŸåŸæœ¬æ•°é‡æ¯”è¾ƒå‡è¡¡çš„æ—¶å€™ï¼Œä¸¤è€…å·®åˆ«ä¸å¤§ï¼Œå½“æ•°é‡æ¯”ä¾‹å¤±è¡¡æ—¶ï¼ŒROCæ›²çº¿ä¸å¦‚PRæ›²çº¿èƒ½æ›´å¥½çš„åæ˜ å‡ºåˆ†ç±»å™¨çš„çœŸå®æ€§èƒ½ï¼Œé€šè¿‡PRæ›²çº¿çš„æŸ¥å‡†ç‡æŒ‡æ ‡åæ˜ å‡ºæ¥ã€‚ 2.PRæ›²çº¿æ¯”ROCæ›²çº¿æ›´å…³æ³¨æ­£æ ·æœ¬ï¼ŒROCæ›²çº¿å…¼é¡¾äº†ä¸¤è€…ã€‚\n\n\n\n\n\n\n\n\n\nå¯¹äºæ­£è´Ÿæ ·æœ¬æ•°é‡æä¸å‡è¡¡çš„æƒ…å†µï¼Œåªé€šè¿‡å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰å¾€å¾€éš¾ä»¥åæ˜ ç³»ç»Ÿçš„çœŸå®æ€§èƒ½ã€‚ ä¸¾ä¾‹è¯´æ˜ï¼Œå¯¹äºä¸€ä¸ªåœ°éœ‡é¢„æµ‹ç³»ç»Ÿï¼Œå‡è®¾æ‰€æœ‰æ ·æœ¬ä¸­ï¼Œ1000å¤©ä¸­æœ‰1å¤©å‘ç”Ÿåœ°éœ‡ï¼Œè®°ï¼š0ï¼šä¸åœ°éœ‡ï¼Œ1ï¼šåœ°éœ‡ï¼Œåˆ†ç±»å™¨ä¸å‡æ€ç´¢çš„å°†æ‰€æœ‰æ ·æœ¬åˆ†ç±»ä¸º0ï¼Œå³å¯å¾—åˆ°99.99%çš„å‡†ç¡®ç‡ï¼Œå½“åœ°éœ‡çœŸæ­£æ¥ä¸´æ—¶ï¼Œå¹¶ä¸èƒ½æˆåŠŸé¢„æµ‹ï¼Œè¿™ç§ç»“æœæ˜¯æˆ‘ä»¬ä¸èƒ½æ¥å—çš„ã€‚\n\nä¸€å¥è¯è¯´æ˜AUCçš„æœ¬è´¨å’Œè®¡ç®—è§„åˆ™\n\næœ¬è´¨ï¼šä¸€ä¸ªæ­£ä¾‹ï¼Œä¸€ä¸ªè´Ÿä¾‹ï¼Œé¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¦‚ç‡å€¼å¤§äºé¢„æµ‹ä¸ºè´Ÿçš„æ¦‚ç‡å€¼çš„å¯èƒ½æ€§ï¼› è®¡ç®—è§„åˆ™ï¼šROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼š\n\nAUCé«˜å¯ä»¥ç†è§£ä¸ºç²¾ç¡®ç‡é«˜å—ï¼Ÿ\n\nä¸å¯ä»¥ï¼Œç²¾ç¡®ç‡æ˜¯åŸºäºæŸä¸ªé˜ˆå€¼è¿›è¡Œè®¡ç®—çš„ï¼ŒAUCæ˜¯åŸºäºæ‰€æœ‰å¯èƒ½çš„é˜ˆå€¼è¿›è¡Œè®¡ç®—çš„ï¼Œå…·æœ‰æ›´é«˜çš„å¥å£®æ€§ã€‚AUCä¸å…³æ³¨æŸä¸ªé˜ˆå€¼ä¸‹çš„è¡¨ç°å¦‚ä½•ï¼Œç»¼åˆæ‰€æœ‰é˜ˆå€¼çš„é¢„æµ‹æ€§èƒ½ï¼Œæ‰€ä»¥ç²¾ç¡®ç‡é«˜ï¼ŒAUCä¸ä¸€å®šå¤§ï¼Œåä¹‹äº¦ç„¶ã€‚\n\nåŒæ—¶å¢å¤§æˆ–å‡å°æ ·æœ¬çš„é¢„æµ‹æ¦‚ç‡ï¼Œä¼šå¯¹AUCäº§ç”Ÿä»€ä¹ˆå½±å“ï¼Ÿ æ²¡å½±å“ï¼Œå› ä¸ºæ˜¯åŒæ—¶å¢å¤§ï¼ŒAUCæœ¬è´¨æ˜¯é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ¦‚ç‡å€¼å¤§äºé¢„æµ‹ä¸ºè´Ÿçš„æ¦‚ç‡å€¼çš„å¯èƒ½æ€§ã€‚\n\n2. CNNåŸºç¡€çŸ¥è¯†\n2.1 å·ç§¯\n\n\n\n\n\n\n\n\n\næ‰€è°“ä¸¤ä¸ªå‡½æ•°çš„å·ç§¯ï¼Œæœ¬è´¨ä¸Šå°±æ˜¯å…ˆå°†ä¸€ä¸ªå‡½æ•°ç¿»è½¬ï¼Œç„¶åè¿›è¡Œæ»‘åŠ¨å åŠ ã€‚\nå¯¹å·ç§¯çš„æ„ä¹‰çš„ç†è§£ï¼š 1. ä»â€œç§¯â€çš„è¿‡ç¨‹å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å¾—åˆ°çš„å åŠ å€¼ï¼Œæ˜¯ä¸ªå…¨å±€çš„æ¦‚å¿µã€‚ä»¥ä¿¡å·åˆ†æä¸ºä¾‹ï¼Œå·ç§¯çš„ç»“æœæ˜¯ä¸ä»…è·Ÿå½“å‰æ—¶åˆ»è¾“å…¥ä¿¡å·çš„å“åº”å€¼æœ‰å…³ï¼Œä¹Ÿè·Ÿè¿‡å»æ‰€æœ‰æ—¶åˆ»è¾“å…¥ä¿¡å·çš„å“åº”éƒ½æœ‰å…³ç³»ï¼Œè€ƒè™‘äº†å¯¹è¿‡å»çš„æ‰€æœ‰è¾“å…¥çš„æ•ˆæœçš„ç´¯ç§¯ã€‚åœ¨å›¾åƒå¤„ç†çš„ä¸­ï¼Œå·ç§¯å¤„ç†çš„ç»“æœï¼Œå…¶å®å°±æ˜¯æŠŠæ¯ä¸ªåƒç´ å‘¨è¾¹çš„ï¼Œç”šè‡³æ˜¯æ•´ä¸ªå›¾åƒçš„åƒç´ éƒ½è€ƒè™‘è¿›æ¥ï¼Œå¯¹å½“å‰åƒç´ è¿›è¡ŒæŸç§åŠ æƒå¤„ç†ã€‚æ‰€ä»¥è¯´ï¼Œâ€œç§¯â€æ˜¯å…¨å±€æ¦‚å¿µï¼Œæˆ–è€…è¯´æ˜¯ä¸€ç§â€œæ··åˆâ€ï¼ŒæŠŠä¸¤ä¸ªå‡½æ•°åœ¨æ—¶é—´æˆ–è€…ç©ºé—´ä¸Šè¿›è¡Œæ··åˆã€‚ 2. é‚£ä¸ºä»€ä¹ˆè¦è¿›è¡Œâ€œå·â€ï¼Ÿç›´æ¥ç›¸ä¹˜ä¸å¥½å—ï¼Ÿæˆ‘çš„ç†è§£ï¼Œè¿›è¡Œâ€œå·â€ï¼ˆç¿»è½¬ï¼‰çš„ç›®çš„å…¶å®æ˜¯æ–½åŠ ä¸€ç§çº¦æŸï¼Œå®ƒæŒ‡å®šäº†åœ¨â€œç§¯â€çš„æ—¶å€™ä»¥ä»€ä¹ˆä¸ºå‚ç…§ã€‚åœ¨ä¿¡å·åˆ†æçš„åœºæ™¯ï¼Œå®ƒæŒ‡å®šäº†åœ¨å“ªä¸ªç‰¹å®šæ—¶é—´ç‚¹çš„å‰åè¿›è¡Œâ€œç§¯â€ï¼Œåœ¨ç©ºé—´åˆ†æçš„åœºæ™¯ï¼Œå®ƒæŒ‡å®šäº†åœ¨å“ªä¸ªä½ç½®çš„å‘¨è¾¹è¿›è¡Œç´¯ç§¯å¤„ç†ã€‚\nå·ç§¯æ—¶é—´å¤æ‚åº¦ =  kæ˜¯kenerlçš„å°ºå¯¸ï¼Œmæ˜¯è¾“å‡ºçš„ä¸‹ä¸€å±‚çš„feature mapçš„å°ºå¯¸.\nåº•å±‚å®ç°: ä¸»è¦ç”¨çš„å°±æ˜¯çŸ©é˜µç›¸ä¹˜ï¼Œä¹Ÿå°±æ˜¯GEMMã€‚å…ˆç”¨ä¸€ä¸ªå«im2colçš„å‡½æ•°æŠŠå›¾åƒè½¬æˆçŸ©é˜µï¼Œç„¶åå’Œå·ç§¯æ ¸åšçŸ©é˜µä¹˜æ³•ã€‚å‚è€ƒ\næ„Ÿå—é‡è®¡ç®—: \n\nå¢å¤§æ„Ÿå—é‡çš„æ–¹æ³•: pooling æ± åŒ–: æ± åŒ–ä¸»è¦ä»»åŠ¡æ˜¯å¯¹æ•°æ®é™ç»´ï¼Œå‡å°ç½‘ç»œå‚æ•°ï¼Œæå‡ç½‘ç»œçš„è®¡ç®—æ•ˆç‡ï¼ŒåŒæ—¶ï¼Œæ± åŒ–ä¹Ÿæ˜¯å¢åŠ æ„Ÿå—é‡çš„æ–¹æ³•ä¹‹ä¸€ï¼Œä½†åœ¨å¢åŠ æ„Ÿå—é‡çš„åŒæ—¶ï¼Œä¼´éšç€åˆ†è¾¨ç‡çš„é™ä½ï¼Œå›¾åƒç»†èŠ‚æŸå¤± dilated convç©ºæ´å·ç§¯: ç©ºæ´å·ç§¯çš„å‡ºç°ä¸ºäº†è§£å†³poolingå±‚å¢å¤§æ„Ÿå—é‡ä¹‹åè¿›è¡Œä¸Šé‡‡æ ·ï¼ˆå¢åŠ å›¾åƒçš„åˆ†è¾¨ç‡ï¼‰è¿‡ç¨‹ä¸­ï¼Œå›¾åƒä¿¡æ¯ç¼ºå¤±é—®é¢˜ã€‚\n1x3ã€3x1ä»£æ›¿3x3å·ç§¯: &gt; å„å‘åŒæ€§çš„æ˜¯å¯ä»¥çš„ï¼Œå‚è€ƒé«˜æ–¯æ»¤æ³¢ï¼Œä½†æ˜¯æ·±åº¦å­¦ä¹ é‡Œé¢çš„å·ç§¯æ ¸ä¸å¤ªå¯èƒ½å„å‘åŒæ€§\nif a 2D kernel has a rank of one, the operation can be equivalently transformed into a series of 1D convolutions\nBut 1. However, as the learned kernels in deep networks have distributed eigenvalues, their intrinsic rank is higher than one in practice, thus applying the transformation directly to the kernels results in signifificant information lossã€‚ 2. However, the authors found out that such replacement is not equivalent as it did not work well on the low-level layers\nå‚è€ƒè®ºæ–‡\nåŠ é€Ÿ:\nWinogradå¿«é€Ÿå·ç§¯ç®—æ³•\n2.2 åå·ç§¯/è½¬ç½®å·ç§¯/sub-pixel\nè§£é‡Š\nè½¬ç½®å·ç§¯çš„è®¡ç®—:\nè¾“å…¥å±‚ï¼š\nè¶…å‚æ•°ï¼š\nè¿‡æ»¤å™¨ä¸ªæ•°ï¼šk è¿‡æ»¤å™¨ä¸­å·ç§¯æ ¸ç»´åº¦ï¼šw*h æ»‘åŠ¨æ­¥é•¿ï¼ˆStrideï¼‰ï¼šs å¡«å……å€¼ï¼ˆPaddingï¼‰ï¼šp è¾“å‡ºå±‚ï¼š\nï¼ˆä¸ºç®€åŒ–è®¡ç®—ï¼Œè®¾ï¼Œåˆ™è®°\nå…¶ä¸­è¾“å‡ºå±‚å’Œè¾“å…¥å±‚ä¹‹é—´çš„å‚æ•°å…³ç³»åˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š\næƒ…å†µä¸€ï¼š(in-1) * s -2p + k = out\n\næƒ…å†µäºŒï¼š(in-1) * s -2p + k != out\n\næ£‹ç›˜æ•ˆåº”\nçŸ¥ä¹ï¼šRedflashing åœ¨ä½¿ç”¨è½¬ç½®å·ç§¯æ—¶è§‚å¯Ÿåˆ°ä¸€ä¸ªæ£˜æ‰‹çš„ç°è±¡ï¼ˆå°¤å…¶æ˜¯æ·±è‰²éƒ¨åˆ†å¸¸å‡ºç°ï¼‰å°±æ˜¯\"æ£‹ç›˜æ ¼å­çŠ¶ä¼ªå½±\"ï¼Œè¢«å‘½åä¸ºæ£‹ç›˜æ•ˆåº”ï¼ˆCheckboard artifactsï¼‰ã€‚\n\næ£‹ç›˜æ•ˆåº”æ˜¯ç”±äºè½¬ç½®å·ç§¯çš„â€œä¸å‡åŒ€é‡å â€ï¼ˆUneven overlapï¼‰çš„ç»“æœã€‚ä½¿å›¾åƒä¸­æŸä¸ªéƒ¨ä½çš„é¢œè‰²æ¯”å…¶ä»–éƒ¨ä½æ›´æ·±ã€‚å°¤å…¶æ˜¯å½“å·ç§¯æ ¸ï¼ˆKernelï¼‰çš„å¤§å°ä¸èƒ½è¢«æ­¥é•¿ï¼ˆStrideï¼‰æ•´é™¤æ—¶ï¼Œåå·ç§¯å°±ä¼šä¸å‡åŒ€é‡å ã€‚è™½ç„¶åŸåˆ™ä¸Šç½‘ç»œå¯ä»¥é€šè¿‡è®­ç»ƒè°ƒæ•´æƒé‡æ¥é¿å…è¿™ç§æƒ…å†µï¼Œä½†åœ¨å®è·µä¸­ç¥ç»ç½‘ç»œå¾ˆéš¾å®Œå…¨é¿å…è¿™ç§ä¸å‡åŒ€é‡å ã€‚ â€‹ä¸‹é¢é€šè¿‡ä¸€ä¸ªè¯¦ç»†çš„ä¾‹å­ï¼Œæ›´ä¸ºç›´è§‚å±•ç¤ºæ£‹ç›˜æ•ˆåº”ã€‚ä¸‹å›¾çš„é¡¶éƒ¨éƒ¨åˆ†æ˜¯è¾“å…¥å±‚ï¼Œåº•éƒ¨éƒ¨åˆ†ä¸ºè½¬ç½®å·ç§¯è¾“å‡ºç»“æœã€‚ç»“æœè½¬ç½®å·ç§¯æ“ä½œï¼Œå°å°ºå¯¸çš„è¾“å…¥æ˜ å°„åˆ°è¾ƒå¤§å°ºå¯¸çš„è¾“å‡ºï¼ˆä½“ç°åœ¨é•¿å’Œå®½ç»´åº¦ï¼‰ã€‚ åœ¨ï¼ˆaï¼‰ä¸­ï¼Œæ­¥é•¿ä¸º1ï¼Œå·ç§¯æ ¸ä¸º2*2ã€‚å¦‚çº¢è‰²éƒ¨åˆ†æ‰€å±•ç¤ºï¼Œè¾“å…¥ç¬¬ä¸€ä¸ªåƒç´ æ˜ å°„åˆ°è¾“å‡ºä¸Šç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªåƒç´ ã€‚è€Œæ­£å¦‚ç»¿è‰²éƒ¨åˆ†ï¼Œè¾“å…¥çš„ç¬¬äºŒä¸ªåƒç´ æ˜ å°„åˆ°è¾“å‡ºä¸Šçš„ç¬¬äºŒä¸ªå’Œç¬¬ä¸‰ä¸ªåƒç´ ã€‚åˆ™è¾“å‡ºä¸Šçš„ç¬¬äºŒä¸ªåƒç´ ä»è¾“å…¥ä¸Šçš„ç¬¬ä¸€ä¸ªå’Œç¬¬äºŒä¸ªåƒç´ æ¥æ”¶ä¿¡æ¯ã€‚æ€»è€Œè¨€ä¹‹ï¼Œè¾“å‡ºä¸­é—´éƒ¨åˆ†çš„åƒç´ ä»è¾“å…¥ä¸­æ¥æ”¶çš„ä¿¡æ¯å­˜åœ¨é‡å åŒºåŸŸã€‚åœ¨ç¤ºä¾‹ï¼ˆbï¼‰ä¸­çš„å·ç§¯æ ¸å¤§å°å¢åŠ åˆ°3æ—¶ï¼Œè¾“å‡ºæ‰€æ¥æ”¶åˆ°çš„å¤§å¤šæ•°ä¿¡æ¯çš„ä¸­å¿ƒéƒ¨åˆ†å°†æ”¶ç¼©ã€‚ä½†è¿™å¹¶ä¸æ˜¯æœ€å¤§çš„é—®é¢˜ï¼Œå› ä¸ºé‡å ä»ç„¶æ˜¯å‡åŒ€çš„ã€‚\n\nå¦‚æœå°†æ­¥å¹…æ”¹ä¸º2ï¼Œåœ¨å·ç§¯æ ¸å¤§å°ä¸º2çš„ç¤ºä¾‹ä¸­ï¼Œè¾“å‡ºä¸Šçš„æ‰€æœ‰åƒç´ ä»è¾“å…¥ä¸­æ¥æ”¶ç›¸åŒæ•°é‡çš„ä¿¡æ¯ã€‚ç”±ä¸‹å›¾ï¼ˆaï¼‰å¯è§ï¼Œæ­¤æ—¶æä»¥è½¬ç½®å·ç§¯çš„é‡å ã€‚è‹¥å°†å·ç§¯æ ¸å¤§å°æ”¹ä¸º4ï¼ˆä¸‹å›¾ï¼ˆbï¼‰ï¼‰ï¼Œåˆ™å‡åŒ€é‡å åŒºåŸŸå°†æ”¶ç¼©ï¼Œä¸æ­¤åŒæ—¶å› ä¸ºé‡å æ˜¯å‡åŒ€çš„ï¼Œæ•…ä»ç„¶ä¸ºæœ‰æ•ˆè¾“å‡ºã€‚ä½†å¦‚æœå°†å·ç§¯æ ¸å¤§å°æ”¹ä¸º3ï¼Œæ­¥é•¿ä¸º2ï¼ˆä¸‹å›¾ï¼ˆcï¼‰ï¼‰ï¼Œä»¥åŠå°†å·ç§¯æ ¸å¤§å°æ”¹ä¸º5ï¼Œæ­¥é•¿ä¸º2ï¼ˆä¸‹å›¾ï¼ˆdï¼‰ï¼‰ï¼Œé—®é¢˜å°±å‡ºç°äº†ï¼Œå¯¹äºè¿™ä¸¤ç§æƒ…å†µè¾“å‡ºä¸Šçš„æ¯ä¸ªåƒç´ æ¥æ”¶çš„ä¿¡æ¯é‡ä¸ç›¸é‚»åƒç´ ä¸åŒã€‚åœ¨è¾“å‡ºä¸Šæ‰¾ä¸åˆ°è¿ç»­ä¸”å‡åŒ€é‡å åŒºåŸŸã€‚\n\nåœ¨äºŒç»´æƒ…å†µä¸‹æ£‹ç›˜æ•ˆåº”æ›´ä¸ºä¸¥é‡ï¼Œä¸‹å›¾ç›´è§‚åœ°å±•ç¤ºäº†åœ¨äºŒç»´ç©ºé—´å†…çš„æ£‹ç›˜æ•ˆåº”ã€‚\n\nå¦‚ä½•é¿å…æ£‹ç›˜æ•ˆåº”\n\né‡‡å–å¯ä»¥è¢«æ­¥é•¿æ•´é™¤çš„å·ç§¯æ ¸é•¿åº¦ è¯¥æ–¹æ³•è¾ƒå¥½åœ°åº”å¯¹äº†æ£‹ç›˜æ•ˆåº”é—®é¢˜ï¼Œä½†ä»ç„¶ä¸å¤Ÿåœ†æ»¡ï¼Œå› ä¸ºä¸€æ—¦æˆ‘ä»¬çš„å·ç§¯æ ¸å­¦ä¹ ä¸å‡åŒ€ï¼Œä¾æ—§ä¼šäº§ç”Ÿæ£‹ç›˜æ•ˆåº”ï¼ˆå¦‚ä¸‹å›¾æ‰€ç¤ºï¼‰\n\n\n\næ’å€¼ å¯ä»¥ç›´æ¥è¿›è¡Œæ’å€¼Resizeæ“ä½œï¼Œç„¶åå†è¿›è¡Œå·ç§¯æ“ä½œã€‚è¯¥æ–¹å¼åœ¨è¶…åˆ†è¾¨ç‡çš„ç›¸å…³è®ºæ–‡ä¸­æ¯”è¾ƒå¸¸è§ã€‚ä¾‹å¦‚æˆ‘ä»¬å¯ä»¥ç”¨å¸¸è§çš„å›¾å½¢å­¦ä¸­å¸¸ç”¨çš„åŒçº¿æ€§æ’å€¼å’Œè¿‘é‚»æ’å€¼ä»¥åŠæ ·æ¡æ’å€¼æ¥è¿›è¡Œä¸Šé‡‡æ ·ã€‚\n\n\n2.3 ç©ºæ´å·ç§¯/æ‰©å¼ å·ç§¯/è†¨èƒ€å·ç§¯\nçŸ¥ä¹ï¼šä»£è¾° ç©ºæ´å·ç§¯ï¼ˆAtrous Convolutionï¼‰ï¼Œå‘å·ç§¯å±‚å¼•å…¥äº†ä¸€ä¸ªç§°ä¸ºâ€œæ‰©å¼ ç‡(dilation rate)â€çš„æ–°å‚æ•°ï¼Œè¯¥å‚æ•°å®šä¹‰äº†å·ç§¯æ ¸å¤„ç†æ•°æ®æ—¶å„å€¼çš„é—´è·ã€‚æ¢å¥è¯è¯´ï¼Œç›¸æ¯”åŸæ¥çš„æ ‡å‡†å·ç§¯ï¼Œæ‰©å¼ å·ç§¯å¤šäº†ä¸€ä¸ªè¶…å‚æ•°ç§°ä¹‹ä¸ºdilation rateï¼ˆæ‰©å¼ ç‡ï¼‰ï¼ŒæŒ‡çš„æ˜¯kernelå„ç‚¹ä¹‹é—´çš„é—´éš”æ•°é‡ï¼Œæ­£å¸¸çš„å·ç§¯æ ¸çš„æ‰©å¼ ç‡ä¸º1ã€‚\n\nä¸Šå›¾æ˜¯ä¸€ä¸ªæ‰©å¼ ç‡ä¸º2ï¼Œå°ºå¯¸ä¸º 3Ã—3 çš„ç©ºæ´å·ç§¯ï¼Œæ„Ÿå—é‡ä¸5Ã—5çš„å·ç§¯æ ¸ç›¸åŒï¼Œè€Œä¸”ä»…éœ€è¦9ä¸ªå‚æ•°ã€‚åœ¨ç›¸åŒçš„è®¡ç®—æ¡ä»¶ä¸‹ï¼Œç©ºæ´å·ç§¯æä¾›äº†æ›´å¤§çš„æ„Ÿå—é‡ã€‚å½“ç½‘ç»œå±‚éœ€è¦è¾ƒå¤§çš„æ„Ÿå—é‡ï¼Œä½†è®¡ç®—èµ„æºæœ‰é™è€Œæ— æ³•æé«˜å·ç§¯æ ¸æ•°é‡æˆ–å¤§å°æ—¶ï¼Œå¯ä»¥è€ƒè™‘ç©ºæ´å·ç§¯ã€‚\n\n\n\n\n\n\n\n\n\nç©ºæ´å·ç§¯ä¸»è¦æœ‰ä¸¤æ–¹é¢çš„ä½œç”¨ï¼š 1.æ‰©å¤§æ„Ÿå—é‡åœ¨æ·±åº¦å­¦ä¹ ç½‘ç»œä¸­ä¸ºäº†å¢åŠ æ„Ÿå—é‡ä¸”é™ä½è®¡ç®—é‡ï¼Œæ€»è¦è¿›è¡Œé™é‡‡æ ·(poolingæˆ–conv)ï¼Œè¿™æ ·è™½ç„¶å¯ä»¥å¢åŠ æ„Ÿå—é‡ï¼Œä½†ç©ºé—´åˆ†è¾¨ç‡é™ä½äº†ã€‚ä¸ºäº†èƒ½ä¸ä¸¢å¤±åˆ†è¾¨ç‡ï¼Œä¸”ä»ç„¶æ‰©å¤§æ„Ÿå—é‡ï¼Œå¯ä»¥ä½¿ç”¨ç©ºæ´å·ç§¯ã€‚è¿™åœ¨æ£€æµ‹ï¼Œåˆ†å‰²ä»»åŠ¡ä¸­ååˆ†æœ‰ç”¨ã€‚ä¸€æ–¹é¢æ„Ÿå—é‡å¤§äº†å¯ä»¥æ£€æµ‹åˆ†å‰²å¤§ç›®æ ‡ï¼Œå¦ä¸€æ–¹é¢åˆ†è¾¨ç‡é«˜äº†å¯ä»¥ç²¾ç¡®å®šä½ç›®æ ‡ã€‚ 2.æ•è·å¤šå°ºåº¦ä¸Šä¸‹æ–‡ä¿¡æ¯ç©ºæ´å·ç§¯æœ‰ä¸€ä¸ªå‚æ•°å¯ä»¥è®¾ç½®dilation rateï¼Œå…·ä½“å«ä¹‰å°±æ˜¯åœ¨å·ç§¯æ ¸ä¸­å¡«å……dilation rate-1ä¸ª0ï¼Œå› æ­¤ï¼Œå½“è®¾ç½®ä¸åŒdilation rateæ—¶ï¼Œæ„Ÿå—é‡å°±ä¼šä¸ä¸€æ ·ï¼Œä¹Ÿå³è·å–äº†å¤šå°ºåº¦ä¿¡æ¯ã€‚å¤šå°ºåº¦ä¿¡æ¯åœ¨è§†è§‰ä»»åŠ¡ä¸­ç›¸å½“é‡è¦å•Šã€‚DeepLabä¸­çš„ASPPæ¨¡å— ä»è¿™é‡Œå¯ä»¥çœ‹å‡ºï¼Œç©ºæ´å·ç§¯å¯ä»¥ä»»æ„æ‰©å¤§æ„Ÿå—é‡ï¼Œä¸”ä¸éœ€è¦å¼•å…¥é¢å¤–å‚æ•°ï¼Œä½†å¦‚æœæŠŠåˆ†è¾¨ç‡å¢åŠ äº†ï¼Œç®—æ³•æ•´ä½“è®¡ç®—é‡è‚¯å®šä¼šå¢åŠ ã€‚\n\n\n\n\n\n\n\n\n\nç©ºæ´å·ç§¯è™½ç„¶æœ‰è¿™ä¹ˆå¤šä¼˜ç‚¹ï¼Œä½†åœ¨å®é™…ä¸­ä¸å¥½ä¼˜åŒ–ï¼Œé€Ÿåº¦ä¼šå¤§å¤§æŠ˜æ‰£ã€‚\nç©ºæ´å·ç§¯å­˜åœ¨çš„é—®é¢˜:\nç©ºæ´å·ç§¯æ˜¯å­˜åœ¨ç†è®ºé—®é¢˜çš„ï¼Œè®ºæ–‡ä¸­ç§°ä¸ºgriddingï¼Œå…¶å®å°±æ˜¯ç½‘æ ¼æ•ˆåº”/æ£‹ç›˜é—®é¢˜ã€‚å› ä¸ºç©ºæ´å·ç§¯å¾—åˆ°çš„æŸä¸€å±‚çš„ç»“æœä¸­ï¼Œé‚»è¿‘çš„åƒç´ æ˜¯ä»ç›¸äº’ç‹¬ç«‹çš„å­é›†ä¸­å·ç§¯å¾—åˆ°çš„ï¼Œç›¸äº’ä¹‹é—´ç¼ºå°‘ä¾èµ–ã€‚\n\nå±€éƒ¨ä¿¡æ¯ä¸¢å¤±ï¼š ç”±äºç©ºæ´å·ç§¯çš„è®¡ç®—æ–¹å¼ç±»ä¼¼äºæ£‹ç›˜æ ¼å¼ï¼ŒæŸä¸€å±‚å¾—åˆ°çš„å·ç§¯ç»“æœï¼Œæ¥è‡ªä¸Šä¸€å±‚çš„ç‹¬ç«‹çš„é›†åˆï¼Œæ²¡æœ‰ç›¸äº’ä¾èµ–ï¼Œå› æ­¤è¯¥å±‚çš„å·ç§¯ç»“æœä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ï¼Œå³å±€éƒ¨ä¿¡æ¯ä¸¢å¤±ã€‚\nè¿œè·ç¦»è·å–çš„ä¿¡æ¯æ²¡æœ‰ç›¸å…³æ€§ï¼š ç”±äºç©ºæ´å·ç§¯ç¨€ç–çš„é‡‡æ ·è¾“å…¥ä¿¡å·ï¼Œä½¿å¾—è¿œè·ç¦»å·ç§¯å¾—åˆ°çš„ä¿¡æ¯ä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ï¼Œå½±å“åˆ†ç±»ç»“æœã€‚\n\n(è§£å†³æ–¹æ³•ï¼š)[https://zhuanlan.zhihu.com/p/50369448] 1. Removing max poolingï¼šç”±äºmaxpoolä¼šå¼•å…¥æ›´é«˜é¢‘çš„æ¿€æ´»ï¼Œè¿™æ ·çš„æ¿€æ´»ä¼šéšç€å·ç§¯å±‚å¾€åä¼ æ’­ï¼Œä½¿å¾—gridé—®é¢˜æ›´æ˜æ˜¾ã€‚ 2. Adding layersï¼šåœ¨ç½‘ç»œæœ€åå¢åŠ æ›´å°ç©ºæ´ç‡çš„æ®‹å‚block, æœ‰ç‚¹ç±»ä¼¼äºHDCã€‚ 3. Removing residual connectionsï¼šå»æ‰æ®‹å‚è¿æ¥ï¼Œé˜²æ­¢ä¹‹å‰å±‚çš„é«˜é¢‘ä¿¡å·å¾€åä¼ æ’­ã€‚\n\n\n\n\n\n\n\n\n\næ€»ç»“ï¼šç®€å•æ¥è¯´ï¼Œå°±æ˜¯ç©ºæ´å·ç§¯è™½ç„¶åœ¨å‚æ•°ä¸å˜çš„æƒ…å†µä¸‹ä¿è¯äº†æ›´å¤§çš„æ„Ÿå—é‡ï¼Œä½†æ˜¯å¯¹äºä¸€äº›å¾ˆå°çš„ç‰©ä½“ï¼Œæœ¬èº«å°±ä¸è¦é‚£ä¹ˆå¤§çš„æ„Ÿå—é‡æ¥è¯´ï¼Œè¿™æ˜¯ä¸å‹å¥½çš„ã€‚\nç©ºæ´å·ç§¯æ„Ÿå—é‡å¦‚ä½•è®¡ç®—\n\n\n\n\n\n\n\n\n\nå’Œæ ‡å‡†å·ç§¯æ˜¯ä¸€è‡´çš„ ç©ºæ´å·ç§¯å®é™…å·ç§¯æ ¸å¤§å°ï¼šK=k+(k-1)(r-1)ï¼Œkä¸ºåŸå§‹å·ç§¯æ ¸å¤§å°ï¼Œrä¸ºç©ºæ´å·ç§¯å‚æ•°ç©ºæ´ç‡ï¼›\nä»¥ä¸‰ä¸ªr=2çš„3*3/s1ç©ºæ´å·ç§¯ä¸ºä¾‹è®¡ç®—æ„Ÿå—é‡ï¼š\nK=k+(k-1)(r-1)=3+2*1=5\nR=1+4+4+4=13\n\n\n\n\n\n\n\n\n\nç›¸å½“äºä¸‰ä¸ªkernel size=5çš„å·ç§¯æ ¸ä¸²è”ï¼Œå¦‚æœæ­¥é•¿è®¾ç½®ä¸º1çš„è¯ï¼Œæ¯ä¸¤å±‚çš„å°ºå¯¸å…³ç³»ä¸ºX0-5+1=X1,ä¹Ÿå°±æ˜¯X0-4=X1,å› æ­¤å¯ä»¥å¾—åˆ°é€šé¡¹å…¬å¼ï¼ŒX0=Xi+i*4ã€‚å› æ­¤å¯¹äºä¸‰ä¸ªå·ç§¯æ ¸æœ‰å››ä¸ªå±‚ï¼Œå¯¹åº”i=3ï¼ŒX3=1,æ‰€ä»¥æ˜¯13\n2.4 depthwiseå·ç§¯\n\n\nå¸¸è§„å·ç§¯(æ¥æºè§æ°´å°)\n\nDepthwise Convolutionçš„ä¸€ä¸ªå·ç§¯æ ¸è´Ÿè´£ä¸€ä¸ªé€šé“ï¼Œä¸€ä¸ªé€šé“åªè¢«ä¸€ä¸ªå·ç§¯æ ¸å·ç§¯ã€‚å¸¸è§„å·ç§¯æ¯ä¸ªå·ç§¯æ ¸æ˜¯åŒæ—¶æ“ä½œè¾“å…¥å›¾ç‰‡çš„æ¯ä¸ªé€šé“ã€‚\nåŒæ ·æ˜¯å¯¹äºä¸€å¼ 5Ã—5åƒç´ ã€ä¸‰é€šé“å½©è‰²è¾“å…¥å›¾ç‰‡ï¼ˆshapeä¸º5Ã—5Ã—3ï¼‰ï¼ŒDepthwise Convolutioné¦–å…ˆç»è¿‡ç¬¬ä¸€æ¬¡å·ç§¯è¿ç®—ï¼Œä¸åŒäºä¸Šé¢çš„å¸¸è§„å·ç§¯ï¼ŒDWå®Œå…¨æ˜¯åœ¨äºŒç»´å¹³é¢å†…è¿›è¡Œã€‚å·ç§¯æ ¸çš„æ•°é‡ä¸ä¸Šä¸€å±‚çš„é€šé“æ•°ç›¸åŒï¼ˆé€šé“å’Œå·ç§¯æ ¸ä¸€ä¸€å¯¹åº”ï¼‰ã€‚æ‰€ä»¥ä¸€ä¸ªä¸‰é€šé“çš„å›¾åƒç»è¿‡è¿ç®—åç”Ÿæˆäº†3ä¸ªFeature map(å¦‚æœæœ‰same paddingåˆ™å°ºå¯¸ä¸è¾“å…¥å±‚ç›¸åŒä¸º5Ã—5)ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n\n\ndepthwiseå·ç§¯(æ¥æºè§æ°´å°)\n\nå…¶ä¸­ä¸€ä¸ªFilteråªåŒ…å«ä¸€ä¸ªå¤§å°ä¸º3Ã—3çš„Kernelï¼Œå·ç§¯éƒ¨åˆ†çš„å‚æ•°ä¸ªæ•°è®¡ç®—å¦‚ä¸‹ï¼š N_depthwise = 3 Ã— 3 Ã— 3 = 27\n\n\n\n\n\n\n\n\n\nDepthwise Convolutionå®Œæˆåçš„Feature mapæ•°é‡ä¸è¾“å…¥å±‚çš„é€šé“æ•°ç›¸åŒï¼Œæ— æ³•æ‰©å±•Feature mapã€‚è€Œä¸”è¿™ç§è¿ç®—å¯¹è¾“å…¥å±‚çš„æ¯ä¸ªé€šé“ç‹¬ç«‹è¿›è¡Œå·ç§¯è¿ç®—ï¼Œæ²¡æœ‰æœ‰æ•ˆçš„åˆ©ç”¨ä¸åŒé€šé“åœ¨ç›¸åŒç©ºé—´ä½ç½®ä¸Šçš„featureä¿¡æ¯ã€‚å› æ­¤éœ€è¦Pointwise Convolutionæ¥å°†è¿™äº›Feature mapè¿›è¡Œç»„åˆç”Ÿæˆæ–°çš„Feature mapã€‚\n2.5 pointwiseå·ç§¯\nPointwise Convolutionçš„è¿ç®—ä¸å¸¸è§„å·ç§¯è¿ç®—éå¸¸ç›¸ä¼¼ï¼Œå®ƒçš„å·ç§¯æ ¸çš„å°ºå¯¸ä¸º 1Ã—1Ã—Mï¼ŒMä¸ºä¸Šä¸€å±‚çš„é€šé“æ•°ã€‚æ‰€ä»¥è¿™é‡Œçš„å·ç§¯è¿ç®—ä¼šå°†ä¸Šä¸€æ­¥çš„mapåœ¨æ·±åº¦æ–¹å‘ä¸Šè¿›è¡ŒåŠ æƒç»„åˆï¼Œç”Ÿæˆæ–°çš„Feature mapã€‚æœ‰å‡ ä¸ªå·ç§¯æ ¸å°±æœ‰å‡ ä¸ªè¾“å‡ºFeature mapã€‚å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n\n\npointwiseå·ç§¯(æ¥æºè§æ°´å°)\n\nç”±äºé‡‡ç”¨çš„æ˜¯1Ã—1å·ç§¯çš„æ–¹å¼ï¼Œæ­¤æ­¥ä¸­å·ç§¯æ¶‰åŠåˆ°çš„å‚æ•°ä¸ªæ•°å¯ä»¥è®¡ç®—ä¸ºï¼š N_pointwise = 1 Ã— 1 Ã— 3 Ã— 4 = 12\nç»è¿‡Pointwise Convolutionä¹‹åï¼ŒåŒæ ·è¾“å‡ºäº†4å¼ Feature mapï¼Œä¸å¸¸è§„å·ç§¯çš„è¾“å‡ºç»´åº¦ç›¸åŒã€‚\n\n\n\n\n\n\n\n\n\nå‚æ•°å¯¹æ¯” å›é¡¾ä¸€ä¸‹ï¼Œå¸¸è§„å·ç§¯çš„å‚æ•°ä¸ªæ•°ä¸ºï¼š N_std = 4 Ã— 3 Ã— 3 Ã— 3 = 108 Separable Convolutionçš„å‚æ•°ç”±ä¸¤éƒ¨åˆ†ç›¸åŠ å¾—åˆ°ï¼š N_depthwise = 3 Ã— 3 Ã— 3 = 27 N_pointwise = 1 Ã— 1 Ã— 3 Ã— 4 = 12 N_separable = N_depthwise + N_pointwise = 39 ç›¸åŒçš„è¾“å…¥ï¼ŒåŒæ ·æ˜¯å¾—åˆ°4å¼ Feature mapï¼ŒSeparable Convolutionçš„å‚æ•°ä¸ªæ•°æ˜¯å¸¸è§„å·ç§¯çš„çº¦1/3ã€‚å› æ­¤ï¼Œåœ¨å‚æ•°é‡ç›¸åŒçš„å‰æä¸‹ï¼Œé‡‡ç”¨Separable Convolutionçš„ç¥ç»ç½‘ç»œå±‚æ•°å¯ä»¥åšçš„æ›´æ·±ã€‚\n2.6 convï¼Œdepthwiseå’Œpointwise è®¡ç®—é‡\nå‡è®¾è¾“å…¥ç‰¹å¾å›¾å¤§å°ä¸º  Ã—  Ã— Mï¼Œ è¾“å‡ºç‰¹å¾å›¾å¤§å°ä¸º  Ã—  Ã— Nï¼Œ å·ç§¯æ ¸å¤§å°ä¸º  Ã— \nå‚æ•°é‡ï¼š Â  Â  æ ‡å‡†å·ç§¯å‚æ•°é‡ä¸ºï¼š Â  Â Â Â Â Â Â  Ã—  Ã— MÂ Ã— N\nÂ  Â  æ·±åº¦å¯åˆ†ç¦»å·ç§¯å‚æ•°é‡ä¸º(depthwise+pointwise)ï¼š Â  Â Â Â Â Â Â  Ã—  Ã— M + MÂ Ã— N\nè®¡ç®—é‡ï¼š Â  Â Â æ ‡å‡†å·ç§¯è®¡ç®—é‡ä¸ºï¼š Â  Â Â Â Â Â Â  Ã—  Ã— M Ã—  Ã—  Ã— N\nÂ  Â Â æ·±åº¦å¯åˆ†ç¦»å·ç§¯è®¡ç®—é‡ä¸ºï¼š Â  Â Â Â Â Â Â  Ã—  Ã— MÂ Ã—  Ã— Â +Â MÂ Ã—Â  Ã—  Ã— N\n\nå¯è§å‚æ•°æ•°é‡å’Œä¹˜åŠ æ“ä½œçš„è¿ç®—é‡å‡ä¸‹é™ä¸ºåŸæ¥çš„ æˆ‘ä»¬é€šå¸¸æ‰€ä½¿ç”¨çš„æ˜¯3Ã—3çš„å·ç§¯æ ¸ï¼Œä¹Ÿå°±æ˜¯ä¼šä¸‹é™åˆ°åŸæ¥çš„ä¹åˆ†ä¹‹ä¸€åˆ°å…«åˆ†ä¹‹ä¸€ã€‚\n2.7 åˆ†ç»„å·ç§¯\n\nç¬¬ä¸€å¼ å›¾ä»£è¡¨æ ‡å‡†å·ç§¯æ“ä½œã€‚è‹¥è¾“å…¥ç‰¹å¾å›¾å°ºå¯¸ä¸º ï¼Œå·ç§¯æ ¸å°ºå¯¸ä¸º ï¼Œè¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ä¸ºï¼Œæ ‡å‡†å·ç§¯å±‚çš„å‚æ•°é‡ä¸ºï¼š*c_2ã€‚ï¼ˆä¸€ä¸ªæ»¤æ³¢å™¨åœ¨è¾“å…¥ç‰¹å¾å›¾ å¤§å°çš„åŒºåŸŸå†…æ“ä½œï¼Œè¾“å‡ºç»“æœä¸º1ä¸ªæ•°å€¼ï¼Œæ‰€ä»¥éœ€è¦ ä¸ªæ»¤æ³¢å™¨ã€‚ï¼‰\nç¬¬äºŒå¼ å›¾ä»£è¡¨åˆ†ç»„å·ç§¯æ“ä½œã€‚å°†è¾“å…¥ç‰¹å¾å›¾æŒ‰ç…§é€šé“æ•°åˆ†æˆgç»„ï¼Œåˆ™æ¯ç»„è¾“å…¥ç‰¹å¾å›¾çš„å°ºå¯¸ä¸º ï¼Œå¯¹åº”çš„å·ç§¯æ ¸å°ºå¯¸ä¸ºï¼Œæ¯ç»„è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ä¸ºã€‚å°†gç»„ç»“æœæ‹¼æ¥(concat)ï¼Œå¾—åˆ°æœ€ç»ˆå°ºå¯¸ä¸º çš„è¾“å‡ºç‰¹å¾å›¾ã€‚åˆ†ç»„å·ç§¯å±‚çš„å‚æ•°é‡ä¸º ã€‚\næ·±å…¥æ€è€ƒä¸€ä¸‹ï¼Œå¸¸è§„å·ç§¯è¾“å‡ºçš„ç‰¹å¾å›¾ä¸Šï¼Œæ¯ä¸€ä¸ªç‚¹æ˜¯ç”±è¾“å…¥ç‰¹å¾å›¾ä¸ªç‚¹è®¡ç®—å¾—åˆ°çš„ï¼›è€Œåˆ†ç»„å·ç§¯è¾“å‡ºçš„ç‰¹å¾å›¾ä¸Šï¼Œæ¯ä¸€ä¸ªç‚¹æ˜¯ç”±è¾“å…¥ç‰¹å¾å›¾ ä¸ªç‚¹è®¡ç®—å¾—åˆ°çš„ã€‚è‡ªç„¶ï¼Œåˆ†ç»„å·ç§¯çš„å‚æ•°é‡æ˜¯æ ‡å‡†å·ç§¯çš„ ã€‚\n2.8 PixelShuffle\nPixelShuffle(åƒç´ é‡ç»„)çš„ä¸»è¦åŠŸèƒ½æ˜¯å°†ä½åˆ†è¾¨çš„ç‰¹å¾å›¾ï¼Œé€šè¿‡å·ç§¯å’Œå¤šé€šé“é—´çš„é‡ç»„å¾—åˆ°é«˜åˆ†è¾¨ç‡çš„ç‰¹å¾å›¾ã€‚è¿™ä¸€æ–¹æ³•æœ€åˆæ˜¯ä¸ºäº†è§£å†³å›¾åƒè¶…åˆ†è¾¨ç‡é—®é¢˜è€Œæå‡ºçš„ï¼Œè¿™ç§ç§°ä¸ºSub-Pixel Convolutional Neural Networkçš„æ–¹æ³•æˆä¸ºäº†ä¸Šé‡‡æ ·çš„æœ‰æ•ˆæ‰‹æ®µã€‚\n\npixelshuffleçš„ä¸»è¦åŠŸèƒ½å°±æ˜¯å°†è¿™ä¸ªé€šé“çš„ç‰¹å¾å›¾ç»„åˆä¸ºæ–°çš„w*r, h*rçš„ä¸Šé‡‡æ ·ç»“æœã€‚å…·ä½“æ¥è¯´ï¼Œå°±æ˜¯å°†åŸæ¥ä¸€ä¸ªä½åˆ†è¾¨çš„åƒç´ åˆ’åˆ†ä¸ºrå„æ›´å°çš„æ ¼å­ï¼Œåˆ©ç”¨rä¸ªç‰¹å¾å›¾å¯¹åº”ä½ç½®çš„å€¼æŒ‰ç…§ä¸€å®šçš„è§„åˆ™æ¥å¡«å……è¿™äº›å°æ ¼å­ã€‚æŒ‰ç…§åŒæ ·çš„è§„åˆ™å°†æ¯ä¸ªä½åˆ†è¾¨åƒç´ åˆ’åˆ†å‡ºçš„å°æ ¼å­å¡«æ»¡å°±å®Œæˆäº†é‡ç»„è¿‡ç¨‹ã€‚åœ¨è¿™ä¸€è¿‡ç¨‹ä¸­æ¨¡å‹å¯ä»¥è°ƒæ•´r*rä¸ªshuffleé€šé“æƒé‡ä¸æ–­ä¼˜åŒ–ç”Ÿæˆçš„ç»“æœã€‚ ä¸»è¦å®ç°äº†è¿™æ ·çš„åŠŸèƒ½ï¼šN*(C*r*r)*W*H----&gt;&gt;N*C*(H*r)*(W*r)\n\n\n\n\n\n\n\n\n\nåœ¨å›¾åƒè¶…åˆ†è¾¨å’Œå›¾åƒå¢å¼ºçš„ç®—æ³•ä¸­éœ€è¦å¯¹ç‰¹å¾å›¾è¿›è¡Œä¸Šä¸‹é‡‡æ ·çš„è¿‡ç¨‹ï¼Œå¯ä»¥è§£å†³æ’å€¼å’Œè§£å·ç§¯çš„ä¸€äº›äººå·¥ç—•è¿¹é—®é¢˜ã€‚\n2.9 Pooling\n(çŸ¥ä¹)[https://www.zhihu.com/question/49376084/answer/172483833]\nPooling çš„æœ¬è´¨ï¼Œå…¶å®æ˜¯é‡‡æ ·ã€‚Pooling å¯¹äºè¾“å…¥çš„ Feature Mapï¼Œé€‰æ‹©æŸç§æ–¹å¼å¯¹å…¶è¿›è¡Œå‹ç¼©ã€‚å¦‚Max-Pooling,è¿˜æœ‰Mean-Poolingï¼ŒStochastic-Pooling ç­‰ã€‚å®ƒä»¬çš„å…·ä½“å®ç°å¦‚åç§°æ‰€ç¤ºï¼Œå…·ä½“é€‰æ‹©å“ªä¸€ä¸ªåˆ™å–å†³äºå…·ä½“çš„ä»»åŠ¡ã€‚ Pooling çš„æ„ä¹‰ï¼Œä¸»è¦æœ‰ä¸¤ç‚¹ï¼š 1. å‡å°‘å‚æ•°ã€‚é€šè¿‡å¯¹ Feature Map é™ç»´ï¼Œæœ‰æ•ˆå‡å°‘åç»­å±‚éœ€è¦çš„å‚æ•° 2. Translation Invariance(å¹³ç§»ä¸å˜æ€§)ã€‚å®ƒè¡¨ç¤ºå¯¹äº Inputï¼Œå½“å…¶ä¸­åƒç´ åœ¨é‚»åŸŸå‘ç”Ÿå¾®å°ä½ç§»æ—¶ï¼ŒPooling Layer çš„è¾“å‡ºæ˜¯ä¸å˜çš„ã€‚è¿™å°±ä½¿ç½‘ç»œçš„é²æ£’æ€§å¢å¼ºäº†ï¼Œæœ‰ä¸€å®šæŠ—æ‰°åŠ¨çš„ä½œç”¨\n2.10 maxpooling/averagepoolingæ€ä¹ˆä¼ é€’å¯¼æ•°ï¼Ÿ(åæ± åŒ–)\nå‚è€ƒ\næ± åŒ–å±‚åœ¨åå‘ä¼ æ’­æ—¶ï¼Œå®ƒæ˜¯ä¸å¯å¯¼çš„ï¼Œå› ä¸ºå®ƒæ˜¯å¯¹ç‰¹å¾å›¾è¿›è¡Œä¸‹é‡‡æ ·ä¼šå¯¼è‡´ç‰¹å¾å›¾å˜å°ï¼Œæ¯”å¦‚ä¸€ä¸ª2x2çš„æ± åŒ–ï¼Œåœ¨L+1å±‚è¾“å‡ºçš„ç‰¹å¾å›¾æ˜¯16ä¸ªç¥ç»å…ƒï¼Œé‚£ä¹ˆå¯¹åº”Lå±‚å°±ä¼šæœ‰64ä¸ªç¥ç»å…ƒï¼Œä¸¤å±‚ä¹‹é—´ç»è¿‡æ± åŒ–æ“ä½œåï¼Œç‰¹å¾å›¾å°ºå¯¸æ”¹å˜ï¼Œæ— æ³•ä¸€ä¸€å¯¹åº”ï¼Œè¿™ä½¿å¾—æ¢¯åº¦æ— æ³•æŒ‰ä½ä¼ æ’­ã€‚é‚£ä¹ˆå¦‚ä½•è§£å†³æ± åŒ–å±‚ä¸å¯å¯¼ä½†å´è¦å‚ä¸åå‘ä¼ æ’­å‘¢ï¼Ÿ\nåœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¢¯åº¦æ˜¯æŒ‰ä½ä¼ æ’­çš„ï¼Œé‚£ä¹ˆï¼Œä¸€ä¸ªè§£å†³æ–¹æ³•ï¼Œå°±æ˜¯å¦‚ä½•æ„é€ æŒ‰ä½çš„é—®é¢˜ï¼Œä½†ä¸€å®šè¦éµå®ˆä¼ æ’­æ¢¯åº¦æ€»å’Œä¿æŒä¸å˜çš„åŸåˆ™ã€‚\nå¯¹äºå¹³å‡æ± åŒ–ï¼Œå…¶å‰å‘ä¼ æ’­æ˜¯å–æŸç‰¹å¾åŒºåŸŸçš„å¹³å‡å€¼è¿›è¡Œè¾“å‡ºï¼Œè¿™ä¸ªåŒºåŸŸçš„æ¯ä¸€ä¸ªç¥ç»å…ƒéƒ½æ˜¯æœ‰å‚ä¸å‰å‘ä¼ æ’­äº†çš„ï¼Œå› æ­¤ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¡†æ¶éœ€è¦å°†æ¢¯åº¦å¹³å‡åˆ†é…ç»™æ¯ä¸€ä¸ªç¥ç»å…ƒå†è¿›è¡Œåå‘ä¼ æ’­ï¼Œç›¸å…³çš„æ“ä½œç¤ºæ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n\nå¯¹äºæœ€å¤§æ± åŒ–ï¼Œå…¶å‰å‘ä¼ æ’­æ˜¯å–æŸç‰¹å¾åŒºåŸŸçš„æœ€å¤§å€¼è¿›è¡Œè¾“å‡ºï¼Œè¿™ä¸ªåŒºåŸŸä»…æœ‰æœ€å¤§å€¼ç¥ç»å…ƒå‚ä¸äº†å‰å‘ä¼ æ’­ï¼Œå› æ­¤ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¡†æ¶ä»…éœ€è¦å°†è¯¥åŒºåŸŸçš„æ¢¯åº¦ç›´æ¥åˆ†é…åˆ°æœ€å¤§å€¼ç¥ç»å…ƒå³å¯ï¼Œå…¶ä»–ç¥ç»å…ƒçš„æ¢¯åº¦è¢«åˆ†é…ä¸º0ä¸”æ˜¯è¢«èˆå¼ƒä¸å‚ä¸åå‘ä¼ æ’­çš„ï¼Œä½†å¦‚ä½•ç¡®è®¤æœ€å¤§å€¼ç¥ç»å…ƒï¼Œè¿™ä¸ªè¿˜å¾—æ¡†æ¶åœ¨è¿›è¡Œå‰å‘ä¼ æ’­æ—¶è®°å½•ä¸‹æœ€å¤§å€¼ç¥ç»å…ƒçš„Max IDä½ç½®ï¼Œè¿™æ˜¯æœ€å¤§æ± åŒ–ä¸å¹³å‡æ± åŒ–å·®å¼‚çš„åœ°æ–¹ï¼Œç›¸å…³çš„æ“ä½œç¤ºæ„å¦‚ä¸‹å›¾æ‰€ç¤ºã€‚\n\nå…¶ä¸­ï¼Œä¸Šè¿°è¡¨æ ¼ä¸­ï¼Œå‰å‘ä¼ æ’­æ—¶ï¼Œæ¯ä¸ªå•å…ƒæ ¼è¡¨ç¤ºç‰¹å¾å›¾ç¥ç»å…ƒå€¼ï¼Œè€Œåœ¨åå‘ä¼ æ’­æ—¶ï¼Œæ¯ä¸ªå•å…ƒæ ¼è¡¨ç¤ºçš„æ˜¯åˆ†é…ç»™å¯¹åº”ç¥ç»å…ƒçš„æ¢¯åº¦å€¼ã€‚\n2.11 (BN IN LN GN ADAIN)[https://zhuanlan.zhihu.com/p/289384231?utm_source=wechat_session]\n\nBNè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶ï¼Œå›ºå®šchannel(åœ¨ä¸€ä¸ªchannelå†…)ï¼Œå¯¹HWå’Œbatchä½œå¹³å‡ï¼› LNè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶ï¼Œå›ºå®šbatch(åœ¨ä¸€ä¸ªbatchå†…)ï¼Œå¯¹HWå’Œchannelä½œå¹³å‡ï¼› INè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶ï¼ŒåŒæ—¶å›ºå®šchannelå’Œbatch(åœ¨ä¸€ä¸ªbatchå†…ä¸­çš„ä¸€ä¸ªchannelå†…)ï¼Œå¯¹HWä½œå¹³å‡ï¼› GNè®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®æ—¶ï¼Œå›ºå®šbatchä¸”å¯¹channelä½œåˆ†ç»„(åœ¨ä¸€ä¸ªbatchå†…å¯¹channelä½œåˆ†ç»„)ï¼Œåœ¨åˆ†ç»„å†…å¯¹HWä½œå¹³å‡ã€‚\n2.11.1 BN\nåœ¨ç½‘ç»œå±‚æ•°åŠ æ·±çš„æ—¶å€™ï¼Œä¼šå½±å“æˆ‘ä»¬æ¯ä¸€å±‚è¾“å‡ºçš„æ•°æ®åˆ†å¸ƒã€‚è€Œä¹‹æ‰€ä»¥è®­ç»ƒæ”¶æ•›æ…¢ï¼Œä¸€èˆ¬æ˜¯æ•´ä½“åˆ†å¸ƒé€æ¸å¾€éçº¿æ€§å‡½æ•°çš„å–å€¼åŒºé—´çš„ä¸Šä¸‹é™ä¸¤ç«¯é è¿‘ï¼ˆä»¥Sigmoidå‡½æ•°ä¸ºä¾‹ï¼‰ï¼Œæ‰€ä»¥è¿™å¯¼è‡´åå‘ä¼ æ’­æ—¶ä½å±‚ç¥ç»ç½‘ç»œçš„æ¢¯åº¦å¾ˆå°ç”šè‡³æ¶ˆå¤±ï¼Œè¿™æ˜¯è®­ç»ƒæ·±å±‚ç¥ç»ç½‘ç»œæ”¶æ•›è¶Šæ¥è¶Šæ…¢çš„æœ¬è´¨åŸå› ï¼Œè€ŒBNå°±æ˜¯é€šè¿‡ä¸€å®šçš„è§„èŒƒåŒ–æ‰‹æ®µï¼ŒæŠŠæ¯å±‚ç¥ç»ç½‘ç»œä»»æ„ç¥ç»å…ƒè¿™ä¸ªè¾“å…¥å€¼çš„åˆ†å¸ƒå¼ºè¡Œæ‹‰å›åˆ°å‡å€¼ä¸º0æ–¹å·®ä¸º1çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œè¿™æ ·ä½¿å¾—æ¿€æ´»è¾“å…¥å€¼è½åœ¨éçº¿æ€§å‡½æ•°å¯¹è¾“å…¥æ¯”è¾ƒæ•æ„Ÿçš„åŒºåŸŸï¼Œè¿™æ ·è¾“å…¥çš„å°å˜åŒ–å°±ä¼šå¯¼è‡´æŸå¤±å‡½æ•°è¾ƒå¤§çš„å˜åŒ–ï¼Œæ‰€ä»¥å°±å¯ä»¥è®©æ¢¯åº¦å˜å¤§ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜äº§ç”Ÿï¼Œè€Œä¸”æ¢¯åº¦å˜å¤§æ„å‘³ç€å­¦ä¹ æ”¶æ•›é€Ÿåº¦å¿«ï¼Œèƒ½å¤§å¤§åŠ å¿«è®­ç»ƒé€Ÿåº¦ã€‚\nBNæ ¸å¿ƒå…¬å¼ï¼š \n\nBNçš„å…·ä½“æ“ä½œä¸ºï¼šå…ˆè®¡ç®—Bçš„å‡å€¼å’Œæ–¹å·®ï¼Œä¹‹åå°†Bé›†åˆçš„å‡å€¼ã€æ–¹å·®å˜æ¢ä¸º0ã€1ï¼Œæœ€åå°†Bä¸­æ¯ä¸ªå…ƒç´ ä¹˜ä»¥Î³å†åŠ Î²ï¼Œè¾“å‡ºã€‚ Î³ã€Î²æ˜¯å¯è®­ç»ƒå‚æ•°ï¼Œå‚ä¸æ•´ä¸ªç½‘ç»œçš„BPï¼›\nå½’ä¸€åŒ–çš„ç›®çš„ï¼šå°†æ•°æ®è§„æ•´åˆ°ç»Ÿä¸€åŒºé—´ï¼Œå‡å°‘æ•°æ®çš„å‘æ•£ç¨‹åº¦ï¼Œé™ä½ç½‘ç»œçš„å­¦ä¹ éš¾åº¦ã€‚BNçš„ç²¾é«“åœ¨äºå½’ä¸€ä¹‹åï¼Œä½¿ç”¨Î³ã€Î²ä½œä¸ºè¿˜åŸå‚æ•°ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šä¿ç•™åŸæ•°æ®çš„åˆ†å¸ƒã€‚\n\nè®­ç»ƒä¸æ¨ç†æ—¶BNä¸­çš„å‡å€¼ã€æ–¹å·®åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ è®­ç»ƒæ—¶ï¼Œå‡å€¼ã€æ–¹å·®åˆ†åˆ«æ˜¯è¯¥æ‰¹æ¬¡å†…æ•°æ®ç›¸åº”ç»´åº¦çš„å‡å€¼ä¸æ–¹å·®ï¼› æ¨ç†æ—¶ï¼Œå‡å€¼ã€æ–¹å·®æ˜¯åŸºäºæ‰€æœ‰æ‰¹æ¬¡çš„æœŸæœ›è®¡ç®—æ‰€å¾—ï¼Œå…¬å¼å¦‚ä¸‹ï¼š  å…¶ä¸­ï¼ŒE(x)è¡¨ç¤ºxçš„æœŸæœ›.\nä»£ç å®ç°æŠ€å·§ï¼š\n\nåœ¨ä»£ç å®ç°ä¸­æœ‰ä¸€ä¸ªæŠ€å·§ï¼Œå¦‚æœè®­ç»ƒå‡ ç™¾ä¸‡ä¸ªBatchï¼Œé‚£ä¹ˆæ˜¯ä¸æ˜¯è¦å°†å…¶å‡å€¼æ–¹å·®å…¨éƒ¨å‚¨å­˜ï¼Œæœ€åå†è®¡ç®—æ¨ç†æ—¶æ‰€ç”¨çš„å‡å€¼å’Œæ–¹å·®ï¼Ÿè¿™æ ·æ˜¾ç„¶å¤ªè¿‡ç¬¨æ‹™ï¼Œå ç”¨å†…å­˜éšç€è®­ç»ƒæ¬¡æ•°ä¸æ–­ä¸Šå‡ã€‚ä¸ºäº†é¿å…è¯¥é—®é¢˜ï¼Œå®é™…ä»£ç ï¼ˆå¦‚tfï¼‰ä½¿ç”¨äº†æ»‘åŠ¨å¹³å‡ï¼Œå‚¨å­˜å›ºå®šä¸ªæ•°Batchçš„å‡å€¼å’Œæ–¹å·®ï¼Œä¸æ–­è¿­ä»£æ›´æ–°æ¨ç†æ—¶éœ€è¦çš„E(x)ä¸Var(x)ã€‚ æ³¨æ„åˆ°ä»£ç ä¸­ï¼š 1. betaã€gammaåœ¨è®­ç»ƒçŠ¶æ€ä¸‹ï¼Œæ˜¯å¯è®­ç»ƒå‚æ•°ï¼Œåœ¨æ¨ç†çŠ¶æ€ä¸‹ï¼Œç›´æ¥åŠ è½½è®­ç»ƒå¥½çš„æ•°å€¼ã€‚ 2. moving_meanã€moving_varåœ¨è®­ç»ƒã€æ¨ç†ä¸­éƒ½æ˜¯ä¸å¯è®­ç»ƒå‚æ•°ï¼Œåªæ ¹æ®æ»‘åŠ¨å¹³å‡è®¡ç®—å…¬å¼æ›´æ–°æ•°å€¼ï¼Œä¸ä¼šéšç€ç½‘ç»œçš„è®­ç»ƒBPè€Œæ”¹å˜æ•°å€¼ï¼›åœ¨æ¨ç†æ—¶ï¼Œç›´æ¥åŠ è½½å‚¨å­˜è®¡ç®—å¥½çš„æ»‘åŠ¨å¹³å‡ä¹‹åçš„æ•°å€¼ï¼Œä½œä¸ºæ¨ç†æ—¶çš„å‡å€¼å’Œæ–¹å·®ã€‚\nBNå±‚çš„æœ¬è´¨: å¹³æ»‘äº†ä¼˜åŒ–ç©ºé—´\nå¯¹æ¯”ç™½åŒ–æ“ä½œ:\nç™½åŒ–æ˜¯æœºå™¨å­¦ä¹ é‡Œé¢ å¸¸ç”¨çš„ä¸€ç§è§„èŒƒåŒ–æ•°æ®åˆ†å¸ƒçš„æ–¹æ³•ï¼Œä¸»è¦æ˜¯PCAç™½åŒ–ä¸ZCAç™½åŒ–ã€‚ç™½åŒ–æ˜¯å¯¹è¾“å…¥æ•°æ®åˆ†å¸ƒè¿›è¡Œå˜æ¢ï¼Œè¿›è€Œè¾¾åˆ°ä»¥ä¸‹ä¸¤ä¸ªç›®çš„ï¼š ï¼ˆ1ï¼‰ä½¿å¾—è¾“å…¥ç‰¹å¾åˆ†å¸ƒå…·æœ‰ç›¸åŒçš„å‡å€¼ä¸æ–¹å·®ã€‚ ï¼ˆ2ï¼‰å»é™¤ç‰¹å¾ä¹‹é—´çš„ç›¸å…³æ€§ã€‚ ä½†æ˜¯ç™½åŒ–ä¹Ÿå­˜åœ¨ä¸¤ä¸ªé—®é¢˜ï¼š ï¼ˆ1ï¼‰è®¡ç®—æˆæœ¬å¤ªå¤§ï¼ŒåƒPCAç™½åŒ–è¿˜è¦ç®—åæ–¹å·®çŸ©é˜µç­‰ã€‚ ï¼ˆ2ï¼‰ç™½åŒ–è¿‡ç¨‹ç”±äºæ”¹å˜äº†ç½‘ç»œæ¯ä¸€å±‚çš„åˆ†å¸ƒï¼Œå› è€Œæ”¹å˜äº†ç½‘ç»œå±‚ä¸­æœ¬èº«æ•°æ®çš„è¡¨è¾¾èƒ½åŠ›ã€‚åº•å±‚ç½‘ç»œå­¦ä¹ åˆ°çš„å‚æ•°ä¿¡æ¯ä¼šè¢«ç™½åŒ–æ“ä½œä¸¢å¤±æ‰ã€‚è€ŒBNæ­£æ˜¯é’ˆå¯¹äº†ç™½åŒ–çš„è¿™ä¸¤ä¸ªç¼ºç‚¹è¿›è¡Œäº†æ”¹å–„\nBNçš„ç¼ºé™·:\n\néœ€è¦è¾ƒå¤§çš„ batchsize æ‰èƒ½åˆç†ä¼°è®­ç»ƒæ•°æ®çš„å‡å€¼å’Œæ–¹å·®(æ¨ªå‘è®¡ç®—)ï¼Œè¿™å¯¼è‡´å†…å­˜å¾ˆå¯èƒ½ä¸å¤Ÿç”¨;\nå¾ˆéš¾åº”ç”¨åœ¨è®­ç»ƒæ•°æ®é•¿åº¦ä¸åŒçš„ RNN æ¨¡å‹ä¸Š.\n\nBNå’Œå·ç§¯å±‚èåˆ:\n\n2.11.2 IN\nINæ˜¯é’ˆå¯¹äºä¸åŒçš„batch, ä¸åŒçš„chennelè¿›è¡Œå½’ä¸€åŒ–ã€‚è¿˜æ˜¯æŠŠå›¾åƒçš„å°ºå¯¸è¡¨ç¤ºä¸º[N, C, H, W]çš„è¯ï¼ŒINåˆ™æ˜¯é’ˆå¯¹äº[H,W]è¿›è¡Œå½’ä¸€åŒ–ã€‚è¿™ç§æ–¹å¼é€šå¸¸ä¼šç”¨åœ¨é£æ ¼è¿ç§»çš„è®­ç»ƒä¸­ã€‚\n\n\n\n\n\n\n\n\n\nIN æ“ä½œä¹Ÿåœ¨å•ä¸ªæ ·æœ¬å†…éƒ¨è¿›è¡Œï¼Œä¸ä¾èµ– batchã€‚\n2.11.3 LN\nLNçš„æ–¹æ³•æ˜¯å¯¹äºæ¯ä¸€ä¸ªsampleä¸­çš„å¤šä¸ªfeature(ä¹Ÿå°±æ˜¯channel)è¿›è¡Œå½’ä¸€åŒ–æ“ä½œã€‚æŠŠå›¾åƒçš„å°ºå¯¸è¡¨ç¤ºä¸º[N, C, H, W]çš„è¯ï¼ŒLNåˆ™æ˜¯å¯¹äº[C,H,W]è¿›è¡Œå½’ä¸€åŒ–ã€‚ç›¸å¯¹äºBNä¸­æ‰€è¡¨ç¤ºçš„åŒä¸€ä¸ªfeatureåœ¨ä¸åŒçš„batchä¹‹é—´æ‹¥æœ‰åŒæ ·çš„å‡å€¼å’Œæ–¹å·®ã€‚LNä¸­æ‰€è¡¨ç¤ºçš„åˆ™æ˜¯åœ¨åŒä¸€ä¸ªsampleä¸­ï¼Œä¸åŒçš„featureä¸Šæœ‰ç€ç›¸åŒçš„å‡å€¼å’Œæ–¹å·®ã€‚\nä¸BNç›¸æ¯”ï¼ŒLNä¹Ÿä¸ä¾èµ–äºmini-batch sizeçš„å¤§å°ã€‚è¿™ç§æ“ä½œé€šå¸¸è¿ç”¨åœ¨RNNçš„ç½‘ç»œä¸­ã€‚\n\n\n\n\n\n\n\n\n\nLayer Normalization (LN) çš„ä¸€ä¸ªä¼˜åŠ¿æ˜¯ä¸éœ€è¦æ‰¹è®­ç»ƒï¼Œåœ¨å•æ¡æ•°æ®å†…éƒ¨å°±èƒ½å½’ä¸€åŒ–ã€‚LN å¯¹æ¯ä¸ªæ ·æœ¬çš„ Cã€Hã€W ç»´åº¦ä¸Šçš„æ•°æ®æ±‚å‡å€¼å’Œæ ‡å‡†å·®ï¼Œä¿ç•™ N ç»´åº¦ã€‚\n2.11.4 GN\nGNæ˜¯ä»‹ä¹äºinstance normal å’Œ layer normal ä¹‹é—´çš„ä¸€ç§å½’ä¸€åŒ–æ–¹å¼ã€‚ä¹Ÿå°±æ˜¯è¯´å½“æˆ‘ä»¬æŠŠæ‰€æœ‰çš„channeléƒ½æ”¾åˆ°åŒä¸€ä¸ªgroupä¸­çš„æ—¶å€™å°±å˜æˆäº†layer normalï¼Œ å¦‚æœæˆ‘ä»¬æŠŠæ¯ä¸ªchanneléƒ½å½’ä¸ºä¸€ä¸ªä¸åŒçš„groupï¼Œåˆ™å˜æˆäº†instance normal.\nGNåŒæ ·å¯ä»¥é’ˆå¯¹äºmini batch sizeè¾ƒå°çš„æƒ…å†µã€‚å› ä¸ºå®ƒæœ‰ä¸å—batch sizeçš„çº¦æŸã€‚\nå¯ä»¥çœ‹åˆ°ä¸BNä¸åŒï¼ŒLN/INå’ŒGNéƒ½æ²¡æœ‰å¯¹batchä½œå¹³å‡ï¼Œæ‰€ä»¥å½“batchå˜åŒ–æ—¶ï¼Œç½‘ç»œçš„é”™è¯¯ç‡ä¸ä¼šæœ‰æ˜æ˜¾å˜åŒ–ã€‚ä½†è®ºæ–‡çš„å®éªŒæ˜¾ç¤ºï¼šLNå’ŒIN åœ¨æ—¶é—´åºåˆ—æ¨¡å‹(RNN/LSTM)å’Œç”Ÿæˆæ¨¡å‹(GAN)ä¸Šæœ‰å¾ˆå¥½çš„æ•ˆæœï¼Œè€ŒGNåœ¨è§†è§‰æ¨¡å‹ä¸Šè¡¨ç°æ›´å¥½ã€‚\n\n\n\n\n\n\n\n\n\nGroup Normalization (GN) é€‚ç”¨äºå ç”¨æ˜¾å­˜æ¯”è¾ƒå¤§çš„ä»»åŠ¡ï¼Œä¾‹å¦‚å›¾åƒåˆ†å‰²,å¯¹è¿™ç±»ä»»åŠ¡ï¼Œå¯èƒ½ batchsize åªèƒ½æ˜¯ä¸ªä½æ•°ï¼Œå†å¤§æ˜¾å­˜å°±ä¸å¤Ÿç”¨äº†ã€‚è€Œå½“ batchsize æ˜¯ä¸ªä½æ•°æ—¶ï¼ŒBN çš„è¡¨ç°å¾ˆå·®ï¼Œå› ä¸ºæ²¡åŠæ³•é€šè¿‡å‡ ä¸ªæ ·æœ¬çš„æ•°æ®é‡ï¼Œæ¥è¿‘ä¼¼æ€»ä½“çš„å‡å€¼å’Œæ ‡å‡†å·®ã€‚GN ä¹Ÿæ˜¯ç‹¬ç«‹äº batch çš„ï¼Œå®ƒæ˜¯ LN å’Œ IN çš„æŠ˜ä¸­\n2.11.5 æ˜ å°„å‚æ•°Î³å’ŒÎ²çš„åŒºåˆ«\nå¯¹äº BNï¼ŒINï¼ŒGNï¼Œ å…¶Î³å’ŒÎ²éƒ½æ˜¯ç»´åº¦ç­‰äºé€šé“æ•° C çš„å‘é‡ã€‚è€Œå¯¹äº LNï¼Œå…¶Î³å’ŒÎ²éƒ½æ˜¯ç»´åº¦ç­‰äº normalized_shape çš„çŸ©é˜µã€‚ æœ€åï¼ŒBNå’ŒIN å¯ä»¥è®¾ç½®å‚æ•°ï¼šmomentum å’Œ track_running_statsæ¥è·å¾—åœ¨å…¨å±€æ•°æ®ä¸Šæ›´å‡†ç¡®çš„ running mean å’Œ running stdã€‚ è€Œ LN å’Œ GN åªèƒ½è®¡ç®—å½“å‰ batch å†…æ•°æ®çš„çœŸå®å‡å€¼å’Œæ ‡å‡†å·®ã€‚\n2.11.6 dropout\nåœ¨è®­ç»ƒæ—¶ï¼Œæ¯ä¸ªç¥ç»å•å…ƒä»¥æ¦‚ç‡ğ‘è¢«ä¿ç•™(Dropoutä¸¢å¼ƒç‡ä¸º1âˆ’ğ‘)ï¼› åœ¨é¢„æµ‹é˜¶æ®µï¼ˆæµ‹è¯•é˜¶æ®µï¼‰ï¼Œæ¯ä¸ªç¥ç»å•å…ƒéƒ½æ˜¯å­˜åœ¨çš„ï¼Œæƒé‡å‚æ•°ğ‘¤è¦ä¹˜ä»¥ğ‘ï¼Œè¾“å‡ºæ˜¯ï¼šğ‘ğ‘¤ã€‚\né¢„æµ‹é˜¶æ®µéœ€è¦ä¹˜ä¸Šğ‘çš„åŸå› ï¼š ã€€ã€€å‰ä¸€å±‚éšè—å±‚çš„ä¸€ä¸ªç¥ç»å…ƒåœ¨ğ‘‘ğ‘Ÿğ‘œğ‘ğ‘œğ‘¢ğ‘¡ä¹‹å‰çš„è¾“å‡ºæ˜¯ğ‘¥ï¼Œè®­ç»ƒæ—¶ğ‘‘ğ‘Ÿğ‘œğ‘ğ‘œğ‘¢ğ‘¡ä¹‹åçš„æœŸæœ›å€¼æ˜¯ğ¸=ğ‘ğ‘¥+(1âˆ’ğ‘)0Ë™; åœ¨é¢„æµ‹é˜¶æ®µè¯¥å±‚ç¥ç»å…ƒæ€»æ˜¯æ¿€æ´»ï¼Œä¸ºäº†ä¿æŒåŒæ ·çš„è¾“å‡ºæœŸæœ›å€¼å¹¶ä½¿ä¸‹ä¸€å±‚ä¹Ÿå¾—åˆ°åŒæ ·çš„ç»“æœï¼Œéœ€è¦è°ƒæ•´ğ‘¥âˆ’&gt;ğ‘ğ‘¥. å…¶ä¸­ğ‘æ˜¯Bernoulliåˆ†å¸ƒï¼ˆ0-1åˆ†å¸ƒï¼‰ä¸­å€¼ä¸º1çš„æ¦‚ç‡ã€‚\nä¸ºä»€ä¹ˆè¯´Dropoutå¯ä»¥è§£å†³è¿‡æ‹Ÿåˆï¼Ÿ 1. å–å¹³å‡çš„ä½œç”¨ï¼š å…ˆå›åˆ°æ ‡å‡†çš„æ¨¡å‹å³æ²¡æœ‰dropoutï¼Œæˆ‘ä»¬ç”¨ç›¸åŒçš„è®­ç»ƒæ•°æ®å»è®­ç»ƒ5ä¸ªä¸åŒçš„ç¥ç»ç½‘ç»œï¼Œä¸€èˆ¬ä¼šå¾—åˆ°5ä¸ªä¸åŒçš„ç»“æœï¼Œæ­¤æ—¶æˆ‘ä»¬å¯ä»¥é‡‡ç”¨ â€œ5ä¸ªç»“æœå–å‡å€¼â€æˆ–è€…â€œå¤šæ•°å–èƒœçš„æŠ•ç¥¨ç­–ç•¥â€å»å†³å®šæœ€ç»ˆç»“æœã€‚ä¾‹å¦‚3ä¸ªç½‘ç»œåˆ¤æ–­ç»“æœä¸ºæ•°å­—9,é‚£ä¹ˆå¾ˆæœ‰å¯èƒ½çœŸæ­£çš„ç»“æœå°±æ˜¯æ•°å­—9ï¼Œå…¶å®ƒä¸¤ä¸ªç½‘ç»œç»™å‡ºäº†é”™è¯¯ç»“æœã€‚è¿™ç§â€œç»¼åˆèµ·æ¥å–å¹³å‡â€çš„ç­–ç•¥é€šå¸¸å¯ä»¥æœ‰æ•ˆé˜²æ­¢è¿‡æ‹Ÿåˆé—®é¢˜ã€‚å› ä¸ºä¸åŒçš„ç½‘ç»œå¯èƒ½äº§ç”Ÿä¸åŒçš„è¿‡æ‹Ÿåˆï¼Œå–å¹³å‡åˆ™æœ‰å¯èƒ½è®©ä¸€äº›â€œç›¸åçš„â€æ‹Ÿåˆäº’ç›¸æŠµæ¶ˆã€‚dropoutæ‰ä¸åŒçš„éšè—ç¥ç»å…ƒå°±ç±»ä¼¼åœ¨è®­ç»ƒä¸åŒçš„ç½‘ç»œï¼Œéšæœºåˆ æ‰ä¸€åŠéšè—ç¥ç»å…ƒå¯¼è‡´ç½‘ç»œç»“æ„å·²ç»ä¸åŒï¼Œæ•´ä¸ªdropoutè¿‡ç¨‹å°±ç›¸å½“äºå¯¹å¾ˆå¤šä¸ªä¸åŒçš„ç¥ç»ç½‘ç»œå–å¹³å‡ã€‚è€Œä¸åŒçš„ç½‘ç»œäº§ç”Ÿä¸åŒçš„è¿‡æ‹Ÿåˆï¼Œä¸€äº›äº’ä¸ºâ€œåå‘â€çš„æ‹Ÿåˆç›¸äº’æŠµæ¶ˆå°±å¯ä»¥è¾¾åˆ°æ•´ä½“ä¸Šå‡å°‘è¿‡æ‹Ÿåˆã€‚ 2. å‡å°‘ç¥ç»å…ƒä¹‹é—´å¤æ‚çš„å…±é€‚åº”å…³ç³»ï¼š å› ä¸ºdropoutç¨‹åºå¯¼è‡´ä¸¤ä¸ªç¥ç»å…ƒä¸ä¸€å®šæ¯æ¬¡éƒ½åœ¨ä¸€ä¸ªdropoutç½‘ç»œä¸­å‡ºç°ã€‚è¿™æ ·æƒå€¼çš„æ›´æ–°ä¸å†ä¾èµ–äºæœ‰å›ºå®šå…³ç³»çš„éšå«èŠ‚ç‚¹çš„å…±åŒä½œç”¨ï¼Œé˜»æ­¢äº†æŸäº›ç‰¹å¾ä»…ä»…åœ¨å…¶å®ƒç‰¹å®šç‰¹å¾ä¸‹æ‰æœ‰æ•ˆæœçš„æƒ…å†µ ã€‚è¿«ä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ ï¼Œè¿™äº›ç‰¹å¾åœ¨å…¶å®ƒçš„ç¥ç»å…ƒçš„éšæœºå­é›†ä¸­ä¹Ÿå­˜åœ¨ã€‚æ¢å¥è¯è¯´å‡å¦‚æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ˜¯åœ¨åšå‡ºæŸç§é¢„æµ‹ï¼Œå®ƒä¸åº”è¯¥å¯¹ä¸€äº›ç‰¹å®šçš„çº¿ç´¢ç‰‡æ®µå¤ªè¿‡æ•æ„Ÿï¼Œå³ä½¿ä¸¢å¤±ç‰¹å®šçš„çº¿ç´¢ï¼Œå®ƒä¹Ÿåº”è¯¥å¯ä»¥ä»ä¼—å¤šå…¶å®ƒçº¿ç´¢ä¸­å­¦ä¹ ä¸€äº›å…±åŒçš„ç‰¹å¾ã€‚ä»è¿™ä¸ªè§’åº¦çœ‹dropoutå°±æœ‰ç‚¹åƒL1ï¼ŒL2æ­£åˆ™ï¼Œå‡å°‘æƒé‡ä½¿å¾—ç½‘ç»œå¯¹ä¸¢å¤±ç‰¹å®šç¥ç»å…ƒè¿æ¥çš„é²æ£’æ€§æé«˜ã€‚ 3. Dropoutç±»ä¼¼äºæ€§åˆ«åœ¨ç”Ÿç‰©è¿›åŒ–ä¸­çš„è§’è‰²ï¼šç‰©ç§ä¸ºäº†ç”Ÿå­˜å¾€å¾€ä¼šå€¾å‘äºé€‚åº”è¿™ç§ç¯å¢ƒï¼Œç¯å¢ƒçªå˜åˆ™ä¼šå¯¼è‡´ç‰©ç§éš¾ä»¥åšå‡ºåŠæ—¶ååº”ï¼Œæ€§åˆ«çš„å‡ºç°å¯ä»¥ç¹è¡å‡ºé€‚åº”æ–°ç¯å¢ƒçš„å˜ç§ï¼Œæœ‰æ•ˆçš„é˜»æ­¢è¿‡æ‹Ÿåˆï¼Œå³é¿å…ç¯å¢ƒæ”¹å˜æ—¶ç‰©ç§å¯èƒ½é¢ä¸´çš„ç­ç»ã€‚\ndropoutä¼šæ”¹å˜æ•°æ®åˆ†å¸ƒ, å¯¼è‡´è®­ç»ƒæµ‹è¯•æ ·æœ¬åˆ†å¸ƒä¸ä¸€è‡´ï¼Œæ€ä¹ˆè§£å†³\nå®è·µå‘ç°droputä¹‹åæ”¹å˜äº†æ•°æ®çš„æ ‡å‡†å·®ï¼ˆä»¤æ ‡å‡†å·®å˜å¤§ï¼Œè‹¥æ•°æ®å‡å€¼é0æ—¶ï¼Œç”šè‡³å‡å€¼ä¹Ÿä¼šäº§ç”Ÿæ”¹å˜ï¼‰ã€‚ å¦‚æœåŒæ—¶åˆä½¿ç”¨äº†BNå½’ä¸€åŒ–ï¼Œç”±äºBNåœ¨è®­ç»ƒæ—¶ä¿å­˜äº†è®­ç»ƒé›†çš„å‡å€¼ä¸æ ‡å‡†å·®ã€‚dropoutå½±å“äº†æ‰€ä¿å­˜çš„å‡å€¼ä¸æ ‡å‡†å·®çš„å‡†ç¡®æ€§ï¼ˆä¸èƒ½é€‚åº”æœªæ¥é¢„æµ‹æ•°æ®çš„éœ€è¦ï¼‰ï¼Œé‚£ä¹ˆå°†å½±å“ç½‘ç»œçš„å‡†ç¡®æ€§ã€‚\ndropout æœ‰ä¸¤ç§å®ç°æ–¹å¼ï¼ŒVanilla Dropout å’Œ Inverted Dropoutã€‚ ä¸»æµæ¡†æ¶ä½¿ç”¨Inverted Dropoutï¼š çŸ¥ä¹ï¼šç¥ç»ç½‘ç»œDropoutå±‚ä¸­ä¸ºä»€ä¹ˆdropoutåè¿˜éœ€è¦è¿›è¡Œrescaleï¼Ÿ\n\nå½“æ¨¡å‹ä½¿ç”¨äº†dropout layerï¼Œè®­ç»ƒçš„æ—¶å€™åªæœ‰å æ¯”ä¸ºpçš„éšè—å±‚å•å…ƒå‚ä¸è®­ç»ƒï¼Œé‚£ä¹ˆåœ¨é¢„æµ‹çš„æ—¶å€™ï¼Œå¦‚æœæ‰€æœ‰çš„éšè—å±‚å•å…ƒéƒ½éœ€è¦å‚ä¸è¿›æ¥ï¼Œåˆ™å¾—åˆ°çš„ç»“æœç›¸æ¯”è®­ç»ƒæ—¶å¹³å‡è¦å¤§ï¼Œä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œå°±éœ€è¦æµ‹è¯•çš„æ—¶å€™å°†è¾“å‡ºç»“æœä¹˜ä»¥pä½¿ä¸‹ä¸€å±‚çš„è¾“å…¥è§„æ¨¡ä¿æŒä¸å˜ã€‚è€Œåˆ©ç”¨inverted dropoutï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è®­ç»ƒçš„æ—¶å€™ç›´æ¥å°†dropoutåç•™ä¸‹çš„æƒé‡æ‰©å¤§å€ï¼Œè¿™æ ·å°±å¯ä»¥ä½¿ç»“æœçš„scaleä¿æŒä¸å˜ï¼Œè€Œåœ¨é¢„æµ‹çš„æ—¶å€™ä¹Ÿä¸ç”¨åšé¢å¤–çš„æ“ä½œäº†ï¼Œæ›´æ–¹ä¾¿ä¸€äº›ã€‚\n\n\n\n\n\n\n\n\n\næ¯ä¸ªç¥ç»å…ƒçš„ä¸¢å¼ƒæ¦‚ç‡péµå¾ªæ¦‚ç‡pçš„ä¼¯åŠªåˆ©åˆ†å¸ƒ;ä¼¯åŠªåˆ©å®éªŒæ˜¯ â€œSingle trial with only two outcomes\",äºŒé¡¹å®éªŒæ˜¯ â€œRepeating a Bernoulli experiment for n timesâ€. äºŒé¡¹åˆ†å¸ƒå°±æ˜¯ï¼Œå°†ä¼¯åŠªåˆ©å®éªŒé‡å¤næ¬¡åçš„æ¦‚ç‡åˆ†å¸ƒã€‚\n2.11.7 CNNçš„å¹³ç§»ä¸å˜æ€§\nå‡ºå¤„\nCNNçš„å¹³ç§»ä¸å˜æ€§ã€‚ç®€å•æ¥è¯´ï¼Œå¹³ç§»ä¸å˜æ€§ï¼ˆtranslation invariantï¼‰æŒ‡çš„æ˜¯CNNå¯¹äºåŒä¸€å¼ å›¾åŠå…¶å¹³ç§»åçš„ç‰ˆæœ¬ï¼Œéƒ½èƒ½è¾“å‡ºåŒæ ·çš„ç»“æœã€‚è¿™å¯¹äºå›¾åƒåˆ†ç±»ï¼ˆimage classificationï¼‰é—®é¢˜æ¥è¯´è‚¯å®šæ˜¯æœ€ç†æƒ³çš„ï¼Œå› ä¸ºå¯¹äºä¸€ä¸ªç‰©ä½“çš„å¹³ç§»å¹¶ä¸åº”è¯¥æ”¹å˜å®ƒçš„ç±»åˆ«ã€‚è€Œå¯¹äºå…¶å®ƒé—®é¢˜ï¼Œæ¯”å¦‚ç‰©ä½“æ£€æµ‹ï¼ˆdetectionï¼‰ã€ç‰©ä½“åˆ†å‰²ï¼ˆsegmentationï¼‰æ¥è¯´ï¼Œè¿™ä¸ªæ€§è´¨åˆ™ä¸åº”è¯¥æœ‰ï¼ŒåŸå› æ˜¯å½“è¾“å…¥å‘ç”Ÿå¹³ç§»æ—¶ï¼Œè¾“å‡ºä¹Ÿåº”è¯¥ç›¸åº”åœ°è¿›è¡Œå¹³ç§»ã€‚è¿™ç§æ€§è´¨åˆç§°ä¸ºå¹³ç§»ç­‰ä»·æ€§ï¼ˆtranslation equivalenceï¼‰ã€‚\n3. æ¿€æ´»å‡½æ•°ç›¸å…³\n\n\n\n\n\n\n\n\n\næ— è®ºæ˜¯å…¨è¿æ¥å±‚è¿˜æ˜¯å·ç§¯å±‚çš„è®¡ç®—éƒ½æ˜¯ç®€å•çš„ä¹˜åŠ è¿ç®—ï¼Œä¹Ÿç§°ä¹‹ä¸ºçº¿æ€§è¿ç®—ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥ä½œä¸ºçº¿æ€§å±‚ã€‚ä½†æ˜¯ï¼Œçº¿æ€§å±‚çš„ç‰¹å¾è¡¨è¾¾èƒ½åŠ›æ˜¯æœ‰é™çš„ï¼Œæ‰€ä»¥åœ¨è¿™äº›çº¿æ€§è®¡ç®—ä¹‹ååˆå¼•å…¥äº†éçº¿æ€§è®¡ç®—ï¼Œå¢å¼ºæ¨¡å‹ç‰¹å¾çš„è¡¨è¾¾èƒ½åŠ›ï¼Œä¹Ÿå°±æ˜¯å¤§å®¶ç†ŸçŸ¥çš„æ¿€æ´»å±‚ï¼Œä¹Ÿç§°ä¸ºéçº¿æ€§å±‚ã€‚ å‚è€ƒ\næ¿€æ´»å‡½æ•°å¯ä»¥åˆ†ä¸ºä¸¤å¤§ç±» ï¼š é¥±å’Œæ¿€æ´»å‡½æ•°ï¼š sigmoidã€ tanh éé¥±å’Œæ¿€æ´»å‡½æ•°: ReLU ã€Leaky Relu ã€ELUã€æŒ‡æ•°çº¿æ€§å•å…ƒã€‘ã€PReLUã€å‚æ•°åŒ–çš„ReLU ã€‘ã€RReLUã€éšæœºReLUã€‘ ç›¸å¯¹äºé¥±å’Œæ¿€æ´»å‡½æ•°ï¼Œä½¿ç”¨â€œéé¥±å’Œæ¿€æ´»å‡½æ•°â€çš„ä¼˜åŠ¿åœ¨äºä¸¤ç‚¹ï¼š 1. é¦–å…ˆï¼Œâ€œéé¥±å’Œæ¿€æ´»å‡½æ•°â€èƒ½è§£å†³æ·±åº¦ç¥ç»ç½‘ç»œã€å±‚æ•°éå¸¸å¤šï¼ï¼ã€‘çš„â€œæ¢¯åº¦æ¶ˆå¤±â€é—®é¢˜ï¼Œæµ…å±‚ç½‘ç»œã€ä¸‰äº”å±‚é‚£ç§ã€‘æ‰ç”¨sigmoid ä½œä¸ºæ¿€æ´»å‡½æ•°ã€‚ 2. å…¶æ¬¡ï¼Œå®ƒèƒ½åŠ å¿«æ”¶æ•›é€Ÿåº¦ã€‚\n3.1 Sigmoid\nsigmoidå‡½æ•°ä¹Ÿç§°ä¸ºLogisticå‡½æ•°, sigmodå‡½æ•°çš„å–å€¼èŒƒå›´åœ¨ï¼ˆ0, 1ï¼‰ä¹‹é—´ï¼Œå¯ä»¥å°†ç½‘ç»œçš„è¾“å‡ºæ˜ å°„åœ¨è¿™ä¸€èŒƒå›´ï¼Œæ–¹ä¾¿åˆ†æã€‚\n3.1.1 å…¬å¼åŠå¯¼æ•°\n\n\n3.1.2 æ›²çº¿\n\n\n(æ¥æºè§æ°´å°)\n\n3.1.3 ç‰¹ç‚¹\nä¼˜ç‚¹ï¼š å¹³æ»‘ã€æ˜“äºæ±‚å¯¼ã€‚\nç¼ºç‚¹ï¼š 1. æ¿€æ´»å‡½æ•°è®¡ç®—é‡å¤§ï¼ˆåœ¨æ­£å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ä¸­éƒ½åŒ…å«å¹‚è¿ç®—å’Œé™¤æ³•ï¼‰ï¼› 2. åå‘ä¼ æ’­æ±‚è¯¯å·®æ¢¯åº¦æ—¶ï¼Œæ±‚å¯¼æ¶‰åŠé™¤æ³•ï¼› 3. Sigmoidå¯¼æ•°å–å€¼èŒƒå›´æ˜¯[0, 0.25]ï¼Œç”±äºç¥ç»ç½‘ç»œåå‘ä¼ æ’­æ—¶çš„â€œé“¾å¼ååº”â€ï¼Œå¾ˆå®¹æ˜“å°±ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±çš„æƒ…å†µã€‚ä¾‹å¦‚å¯¹äºä¸€ä¸ª10å±‚çš„ç½‘ç»œï¼Œ æ ¹æ®ï¼Œç¬¬10å±‚çš„è¯¯å·®ç›¸å¯¹ç¬¬ä¸€å±‚å·ç§¯çš„å‚æ•°çš„æ¢¯åº¦å°†æ˜¯ä¸€ä¸ªéå¸¸å°çš„å€¼ï¼Œè¿™å°±æ˜¯æ‰€è°“çš„â€œæ¢¯åº¦æ¶ˆå¤±â€ã€‚ 4. Sigmoidçš„è¾“å‡ºä¸æ˜¯0å‡å€¼ï¼ˆå³zero-centeredï¼‰ï¼›è¿™ä¼šå¯¼è‡´åä¸€å±‚çš„ç¥ç»å…ƒå°†å¾—åˆ°ä¸Šä¸€å±‚è¾“å‡ºçš„é0å‡å€¼çš„ä¿¡å·ä½œä¸ºè¾“å…¥ï¼Œéšç€ç½‘ç»œçš„åŠ æ·±ï¼Œä¼šæ”¹å˜æ•°æ®çš„åŸå§‹åˆ†å¸ƒã€‚\n3.2 Softmax\n\n\n\n\n\n\n\n\n\né€šè¿‡Softmaxå‡½æ•°å°±å¯ä»¥å°†å¤šåˆ†ç±»çš„è¾“å‡ºå€¼è½¬æ¢ä¸ºèŒƒå›´åœ¨[0, 1]å’Œä¸º1çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n3.1.1 å…¬å¼åŠå¯¼æ•°\n å…¶ä¸­  ä¸ºç¬¬iä¸ªèŠ‚ç‚¹çš„è¾“å‡ºå€¼ï¼ŒCä¸ºè¾“å‡ºèŠ‚ç‚¹çš„ä¸ªæ•°ï¼Œå³åˆ†ç±»çš„ç±»åˆ«ä¸ªæ•°ã€‚\nç”¨è¡¨ç¤ºsoftmax:\n\n3.1.2 å¼•å…¥æŒ‡æ•°å½¢å¼\nä¼˜ç‚¹: 1. æŒ‡æ•°å‡½æ•°æ›²çº¿å‘ˆç°é€’å¢è¶‹åŠ¿ï¼Œæœ€é‡è¦çš„æ˜¯æ–œç‡é€æ¸å¢å¤§ï¼Œä¹Ÿå°±æ˜¯è¯´åœ¨xè½´ä¸Šä¸€ä¸ªå¾ˆå°çš„å˜åŒ–ï¼Œå¯ä»¥å¯¼è‡´yè½´ä¸Šå¾ˆå¤§çš„å˜åŒ–ã€‚è¿™ç§å‡½æ•°æ›²çº¿èƒ½å¤Ÿå°†è¾“å‡ºçš„æ•°å€¼æ‹‰å¼€è·ç¦»ã€‚ 2. åœ¨æ·±åº¦å­¦ä¹ ä¸­é€šå¸¸ä½¿ç”¨åå‘ä¼ æ’­æ±‚è§£æ¢¯åº¦è¿›è€Œä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿›è¡Œå‚æ•°æ›´æ–°çš„è¿‡ç¨‹ï¼Œè€ŒæŒ‡æ•°å‡½æ•°åœ¨æ±‚å¯¼çš„æ—¶å€™æ¯”è¾ƒæ–¹ä¾¿ã€‚å¦‚: \nç¼ºç‚¹(ä¸Šæº¢å’Œä¸‹æº¢é—®é¢˜): æŒ‡æ•°å‡½æ•°çš„æ›²çº¿æ–œç‡é€æ¸å¢å¤§è™½ç„¶èƒ½å¤Ÿå°†è¾“å‡ºå€¼æ‹‰å¼€è·ç¦»ï¼Œä½†æ˜¯ä¹Ÿå¸¦æ¥äº†ç¼ºç‚¹ï¼Œå½“å€¼éå¸¸å¤§çš„è¯ï¼Œè®¡ç®—å¾—åˆ°çš„æ•°å€¼ä¹Ÿä¼šå˜çš„éå¸¸å¤§ï¼Œæ•°å€¼å¯èƒ½ä¼šæº¢å‡ºã€‚åŒç†å½“è¾“å…¥ä¸ºè´Ÿæ•°ä¸”ç»å¯¹å€¼ä¹Ÿå¾ˆå¤§çš„æ—¶å€™ï¼Œä¼šåˆ†å­ã€åˆ†æ¯ä¼šå˜å¾—æå°ï¼Œæœ‰å¯èƒ½å››èˆäº”å…¥ä¸º0ï¼Œå¯¼è‡´ä¸‹æº¢å‡ºã€‚\n\n\n\n\n\n\n\n\n\næœ‰ä¸€ä¸ªæ–¹æ³•è®¡ç®—ä¸Šæº¢çš„æƒ…å†µï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªå˜é‡éƒ½å‡å»æœ€å¤§å€¼ï¼Œç„¶ååšsoftmaxï¼›è¿˜æœ‰ä¸€ç§æ–¹æ³•æ˜¯ç›´æ¥ç”¨log softmax\n\n3.1.3 Sigmoid å’Œ Softmax åŒºåˆ«\nsigmoidå°†ä¸€ä¸ªreal valueæ˜ å°„åˆ°ï¼ˆ0,1ï¼‰çš„åŒºé—´ï¼Œç”¨æ¥åšäºŒåˆ†ç±»ã€‚è€Œ softmax æŠŠä¸€ä¸ª k ç»´çš„real valueå‘é‡ï¼ˆa1,a2,a3,a4â€¦.ï¼‰æ˜ å°„æˆä¸€ä¸ªï¼ˆb1,b2,b3,b4â€¦.ï¼‰å…¶ä¸­ bi æ˜¯ä¸€ä¸ª 0ï½1 çš„å¸¸æ•°ï¼Œè¾“å‡ºç¥ç»å…ƒä¹‹å’Œä¸º 1.0ï¼Œæ‰€ä»¥ç›¸å½“äºæ¦‚ç‡å€¼ï¼Œç„¶åå¯ä»¥æ ¹æ® bi çš„æ¦‚ç‡å¤§å°æ¥è¿›è¡Œå¤šåˆ†ç±»çš„ä»»åŠ¡ã€‚\näºŒåˆ†ç±»é—®é¢˜æ—¶ sigmoid å’Œ softmax æ˜¯ä¸€æ ·çš„ï¼Œæ±‚çš„éƒ½æ˜¯ cross entropy lossï¼Œè€Œ softmax å¯ä»¥ç”¨äºå¤šåˆ†ç±»é—®é¢˜å¤šä¸ªlogisticå›å½’é€šè¿‡å åŠ ä¹ŸåŒæ ·å¯ä»¥å®ç°å¤šåˆ†ç±»çš„æ•ˆæœï¼Œä½†æ˜¯ softmaxå›å½’è¿›è¡Œçš„å¤šåˆ†ç±»ï¼Œç±»ä¸ç±»ä¹‹é—´æ˜¯äº’æ–¥çš„ï¼Œå³ä¸€ä¸ªè¾“å…¥åªèƒ½è¢«å½’ä¸ºä¸€ç±»ï¼›å¤šä¸ªlogisticå›å½’è¿›è¡Œå¤šåˆ†ç±»ï¼Œè¾“å‡ºçš„ç±»åˆ«å¹¶ä¸æ˜¯äº’æ–¥çš„ï¼Œå³\"è‹¹æœ\"è¿™ä¸ªè¯è¯­æ—¢å±äº\"æ°´æœ\"ç±»ä¹Ÿå±äº\"3C\"ç±»åˆ«ã€‚\n\n\n\n\n\n\n\n\n\nä½¿ç”¨softmaxå›å½’æˆ–è€…å¤šä¸ªlogisticså›å½’è§£å†³å¤šåˆ†ç±»é—®é¢˜æ—¶ï¼šä½¿ç”¨å“ªä¸€ä¸ªä¸»è¦æ ¹æ®ç±»åˆ«ä¹‹é—´æ˜¯å¦äº’æ–¥ã€‚å¯¹äºé€‰æ‹©softmaxåˆ†ç±»å™¨è¿˜æ˜¯kä¸ªlogisticsåˆ†ç±»å™¨ï¼Œå–å†³äºæ‰€æœ‰ç±»åˆ«ä¹‹é—´æ˜¯å¦äº’æ–¥ã€‚æ‰€æœ‰ç±»åˆ«ä¹‹é—´æ˜æ˜¾äº’æ–¥ç”¨softmaxï¼›æ‰€æœ‰ç±»åˆ«ä¹‹é—´ä¸äº’æ–¥æœ‰äº¤å‰çš„æƒ…å†µä¸‹æœ€å¥½ç”¨kä¸ªlogisticsåˆ†ç±»å™¨ã€‚\n\n3.1.4 ä¸ºä»€ä¹ˆsoft?\nçŸ¥ä¹: hardmaxæœ€å¤§çš„ç‰¹ç‚¹å°±æ˜¯åªé€‰å‡ºå…¶ä¸­ä¸€ä¸ªæœ€å¤§çš„å€¼ï¼Œå³éé»‘å³ç™½ã€‚ä½†æ˜¯å¾€å¾€åœ¨å®é™…ä¸­è¿™ç§æ–¹å¼æ˜¯ä¸åˆæƒ…ç†çš„ï¼Œæ¯”å¦‚å¯¹äºæ–‡æœ¬åˆ†ç±»æ¥è¯´ï¼Œä¸€ç¯‡æ–‡ç« æˆ–å¤šæˆ–å°‘åŒ…å«ç€å„ç§ä¸»é¢˜ä¿¡æ¯ï¼Œæˆ‘ä»¬æ›´æœŸæœ›å¾—åˆ°æ–‡ç« å¯¹äºæ¯ä¸ªå¯èƒ½çš„æ–‡æœ¬ç±»åˆ«çš„æ¦‚ç‡å€¼ï¼ˆç½®ä¿¡åº¦ï¼‰ï¼Œå¯ä»¥ç®€å•ç†è§£æˆå±äºå¯¹åº”ç±»åˆ«çš„å¯ä¿¡åº¦ã€‚æ‰€ä»¥æ­¤æ—¶ç”¨åˆ°äº†softçš„æ¦‚å¿µï¼ŒSoftmaxçš„å«ä¹‰å°±åœ¨äºä¸å†å”¯ä¸€çš„ç¡®å®šæŸä¸€ä¸ªæœ€å¤§å€¼ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªè¾“å‡ºåˆ†ç±»çš„ç»“æœéƒ½èµ‹äºˆä¸€ä¸ªæ¦‚ç‡å€¼ï¼Œè¡¨ç¤ºå±äºæ¯ä¸ªç±»åˆ«çš„å¯èƒ½æ€§ã€‚\n3.3 ReLU, ReLU6\n\n\n\n\n\n\n\n\n\nreluå’Œsigmoidæ¯”ï¼Œ1.ä¸ä¼šæ¢¯åº¦å¼¥æ•£; 2.ç¨€ç–å‚æ•°; 3è®¡ç®—ç®€å•\nRelu(Rectified Linear Unit)â€”â€”ä¿®æ­£çº¿æ€§å•å…ƒå‡½æ•°ï¼šè¯¥å‡½æ•°å½¢å¼æ¯”è¾ƒç®€å•ï¼Œ å…¬å¼ï¼šrelu=max(0, x)\n\n\n(æ¥æºè§æ°´å°)\n\nä»ä¸Šå›¾å¯çŸ¥ï¼ŒReLUçš„æœ‰æ•ˆå¯¼æ•°æ˜¯å¸¸æ•°1ï¼Œè§£å†³äº†æ·±å±‚ç½‘ç»œä¸­å‡ºç°çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œä¹Ÿå°±ä½¿å¾—æ·±å±‚ç½‘ç»œå¯è®­ç»ƒã€‚åŒæ—¶ReLUåˆæ˜¯éçº¿æ€§å‡½æ•°ï¼Œæ‰€è°“éçº¿æ€§ï¼Œå°±æ˜¯ä¸€é˜¶å¯¼æ•°ä¸ä¸ºå¸¸æ•°ï¼›å¯¹ReLUæ±‚å¯¼ï¼Œåœ¨è¾“å…¥å€¼åˆ†åˆ«ä¸ºæ­£å’Œä¸ºè´Ÿçš„æƒ…å†µä¸‹ï¼Œå¯¼æ•°æ˜¯ä¸åŒçš„ï¼Œå³ReLUçš„å¯¼æ•°ä¸æ˜¯å¸¸æ•°ï¼Œæ‰€ä»¥ReLUæ˜¯éçº¿æ€§çš„ï¼ˆåªæ˜¯ä¸åŒäºSigmoidå’Œtanhï¼Œreluçš„éçº¿æ€§ä¸æ˜¯å…‰æ»‘çš„ï¼‰ã€‚\nReLUåœ¨x&gt;0ä¸‹ï¼Œå¯¼æ•°ä¸ºå¸¸æ•°1çš„ç‰¹ç‚¹ï¼š å¯¼æ•°ä¸ºå¸¸æ•°1çš„å¥½å¤„å°±æ˜¯åœ¨â€œé“¾å¼ååº”â€ä¸­ä¸ä¼šå‡ºç°æ¢¯åº¦æ¶ˆå¤±ï¼Œä½†æ¢¯åº¦ä¸‹é™çš„å¼ºåº¦å°±å®Œå…¨å–å†³äºæƒå€¼çš„ä¹˜ç§¯ï¼Œè¿™æ ·å°±å¯èƒ½ä¼šå‡ºç°æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚è§£å†³è¿™ç±»é—®é¢˜ï¼šä¸€æ˜¯æ§åˆ¶æƒå€¼ï¼Œè®©å®ƒä»¬åœ¨ï¼ˆ0ï¼Œ1ï¼‰èŒƒå›´å†…ï¼›äºŒæ˜¯åšæ¢¯åº¦è£å‰ªï¼Œæ§åˆ¶æ¢¯åº¦ä¸‹é™å¼ºåº¦ï¼Œå¦‚ReLU(x)=min(6, max(0,x))\nReLUåœ¨x&lt;0ä¸‹ï¼Œè¾“å‡ºç½®ä¸º0çš„ç‰¹ç‚¹ï¼š\næè¿°è¯¥ç‰¹å¾å‰ï¼Œéœ€è¦æ˜ç¡®æ·±åº¦å­¦ä¹ çš„ç›®æ ‡ï¼šæ·±åº¦å­¦ä¹ æ˜¯æ ¹æ®å¤§æ‰¹é‡æ ·æœ¬æ•°æ®ï¼Œä»é”™ç»¼å¤æ‚çš„æ•°æ®å…³ç³»ä¸­ï¼Œæ‰¾åˆ°å…³é”®ä¿¡æ¯ï¼ˆå…³é”®ç‰¹å¾ï¼‰ã€‚æ¢å¥è¯è¯´ï¼Œå°±æ˜¯æŠŠå¯†é›†çŸ©é˜µè½¬åŒ–ä¸ºç¨€ç–çŸ©é˜µï¼Œä¿ç•™æ•°æ®çš„å…³é”®ä¿¡æ¯ï¼Œå»é™¤å™ªéŸ³ï¼Œè¿™æ ·çš„æ¨¡å‹å°±æœ‰äº†é²æ£’æ€§ã€‚ReLUå°†x&lt;0çš„è¾“å‡ºç½®ä¸º0ï¼Œå°±æ˜¯ä¸€ä¸ªå»å™ªéŸ³ï¼Œç¨€ç–çŸ©é˜µçš„è¿‡ç¨‹ã€‚è€Œä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè¿™ç§ç¨€ç–æ€§æ˜¯åŠ¨æ€è°ƒèŠ‚çš„ï¼Œç½‘ç»œä¼šè‡ªåŠ¨è°ƒæ•´ç¨€ç–æ¯”ä¾‹ï¼Œä¿è¯çŸ©é˜µæœ‰æœ€ä¼˜çš„æœ‰æ•ˆç‰¹å¾ã€‚ ä½†æ˜¯ReLU å¼ºåˆ¶å°†x&lt;0éƒ¨åˆ†çš„è¾“å‡ºç½®ä¸º0ï¼ˆç½®ä¸º0å°±æ˜¯å±è”½è¯¥ç‰¹å¾ï¼‰ï¼Œå¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹æ— æ³•å­¦ä¹ åˆ°æœ‰æ•ˆç‰¹å¾ï¼Œæ‰€ä»¥å¦‚æœå­¦ä¹ ç‡è®¾ç½®çš„å¤ªå¤§ï¼Œå°±å¯èƒ½ä¼šå¯¼è‡´ç½‘ç»œçš„å¤§éƒ¨åˆ†ç¥ç»å…ƒå¤„äºâ€˜deadâ€™çŠ¶æ€ï¼Œæ‰€ä»¥ä½¿ç”¨ReLUçš„ç½‘ç»œï¼Œå­¦ä¹ ç‡ä¸èƒ½è®¾ç½®å¤ªå¤§ã€‚\nReLUä½œä¸ºæ¿€æ´»å‡½æ•°çš„ç‰¹ç‚¹ï¼š 1. ç›¸æ¯”Sigmoidå’Œtanhï¼ŒReLUæ‘’å¼ƒäº†å¤æ‚çš„è®¡ç®—ï¼Œæé«˜äº†è¿ç®—é€Ÿåº¦ã€‚ 2. è§£å†³äº†æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œæ”¶æ•›é€Ÿåº¦å¿«äºSigmoidå’Œtanhå‡½æ•°ï¼Œä½†è¦é˜²èŒƒReLUçš„æ¢¯åº¦çˆ†ç‚¸ 3. å®¹æ˜“å¾—åˆ°æ›´å¥½çš„æ¨¡å‹ï¼Œä½†ä¹Ÿè¦é˜²æ­¢è®­ç»ƒä¸­å‡ºç°æ¨¡å‹â€˜Deadâ€™æƒ…å†µã€‚\nreluå°äº0ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±ï¼Œæ€ä¹ˆåŠï¼Ÿ &gt; åœ¨å°äºçš„æ—¶å€™ï¼Œæ¿€æ´»å‡½æ•°æ¢¯åº¦ä¸ºé›¶ï¼Œæ¢¯åº¦æ¶ˆå¤±ï¼Œç¥ç»å…ƒä¸æ›´æ–°ï¼Œå˜æˆäº†æ­»äº¡èŠ‚ç‚¹ã€‚å‡ºç°è¿™ä¸ªåŸå› å¯èƒ½æ˜¯å› ä¸ºå­¦ä¹ ç‡å¤ªå¤§ï¼Œå¯¼è‡´wæ›´æ–°å·¨å¤§ï¼Œä½¿å¾—è¾“å…¥æ•°æ®åœ¨ç»è¿‡è¿™ä¸ªç¥ç»å…ƒçš„æ—¶å€™ï¼Œè¾“å‡ºå€¼å°äº0ï¼Œä»è€Œç»è¿‡æ¿€æ´»å‡½æ•°çš„æ—¶å€™ä¸º0ï¼Œä»æ­¤ä¸å†æ›´æ–°ã€‚æ‰€ä»¥reluä¸ºæ¿€æ´»å‡½æ•°ï¼Œå­¦ä¹ ç‡ä¸èƒ½å¤ªå¤§.\nRelu6:\nReLU6(x)=min(max(0,x),6) \nMobileNetV1 ä¸­ä½¿ç”¨ ReLU6ã€‚ReLU6 å°±æ˜¯æ™®é€šçš„ReLUï¼Œä½†æ˜¯é™åˆ¶æœ€å¤§è¾“å‡ºä¸º6ã€‚è¿™æ˜¯ä¸ºäº†åœ¨ç§»åŠ¨ç«¯è®¾å¤‡ float16/int8 çš„ä½ç²¾åº¦çš„æ—¶å€™ä¹Ÿèƒ½ æœ‰å¾ˆå¥½çš„æ•°å€¼åˆ†è¾¨ç‡ã€‚å¦‚æœå¯¹ ReLU çš„æ¿€æ´»èŒƒå›´ä¸åŠ é™åˆ¶ï¼Œè¾“å‡ºèŒƒå›´ä¸º 0 åˆ°æ­£æ— ç©·ï¼Œå¦‚æœæ¿€æ´»å€¼éå¸¸å¤§ï¼Œåˆ†å¸ƒåœ¨ä¸€ä¸ªå¾ˆå¤§çš„èŒƒå›´å†…ï¼Œåˆ™ä½ç²¾åº¦çš„ float16/int8 æ— æ³•å¾ˆå¥½åœ°ç²¾ç¡®æè¿°å¦‚æ­¤å¤§èŒƒå›´çš„æ•°å€¼ï¼Œå¸¦æ¥ç²¾åº¦æŸå¤±ã€‚\nrelu6çš„å¥½å¤„ï¼š 1. å¯ä»¥è®©æ¨¡å‹æ›´æ—©åœ°å­¦åˆ°ç¨€ç–ç‰¹å¾ã€‚å¹¶æ²¡æœ‰å¯ä¿¡çš„ç†è®ºæ¨å¯¼ï¼Œä½œè€…è¯•éªŒå‡ºæ¥çš„ç»“æœæ˜¯è¿™æ ·çš„ã€‚æ³¨æ„ï¼Œrelu6åªæ˜¯æ¯”reluæ›´æ—©çš„å­¦ä¹ åˆ°ç¨€ç–ç‰¹å¾ï¼Œè€Œä¸æ˜¯è¯´reluå­¦ä¸åˆ°ç¨€ç–ç‰¹å¾ã€‚ 2. å¯ä»¥é˜²æ­¢æ•°å€¼çˆ†ç‚¸ã€‚ 3. å¢å¼ºæµ®ç‚¹æ•°çš„å°æ•°ä½è¡¨è¾¾èƒ½åŠ›ã€‚å› ä¸ºæ•´æ•°ä½æœ€å¤§æ˜¯6ï¼Œæ‰€ä»¥åªå 3ä¸ªbitï¼Œå…¶ä»–bitå…¨éƒ¨ç”¨æ¥è¡¨è¾¾å°æ•°ä½ã€‚\n3.4 Leaky ReLU, PReLUï¼ˆParametric Reluï¼‰, RReLUï¼ˆRandom ReLUï¼‰\nä¸ºäº†é˜²æ­¢æ¨¡å‹çš„â€˜Deadâ€™æƒ…å†µï¼Œåäººå°†x&lt;0éƒ¨åˆ†å¹¶æ²¡æœ‰ç›´æ¥ç½®ä¸º0ï¼Œè€Œæ˜¯ç»™äº†ä¸€ä¸ªå¾ˆå°çš„è´Ÿæ•°æ¢¯åº¦å€¼Î±ã€‚\nLeaky ReLUä¸­çš„Î±ä¸ºå¸¸æ•°ï¼Œä¸€èˆ¬è®¾ç½® 0.01ã€‚è¿™ä¸ªå‡½æ•°é€šå¸¸æ¯” Relu æ¿€æ´»å‡½æ•°æ•ˆæœè¦å¥½ï¼Œä½†æ˜¯æ•ˆæœä¸æ˜¯å¾ˆç¨³å®šï¼Œæ‰€ä»¥åœ¨å®é™…ä¸­ Leaky ReLu ä½¿ç”¨çš„å¹¶ä¸å¤šã€‚\nPReluï¼ˆå‚æ•°åŒ–ä¿®æ­£çº¿æ€§å•å…ƒï¼‰ä¸­çš„Î±ä½œä¸ºä¸€ä¸ªå¯å­¦ä¹ çš„å‚æ•°ï¼Œä¼šåœ¨è®­ç»ƒçš„è¿‡ç¨‹ä¸­è¿›è¡Œæ›´æ–°ã€‚\nRReLUï¼ˆéšæœºçº æ­£çº¿æ€§å•å…ƒï¼‰ä¹Ÿæ˜¯Leaky ReLUçš„ä¸€ä¸ªå˜ä½“ã€‚åœ¨RReLUä¸­ï¼Œè´Ÿå€¼çš„æ–œç‡åœ¨è®­ç»ƒä¸­æ˜¯éšæœºçš„ï¼Œåœ¨ä¹‹åçš„æµ‹è¯•ä¸­å°±å˜æˆäº†å›ºå®šçš„äº†ã€‚RReLUçš„äº®ç‚¹åœ¨äºï¼Œåœ¨è®­ç»ƒç¯èŠ‚ä¸­ï¼Œæ˜¯ä»ä¸€ä¸ªå‡åŒ€çš„åˆ†å¸ƒU(I,u)ä¸­éšæœºæŠ½å–çš„æ•°å€¼ã€‚\n\n\n(æ¥æºè§æ°´å°)\n\n3.5 tanh\ntanhä¸ºåŒæ›²æ­£åˆ‡å‡½æ•°ã€‚tanhå’Œ sigmoid ç›¸ä¼¼ï¼Œéƒ½å±äºé¥±å’Œæ¿€æ´»å‡½æ•°ï¼ŒåŒºåˆ«åœ¨äºè¾“å‡ºå€¼èŒƒå›´ç”± (0,1) å˜ä¸ºäº† (-1,1)ï¼Œå¯ä»¥æŠŠ tanh å‡½æ•°çœ‹åšæ˜¯ sigmoid å‘ä¸‹å¹³ç§»å’Œæ‹‰ä¼¸åçš„ç»“æœã€‚\n3.4.1 å…¬å¼åŠå¯¼æ•°\n å…¬å¼1  å…¬å¼2  å…¬å¼3\nä»å…¬å¼2ä¸­ï¼Œå¯ä»¥æ›´åŠ æ¸…æ™°çœ‹å‡ºtanhä¸sigmoidå‡½æ•°çš„å…³ç³»ï¼ˆå¹³ç§»+æ‹‰ä¼¸ï¼‰\n3.4.2 æ›²çº¿\n\n\n(æ¥æºè§æ°´å°)\n\n3.4.3 ç‰¹ç‚¹\nç›¸æ¯”Sigmoidå‡½æ•°ï¼Œ 1. tanhçš„è¾“å‡ºèŒƒå›´æ—¶(-1, 1)ï¼Œè§£å†³äº†Sigmoidå‡½æ•°çš„ä¸æ˜¯zero-centeredè¾“å‡ºé—®é¢˜ï¼› 2. å¹‚è¿ç®—çš„é—®é¢˜ä»ç„¶å­˜åœ¨ï¼› 3. tanhå¯¼æ•°èŒƒå›´åœ¨(0, 1)ä¹‹é—´ï¼Œç›¸æ¯”sigmoidçš„(0, 0.25)ï¼Œæ¢¯åº¦æ¶ˆå¤±ï¼ˆgradient vanishingï¼‰é—®é¢˜ä¼šå¾—åˆ°ç¼“è§£ï¼Œä½†ä»ç„¶è¿˜ä¼šå­˜åœ¨ã€‚\n3.6 softplus\nSoftpluså‡½æ•°æ˜¯Logistic-Sigmoidå‡½æ•°åŸå‡½æ•°,  åŠ äº†1æ˜¯ä¸ºäº†ä¿è¯éè´Ÿæ€§ã€‚Softpluså¯ä»¥çœ‹ä½œæ˜¯å¹³æ»‘ç‰ˆçš„reluã€‚çº¢è‰²çš„å³ä¸ºReLUã€‚\n\n3.7 Swish, hard-Swish\nSwish:Î²æ˜¯ä¸ªå¸¸æ•°æˆ–è€…å¯ä»¥è®­ç»ƒçš„å‚æ•°ã€‚ å’Œ ReLU ä¸€æ ·ï¼ŒSwish æ— ä¸Šç•Œæœ‰ä¸‹ç•Œã€‚ä¸ ReLU ä¸åŒçš„æ˜¯ï¼ŒSwish æ˜¯å¹³æ»‘ä¸”éå•è°ƒçš„å‡½æ•°ã€‚äº‹å®ä¸Šï¼ŒSwish çš„éå•è°ƒç‰¹æ€§æŠŠå®ƒä¸å¤§å¤šæ•°å¸¸è§çš„æ¿€æ´»å‡½æ•°åŒºåˆ«å¼€æ¥ã€‚\nf(x) = x*sigmoid(Î²x) f'(x) = sigmoid(Î²x) + x(Î²*sigmoid(Î²x))\n\n\n\n\n\n\n\n\n\n\nSwishå‡½æ•°å¯ä»¥çœ‹åšæ˜¯ä»‹äºçº¿æ€§å‡½æ•°ä¸ReLUå‡½æ•°ä¹‹é—´çš„å¹³æ»‘å‡½æ•°.\nhard-Swish(MobileNetV3): è™½ç„¶è¿™ç§Swishéçº¿æ€§æé«˜äº†ç²¾åº¦ï¼Œä½†æ˜¯åœ¨åµŒå…¥å¼ç¯å¢ƒä¸­ï¼Œä»–çš„æˆæœ¬æ˜¯éé›¶çš„ï¼Œå› ä¸ºåœ¨ç§»åŠ¨è®¾å¤‡ä¸Šè®¡ç®—sigmoidå‡½æ•°ä»£ä»·è¦å¤§å¾—å¤šã€‚ å› æ­¤ä½œè€…ä½¿ç”¨hard-Swishå’Œhard-Sigmoidæ›¿æ¢äº†ReLU6å’ŒSE-blockä¸­çš„Sigmoidå±‚ï¼Œä½†æ˜¯åªæ˜¯åœ¨ç½‘ç»œçš„ååŠæ®µæ‰å°†ReLU6æ›¿æ¢ä¸ºh-Swishï¼Œå› ä¸ºä½œè€…å‘ç°Swishå‡½æ•°åªæœ‰åœ¨æ›´æ·±çš„ç½‘ç»œå±‚ä½¿ç”¨æ‰èƒ½ä½“ç°å…¶ä¼˜åŠ¿ã€‚ é¦–å…ˆæ˜¯è‚¯å®šäº†Swishçš„é‡è¦æ€§ï¼Œç„¶åæŒ‡å‡ºåœ¨é‡åŒ–æ¨¡å¼ä¸‹ï¼ŒSigmoidå‡½æ•°æ¯”ReLU6çš„è®¡ç®—ä»£ä»·å¤§çš„å¤šï¼Œæ‰€ä»¥æ‰æœ‰äº†è¿™ä¸ªReLU6ç‰ˆæœ¬çš„h-Swishã€‚\n\n\n\n\n\n\n\n\n\n\n\nwhy hardï¼Ÿrelu6æœ‰ä¸Šç•Œã€‚å¦‚æœå¯¹relu6å†é™¤6å†å‘å·¦å¹³ç§»ä¸‰ä¸ªå•ä½ï¼Œå°±ä¼šå¾—åˆ°ä¸€æ¡ç±»ä¼¼äºsigmoidå‡½æ•° \n3.8 Mish\nMish: y=*tanh(ln(1+exp(x)))\nMishå’ŒSwishä¸­å‚æ•°=1çš„æ›²çº¿å¯¹æ¯”ï¼šï¼ˆç¬¬ä¸€å¼ æ˜¯åŸå§‹å‡½æ•°ï¼Œç¬¬äºŒå¼ æ˜¯å¯¼æ•°ï¼‰\n\n\n\n\n\n\n\n\n\n\nä»¥ä¸Šæ— è¾¹ç•Œ(å³æ­£å€¼å¯ä»¥è¾¾åˆ°ä»»ä½•é«˜åº¦)é¿å…äº†ç”±äºå°é¡¶è€Œå¯¼è‡´çš„é¥±å’Œã€‚ç†è®ºä¸Šå¯¹è´Ÿå€¼çš„è½»å¾®å…è®¸å…è®¸æ›´å¥½çš„æ¢¯åº¦æµï¼Œè€Œä¸æ˜¯åƒReLUä¸­é‚£æ ·çš„ç¡¬é›¶è¾¹ç•Œã€‚æœ€åï¼Œå¯èƒ½ä¹Ÿæ˜¯æœ€é‡è¦çš„ï¼Œç›®å‰çš„æƒ³æ³•æ˜¯ï¼Œå¹³æ»‘çš„æ¿€æ´»å‡½æ•°å…è®¸æ›´å¥½çš„ä¿¡æ¯æ·±å…¥ç¥ç»ç½‘ç»œï¼Œä»è€Œå¾—åˆ°æ›´å¥½çš„å‡†ç¡®æ€§å’Œæ³›åŒ–ã€‚è¦åŒºåˆ«å¯èƒ½æ˜¯Mishå‡½æ•°åœ¨æ›²çº¿ä¸Šå‡ ä¹æ‰€æœ‰ç‚¹ä¸Šçš„å¹³æ»‘åº¦.\n3.9 ç¥ç»ç½‘ç»œä¸­çš„æ¿€æ´»å‡½æ•°ä¸ºä»€ä¹ˆéƒ½æ˜¯å¹³æ»‘æˆ–è¿‘ä¼¼å¹³æ»‘çš„ï¼Ÿ\n\næ¿€æ´»å€¼ä¸å­˜åœ¨åƒæ„ŸçŸ¥æœºé‚£æ ·çš„é˜¶è·ƒç°è±¡ï¼Œæ¯”è¾ƒå®¹æ˜“æ”¶æ•›\nå¾ˆå¤šå¹³æ»‘å‡½æ•°çš„å¼•å…¥ï¼Œä½¿å¾—æ¨¡å‹æœ‰äº†éçº¿æ€§å› ç´ ï¼Œå› æ­¤å¯ä»¥è¯†åˆ«æ›´åŠ å¤æ‚çš„æ¨¡å¼\nå¹³æ»‘å‡½æ•°æ˜¯å¯å¯¼çš„ï¼Œè¿™ä¾¿äºæ¢¯åº¦çš„è®¡ç®—ä¸æ›´æ–°ã€‚è€Œå¯¹åƒæ„ŸçŸ¥æœºè¿™æ ·çš„æ¿€æ´»å‡½æ•°ï¼Œæ¢¯åº¦çš„æ›´æ–°éå¸¸å›°éš¾ï¼›å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸¤ä¸ªæ¿€æ´»å€¼ç›¸åŒçš„ç‚¹ï¼Œä»åŒä¸€ä¸ªç‚¹åˆ°å¦å¤–ä¸€ä¸ªç‚¹ï¼Œä¼¼ä¹æ˜¯æ²¡æœ‰å¾ˆå¥½çš„ç­–ç•¥æ¥æ›´æ–°æ¢¯åº¦\nå¯å¯¼ï¼Œå› æ­¤å¯ä»¥æŒ‡å®šæ›´åŠ çµæ´»çš„æ¢¯åº¦æ›´æ–°è§„åˆ™ï¼ŒåŠ é€Ÿæ¨¡å‹è®­ç»ƒ\n\n4. æ­£åˆ™åŒ–ç›¸å…³\n4.1 æ­£åˆ™åŒ–çš„æœ¬è´¨\nçŸ¥ä¹å›ç­”\né‡ç‚¹è®°å½•ä¸‹ï¼š å¦‚ä½•å»é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé¦–å…ˆæƒ³åˆ°çš„å°±æ˜¯æ§åˆ¶Nçš„æ•°é‡å§ï¼Œå³è®©Næœ€å°åŒ–å§ï¼Œè€Œè®©Næœ€å°åŒ–ï¼Œå…¶å®å°±æ˜¯è®©Wå‘é‡ä¸­é¡¹çš„ä¸ªæ•°æœ€å°åŒ–ï¼Œå…¶ä¸­ã€‚ so,å¦‚ä½•æ±‚è§£â€œè®©Wå‘é‡ä¸­é¡¹çš„ä¸ªæ•°æœ€å°åŒ–\"? æ²¡é”™ï¼Œè¿™å°±æ˜¯0èŒƒæ•°çš„æ¦‚å¿µï¼ä»€ä¹ˆæ˜¯èŒƒæ•°ï¼Œè¿™é‡Œåªæ˜¯ç»™å‡ºä¸ª0-2èŒƒæ•°å®šä¹‰: 0èŒƒæ•°ï¼Œå‘é‡ä¸­éé›¶å…ƒç´ çš„ä¸ªæ•°ã€‚ 1èŒƒæ•°ï¼Œä¸ºç»å¯¹å€¼ä¹‹å’Œã€‚ 2èŒƒæ•°ï¼Œå°±æ˜¯é€šå¸¸æ„ä¹‰ä¸Šçš„æ¨¡ã€‚\n\n\n\n\n\n\n\n\n\næ±‚è§£â€œè®©Wå‘é‡ä¸­é¡¹çš„ä¸ªæ•°æœ€å°åŒ–â€å—ï¼Ÿæ€ä¹ˆä¸0èŒƒæ•°çš„å®šä¹‰æœ‰ç‚¹ä¸ä¸€æ ·ï¼Œä¸€å¥è¯ï¼Œå‘é‡ä¸­0å…ƒç´ ï¼Œå¯¹åº”çš„xæ ·æœ¬ä¸­çš„é¡¹æˆ‘ä»¬æ˜¯ä¸éœ€è¦è€ƒè™‘çš„ï¼Œå¯ä»¥ç æ‰ã€‚å› ä¸º0*æ²¡æœ‰å•¥æ„ä¹‰ï¼Œè¯´æ˜é¡¹æ²¡æœ‰ä»»ä½•æƒé‡\næ‰€ä»¥ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé™¤äº†éœ€è¦å‰é¢çš„ç›¸åŠ é¡¹æœ€å°ï¼Œå³æœ€å°ï¼Œæˆ‘ä»¬è¿˜éœ€è¦è®©æœ€å°ï¼Œæ‰€ä»¥ï¼Œä¸ºäº†åŒæ—¶æ»¡è¶³ä¸¤é¡¹éƒ½æœ€å°åŒ–ï¼Œå’±ä»¬å¯ä»¥æ±‚è§£è®©å’Œr(d)ä¹‹å’Œæœ€å°ï¼Œè¿™æ ·ä¸å°±åŒæ—¶æ»¡è¶³ä¸¤è€…äº†å—ï¼Ÿå¦‚æœr(d) è¿‡å¤§ï¼Œå†å°ä¹Ÿæ²¡ç”¨ï¼›ç›¸år(d)å†å°ï¼Œå¤ªå¤§ä¹Ÿå¤±å»äº†é—®é¢˜çš„æ„ä¹‰ã€‚è¯´åˆ°è¿™é‡Œå·²ç»å›ç­”äº†ï¼Œé‚£å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦æœ‰ä¸ªr(d)é¡¹ï¼Œä¸ºä»€ä¹ˆr(d)èƒ½å¤Ÿé˜²æ­¢è¿‡æ‹ŸåˆåŸå› äº†ã€‚\n\n\n\n\n\n\n\n\n\n1èŒƒæ•°å’Œ0èŒƒæ•°å¯ä»¥å®ç°ç¨€ç–ï¼Œ1å› å…·æœ‰æ¯”L0æ›´å¥½çš„ä¼˜åŒ–æ±‚è§£ç‰¹æ€§è€Œè¢«å¹¿æ³›åº”ç”¨ã€‚ç„¶åL2èŒƒæ•°ï¼Œæ˜¯ä¸‹é¢è¿™ä¹ˆç†è§£çš„ï¼Œæˆ‘å°±ç›´æ¥æŸ¥åˆ«äººç»™çš„è§£é‡Šå¥½äº†ï¼Œåæ­£ç®€å•ï¼Œå°±ä¸è‡ªå·±åŠ¨è„‘å­è§£é‡Šäº†ï¼š L2èŒƒæ•°æ˜¯æŒ‡å‘é‡å„å…ƒç´ çš„å¹³æ–¹å’Œç„¶åæ±‚å¹³æ–¹æ ¹ã€‚æˆ‘ä»¬è®©L2èŒƒæ•°çš„æ­£åˆ™é¡¹||W||2æœ€å°ï¼Œå¯ä»¥ä½¿å¾—Wçš„æ¯ä¸ªå…ƒç´ éƒ½å¾ˆå°ï¼Œéƒ½æ¥è¿‘äº0ï¼Œä½†ä¸L1èŒƒæ•°ä¸åŒï¼Œå®ƒä¸ä¼šè®©å®ƒç­‰äº0ï¼Œè€Œæ˜¯æ¥è¿‘äº0ï¼Œè¿™é‡Œæ˜¯æœ‰å¾ˆå¤§çš„åŒºåˆ«çš„å“¦ï¼›æ‰€ä»¥å¤§å®¶æ¯”èµ·1èŒƒæ•°ï¼Œæ›´é’Ÿçˆ±2èŒƒæ•°ã€‚\n4.2 L1å’ŒL2æ­£åˆ™åŒ–\nL1æ­£åˆ™åŒ–ä¸L2æ­£åˆ™åŒ–\n\n \né™ä½è¿‡æ‹Ÿåˆç¨‹åº¦ï¼š\næ­£åˆ™åŒ–ä¹‹æ‰€ä»¥èƒ½å¤Ÿé™ä½è¿‡æ‹Ÿåˆçš„åŸå› åœ¨äºï¼Œæ­£åˆ™åŒ–æ˜¯ç»“æ„é£é™©æœ€å°åŒ–çš„ä¸€ç§ç­–ç•¥å®ç°ã€‚\nç»™loss functionåŠ ä¸Šæ­£åˆ™åŒ–é¡¹ï¼Œèƒ½ä½¿å¾—æ–°å¾—åˆ°çš„ä¼˜åŒ–ç›®æ ‡å‡½æ•°h = f+normalï¼Œéœ€è¦åœ¨få’Œnormalä¸­åšä¸€ä¸ªæƒè¡¡ï¼ˆtrade-offï¼‰ï¼Œå¦‚æœè¿˜åƒåŸæ¥åªä¼˜åŒ–fçš„æƒ…å†µä¸‹ï¼Œé‚£å¯èƒ½å¾—åˆ°ä¸€ç»„è§£æ¯”è¾ƒå¤æ‚ï¼Œä½¿å¾—æ­£åˆ™é¡¹normalæ¯”è¾ƒå¤§ï¼Œé‚£ä¹ˆhå°±ä¸æ˜¯æœ€ä¼˜çš„ï¼Œå› æ­¤å¯ä»¥çœ‹å‡ºåŠ æ­£åˆ™é¡¹èƒ½è®©è§£æ›´åŠ ç®€å•ï¼Œç¬¦åˆå¥¥å¡å§†å‰ƒåˆ€ç†è®ºï¼ŒåŒæ—¶ä¹Ÿæ¯”è¾ƒç¬¦åˆåœ¨åå·®å’Œæ–¹å·®ï¼ˆæ–¹å·®è¡¨ç¤ºæ¨¡å‹çš„å¤æ‚åº¦ï¼‰åˆ†æä¸­ï¼Œé€šè¿‡é™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œå¾—åˆ°æ›´å°çš„æ³›åŒ–è¯¯å·®ï¼Œé™ä½è¿‡æ‹Ÿåˆç¨‹åº¦ã€‚\nL1æ­£åˆ™åŒ–å’ŒL2æ­£åˆ™åŒ–ï¼š\nL1æ­£åˆ™åŒ–å°±æ˜¯åœ¨loss functionåè¾¹æ‰€åŠ æ­£åˆ™é¡¹ä¸ºL1èŒƒæ•°ï¼ŒåŠ ä¸ŠL1èŒƒæ•°å®¹æ˜“å¾—åˆ°ç¨€ç–è§£ï¼ˆ0æ¯”è¾ƒå¤šï¼‰ã€‚ L2æ­£åˆ™åŒ–å°±æ˜¯loss functionåè¾¹æ‰€åŠ æ­£åˆ™é¡¹ä¸ºL2èŒƒæ•°çš„å¹³æ–¹ï¼ŒåŠ ä¸ŠL2æ­£åˆ™ç›¸æ¯”äºL1æ­£åˆ™æ¥è¯´ï¼Œå¾—åˆ°çš„è§£æ¯”è¾ƒå¹³æ»‘ï¼ˆä¸æ˜¯ç¨€ç–ï¼‰ï¼Œä½†æ˜¯åŒæ ·èƒ½å¤Ÿä¿è¯è§£ä¸­æ¥è¿‘äº0ï¼ˆä½†ä¸æ˜¯ç­‰äº0ï¼Œæ‰€ä»¥ç›¸å¯¹å¹³æ»‘ï¼‰çš„ç»´åº¦æ¯”è¾ƒå¤šï¼Œé™ä½æ¨¡å‹çš„å¤æ‚åº¦ã€‚\nl1 ç›¸æ¯”äº l2 ä¸ºä»€ä¹ˆå®¹æ˜“è·å¾—ç¨€ç–è§£ï¼Ÿ\nä¸¤ç§ regularization èƒ½ä¸èƒ½æŠŠæœ€ä¼˜çš„ x å˜æˆ 0ï¼Œå–å†³äºåŸå…ˆçš„è´¹ç”¨å‡½æ•°åœ¨ 0 ç‚¹å¤„çš„å¯¼æ•°ã€‚å¦‚æœæœ¬æ¥å¯¼æ•°ä¸ä¸º 0ï¼Œé‚£ä¹ˆæ–½åŠ  L2 regularization åå¯¼æ•°ä¾ç„¶ä¸ä¸º 0ï¼Œæœ€ä¼˜çš„ x ä¹Ÿä¸ä¼šå˜æˆ 0ã€‚è€Œæ–½åŠ  L1 regularization æ—¶ï¼Œåªè¦ regularization é¡¹çš„ç³»æ•° C å¤§äºåŸå…ˆè´¹ç”¨å‡½æ•°åœ¨ 0 ç‚¹å¤„çš„å¯¼æ•°çš„ç»å¯¹å€¼ï¼Œx = 0 å°±ä¼šå˜æˆä¸€ä¸ªæå°å€¼ç‚¹ã€‚ä¸Šé¢åªåˆ†æäº†ä¸€ä¸ªå‚æ•° xã€‚äº‹å®ä¸Š L1 regularization ä¼šä½¿å¾—è®¸å¤šå‚æ•°çš„æœ€ä¼˜å€¼å˜æˆ 0ï¼Œè¿™æ ·æ¨¡å‹å°±ç¨€ç–äº†ã€‚\nL1å’ŒL2æ­£åˆ™åŒ–çš„åŒºåˆ« 1. ä»æ±‚è§£æ•ˆç‡ä¸Šçœ‹ï¼š L2æŸå¤±å‡½æ•°æ˜¯å¯å¯¼çš„ï¼ŒL2æ­£åˆ™åŒ–ä¹Ÿæ˜¯å¯å¯¼çš„ï¼Œæ‰€ä»¥L2æ­£åˆ™åŒ–æ˜¯æœ‰è§£æè§£çš„ï¼Œæ±‚è§£çš„æ•ˆç‡é«˜ã€‚ä½†æ˜¯L1æ­£åˆ™åŒ–åœ¨é›¶ç‚¹å¤„æ˜¯ä¸å¯å¯¼çš„ï¼Œæ‰€ä»¥å®ƒæ˜¯æ²¡æœ‰è§£æè§£çš„ï¼Œå¦‚æœé—®é¢˜æ˜¯ä¸€ä¸ªç¨€ç–é—®é¢˜ï¼ˆç®€å•åœ°è¯´å°±æ˜¯å¾ˆå¤šç‰¹å¾çš„ç³»æ•°ä¸º0ï¼‰ï¼Œé‚£ä¹ˆå¯ä»¥é‡‡ç”¨ç¨€ç–ç®—æ³•æ±‚è§£ï¼Œå¦‚æœé—®é¢˜ä¸æ˜¯ç¨€ç–çš„ï¼Œé‚£æ±‚è§£çš„æ•ˆç‡å°±å¾ˆä½äº†ã€‚ 2. ä»è§£çš„è§’åº¦çœ‹ï¼šL2æ­£åˆ™åŒ–å¾—åˆ°ä¸ä¼šæ˜¯ç¨€ç–æ€§ç»“æœï¼Œä½†æ˜¯L1æ­£åˆ™åŒ–å¯èƒ½ä¼šå¾—åˆ°ç¨€ç–ç»“æœã€‚ 3. L1æ­£åˆ™åŒ–çš„ä¼˜ç‚¹åœ¨äºå®ƒå¯ä»¥è¿›è¡Œç‰¹å¾é€‰æ‹©ï¼ˆç”±äºå…¶ç»“æœæ˜¯ç¨€ç–çš„ï¼Œå³å¾ˆå¤šå˜é‡å‰çš„ç³»æ•°ä¸º0ï¼Œé‚£ä¹ˆè¿™äº›ç³»æ•°ä¸º0çš„å˜é‡ï¼Œå°±æ˜¯è¢«æ·˜æ±°çš„å˜é‡ï¼‰ï¼›ä½†æ˜¯L2æ­£åˆ™åŒ–åˆ™ä¸è¡Œã€‚ï¼ˆå› ä¸ºL2æ­£åˆ™åŒ–çš„ç»“æœä¸æ˜¯ç¨€ç–çš„ï¼‰ã€‚æ‰€ä»¥å¯ä»¥è®¤ä¸ºL1æ­£åˆ™åŒ–æ˜¯ä¸€ç§åµŒå…¥å¼çš„ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œå…¶ç‰¹å¾é€‰æ‹©è¿‡ç¨‹ä¸æ¨¡å‹çš„å»ºç«‹è¿‡ç¨‹èä¸ºä¸€ä½“ï¼ŒåŒæ—¶å®Œæˆã€‚\nL1èŒƒæ•°ç¬¦åˆæ‹‰æ™®æ‹‰æ–¯åˆ†å¸ƒï¼ŒL2èŒƒæ•°ç¬¦åˆé«˜æ–¯åˆ†å¸ƒï¼Œæ€ä¹ˆç†è§£ï¼Ÿ\n5 ç½‘ç»œæ¢¯åº¦ä¼˜åŒ–ä¸‹é™æ–¹æ³•\n5.1 SGD\nSGDä¸€èˆ¬éƒ½æŒ‡mini-batch gradient descentã€‚ SGDå°±æ˜¯æ¯ä¸€æ¬¡è¿­ä»£è®¡ç®—mini-batchçš„æ¢¯åº¦ï¼Œç„¶åå¯¹å‚æ•°è¿›è¡Œæ›´æ–°ï¼Œæ˜¯æœ€å¸¸è§çš„ä¼˜åŒ–æ–¹æ³•äº†ã€‚å³ï¼š \nå…¶ä¸­ï¼Œï¼Œæ˜¯æ¢¯åº¦ SGDå®Œå…¨ä¾èµ–äºå½“å‰batchçš„æ¢¯åº¦ï¼Œæ‰€ä»¥\nç¼ºç‚¹:\n\né€‰æ‹©åˆé€‚çš„learning rateæ¯”è¾ƒå›°éš¾ - å¯¹æ‰€æœ‰çš„å‚æ•°æ›´æ–°ä½¿ç”¨åŒæ ·çš„learning rateã€‚å¯¹äºç¨€ç–æ•°æ®æˆ–è€…ç‰¹å¾ï¼Œæœ‰æ—¶æˆ‘ä»¬å¯èƒ½æƒ³æ›´æ–°å¿«ä¸€äº›å¯¹äºä¸ç»å¸¸å‡ºç°çš„ç‰¹å¾ï¼Œå¯¹äºå¸¸å‡ºç°çš„ç‰¹å¾æ›´æ–°æ…¢ä¸€äº›ï¼Œè¿™æ—¶å€™SGDå°±ä¸å¤ªèƒ½æ»¡è¶³è¦æ±‚äº†\nSGDå®¹æ˜“æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ï¼Œå¹¶ä¸”åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½è¢«å›°åœ¨éç‚¹;\n\n5.2 Momentum\nmomentumæ˜¯æ¨¡æ‹Ÿç‰©ç†é‡ŒåŠ¨é‡çš„æ¦‚å¿µï¼Œç§¯ç´¯ä¹‹å‰çš„åŠ¨é‡æ¥æ›¿ä»£çœŸæ­£çš„æ¢¯åº¦ã€‚å…¬å¼å¦‚ä¸‹ï¼š\n\nç‰¹ç‚¹ï¼š ä¸‹é™åˆæœŸæ—¶ï¼Œä½¿ç”¨ä¸Šä¸€æ¬¡å‚æ•°æ›´æ–°ï¼Œä¸‹é™æ–¹å‘ä¸€è‡´ï¼Œä¹˜ä¸Šè¾ƒå¤§çš„Î¼èƒ½å¤Ÿè¿›è¡Œå¾ˆå¥½çš„åŠ é€Ÿ ä¸‹é™ä¸­åæœŸæ—¶ï¼Œåœ¨å±€éƒ¨æœ€å°å€¼æ¥å›éœ‡è¡çš„æ—¶å€™ï¼Œgradient-&gt;0ï¼ŒÎ¼ä½¿å¾—æ›´æ–°å¹…åº¦å¢å¤§ï¼Œè·³å‡ºé™·é˜± åœ¨æ¢¯åº¦æ”¹å˜æ–¹å‘çš„æ—¶å€™ï¼ŒÎ¼èƒ½å¤Ÿå‡å°‘æ›´æ–° æ€»è€Œè¨€ä¹‹ï¼Œmomentumé¡¹èƒ½å¤Ÿåœ¨ç›¸å…³æ–¹å‘åŠ é€ŸSGDï¼ŒæŠ‘åˆ¶æŒ¯è¡ï¼Œä»è€ŒåŠ å¿«æ”¶æ•›\n5.3 Adam\nAdam(Adaptive Moment Estimation)æœ¬è´¨ä¸Šæ˜¯å¸¦æœ‰åŠ¨é‡é¡¹çš„RMSpropï¼Œå®ƒåˆ©ç”¨æ¢¯åº¦çš„ä¸€é˜¶çŸ©ä¼°è®¡å’ŒäºŒé˜¶çŸ©ä¼°è®¡åŠ¨æ€è°ƒæ•´æ¯ä¸ªå‚æ•°çš„å­¦ä¹ ç‡ã€‚Adamçš„ä¼˜ç‚¹ä¸»è¦åœ¨äºç»è¿‡åç½®æ ¡æ­£åï¼Œæ¯ä¸€æ¬¡è¿­ä»£å­¦ä¹ ç‡éƒ½æœ‰ä¸ªç¡®å®šèŒƒå›´ï¼Œä½¿å¾—å‚æ•°æ¯”è¾ƒå¹³ç¨³ã€‚å…¬å¼å¦‚ä¸‹ï¼š\n\nç‰¹ç‚¹ï¼š\nç»“åˆäº†Adagradå–„äºå¤„ç†ç¨€ç–æ¢¯åº¦å’ŒRMSpropå–„äºå¤„ç†éå¹³ç¨³ç›®æ ‡çš„ä¼˜ç‚¹ å¯¹å†…å­˜éœ€æ±‚è¾ƒå° ä¸ºä¸åŒçš„å‚æ•°è®¡ç®—ä¸åŒçš„è‡ªé€‚åº”å­¦ä¹ ç‡ ä¹Ÿé€‚ç”¨äºå¤§å¤šéå‡¸ä¼˜åŒ– - é€‚ç”¨äºå¤§æ•°æ®é›†å’Œé«˜ç»´ç©ºé—´\n5.4 ç»éªŒä¹‹è°ˆ\nå¯¹äºç¨€ç–æ•°æ®ï¼Œå°½é‡ä½¿ç”¨å­¦ä¹ ç‡å¯è‡ªé€‚åº”çš„ä¼˜åŒ–æ–¹æ³•ï¼Œä¸ç”¨æ‰‹åŠ¨è°ƒèŠ‚ï¼Œè€Œä¸”æœ€å¥½é‡‡ç”¨é»˜è®¤å€¼ SGDé€šå¸¸è®­ç»ƒæ—¶é—´æ›´é•¿ï¼Œä½†æ˜¯åœ¨å¥½çš„åˆå§‹åŒ–å’Œå­¦ä¹ ç‡è°ƒåº¦æ–¹æ¡ˆçš„æƒ…å†µä¸‹ï¼Œç»“æœæ›´å¯é  å¦‚æœåœ¨æ„æ›´å¿«çš„æ”¶æ•›ï¼Œå¹¶ä¸”éœ€è¦è®­ç»ƒè¾ƒæ·±è¾ƒå¤æ‚çš„ç½‘ç»œæ—¶ï¼Œæ¨èä½¿ç”¨å­¦ä¹ ç‡è‡ªé€‚åº”çš„ä¼˜åŒ–æ–¹æ³•ã€‚ Adadeltaï¼ŒRMSpropï¼ŒAdamæ˜¯æ¯”è¾ƒç›¸è¿‘çš„ç®—æ³•ï¼Œåœ¨ç›¸ä¼¼çš„æƒ…å†µä¸‹è¡¨ç°å·®ä¸å¤šã€‚ åœ¨æƒ³ä½¿ç”¨å¸¦åŠ¨é‡çš„RMSpropï¼Œæˆ–è€…Adamçš„åœ°æ–¹ï¼Œå¤§å¤šå¯ä»¥ä½¿ç”¨Nadamå–å¾—æ›´å¥½çš„æ•ˆæœ\n5.5 ä¸€äº›é—®é¢˜\nL2æ­£åˆ™=Weight Decayï¼Ÿå¹¶ä¸æ˜¯è¿™æ ·\nä½¿ç”¨Adamä¼˜åŒ–å¸¦L2æ­£åˆ™çš„æŸå¤±å¹¶ä¸æœ‰æ•ˆã€‚å¦‚æœå¼•å…¥L2æ­£åˆ™é¡¹ï¼Œåœ¨è®¡ç®—æ¢¯åº¦çš„æ—¶å€™ä¼šåŠ ä¸Šå¯¹æ­£åˆ™é¡¹æ±‚æ¢¯åº¦çš„ç»“æœã€‚é‚£ä¹ˆå¦‚æœæœ¬èº«æ¯”è¾ƒå¤§çš„ä¸€äº›æƒé‡å¯¹åº”çš„æ¢¯åº¦ä¹Ÿä¼šæ¯”è¾ƒå¤§ï¼Œç”±äºAdamè®¡ç®—æ­¥éª¤ä¸­å‡å»é¡¹ä¼šæœ‰é™¤ä»¥æ¢¯åº¦å¹³æ–¹çš„ç´¯ç§¯ï¼Œä½¿å¾—å‡å»é¡¹åå°ã€‚æŒ‰å¸¸ç†è¯´ï¼Œè¶Šå¤§çš„æƒé‡åº”è¯¥æƒ©ç½šè¶Šå¤§ï¼Œä½†æ˜¯åœ¨Adamå¹¶ä¸æ˜¯è¿™æ ·ã€‚è€Œæƒé‡è¡°å‡å¯¹æ‰€æœ‰çš„æƒé‡éƒ½æ˜¯é‡‡ç”¨ç›¸åŒçš„ç³»æ•°è¿›è¡Œæ›´æ–°ï¼Œè¶Šå¤§çš„æƒé‡æ˜¾ç„¶æƒ©ç½šè¶Šå¤§ã€‚åœ¨å¸¸è§çš„æ·±åº¦å­¦ä¹ åº“ä¸­åªæä¾›äº†L2æ­£åˆ™ï¼Œå¹¶æ²¡æœ‰æä¾›æƒé‡è¡°å‡çš„å®ç°ã€‚è¿™å¯èƒ½å°±æ˜¯å¯¼è‡´Adamè·‘å‡ºæ¥çš„å¾ˆå¤šæ•ˆæœç›¸å¯¹SGD with Momentumåå·®çš„ä¸€ä¸ªåŸå› ã€‚\nç‰›é¡¿æ³•å’Œæ¢¯åº¦ä¸‹é™æ³•æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n6. æ¨¡å‹ç›¸å…³è®¡ç®—\nè¾“å…¥L* Lï¼Œå·ç§¯æ ¸k* kï¼Œæ­¥é•¿sï¼Œpadding pï¼Œè¾“å‡ºå°ºå¯¸ï¼ŒFlopsè®¡ç®—\nL1 = (L-k+2*p)/s + 1 flops = k * k * c1 * c2 * L1 * L1\nç½‘ç»œå¤§å°æŒ‡æ ‡ï¼šå‚æ•°é‡ï¼Œflopsï¼Œä¹˜åŠ æ•°\nå‚è€ƒ * FLOPS: æ³¨æ„å…¨éƒ¨å¤§å†™ æ˜¯floating point of per secondçš„ç¼©å†™ï¼Œæ„æŒ‡æ¯ç§’æµ®ç‚¹è¿ç®—æ¬¡æ•°ã€‚å¯ä»¥ç†è§£ä¸ºè®¡ç®—é€Ÿåº¦ï¼Œç”¨æ¥è¡¡é‡ç¡¬ä»¶çš„æ€§èƒ½ã€‚ * FLOPs: æ˜¯floating point of operationsçš„ç¼©å†™ï¼Œæ˜¯æµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼Œç†è§£ä¸ºè®¡ç®—é‡ï¼Œå¯ä»¥ç”¨æ¥è¡¡é‡ç®—æ³•/æ¨¡å‹å¤æ‚åº¦ã€‚\nå·ç§¯å±‚:\n +1è¡¨ç¤ºbias  è¡¨ç¤ºä¸€æ¬¡å·ç§¯æ“ä½œä¸­çš„åŠ æ³•è¿ç®—é‡ï¼Œ+ 1 è¡¨ç¤ºbiasï¼Œ ä¸Šé¢æ˜¯ä¹˜è¿ç®—å’ŒåŠ è¿ç®—çš„æ€»å’Œï¼Œå°†ä¸€æ¬¡ä¹˜è¿ç®—æˆ–åŠ è¿ç®—éƒ½è§†ä½œä¸€æ¬¡æµ®ç‚¹è¿ç®—ã€‚ åœ¨è®¡ç®—æœºè§†è§‰è®ºæ–‡ä¸­ï¼Œå¸¸å¸¸å°†ä¸€ä¸ª'ä¹˜-åŠ 'ç»„åˆè§†ä¸ºä¸€æ¬¡æµ®ç‚¹è¿ç®—ï¼Œè‹±æ–‡è¡¨è¿°ä¸º'Multi-Add'ï¼Œè¿ç®—é‡æ­£å¥½æ˜¯ä¸Šé¢çš„ç®—æ³•å‡åŠï¼Œæ­¤æ—¶çš„è¿ç®—é‡ä¸ºï¼š \nå…¨è¿æ¥å±‚: params=(I+1)*O=I*O+O æ¯ä¸€å±‚ç¥ç»å…ƒ(Oè¿™ä¸€å±‚)çš„æƒé‡æ•°ä¸ºIÃ—Oï¼Œbiasæ•°é‡ä¸ºOã€‚ FLOPs=[I+(I-1)+1]*O=2*I*O ç¬¬ä¸€ä¸ªIè¡¨ç¤ºä¹˜æ³•è¿ç®—é‡ï¼Œ I-1è¡¨ç¤ºåŠ æ³•è¿ç®—é‡ï¼Œ+1è¡¨ç¤ºbiasï¼Œ *Oè¡¨ç¤ºè®¡ç®—Oä¸ªç¥ç»å…ƒçš„å€¼ã€‚\n7. Lossç›¸å…³\n7.1 Cross Entropy &amp;&amp; MSE\n\nå‡æ–¹å·®æŸå¤±å‡½æ•°ï¼ˆMSEï¼‰ ç®€å•æ¥è¯´ï¼Œå‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰çš„å«ä¹‰æ˜¯æ±‚ä¸€ä¸ªbatchä¸­nä¸ªæ ·æœ¬çš„nä¸ªè¾“å‡ºä¸æœŸæœ›è¾“å‡ºçš„å·®çš„å¹³æ–¹çš„å¹³å‡å€¼ã€\nCross-entropyï¼ˆäº¤å‰ç†µæŸå¤±å‡½æ•°) äº¤å‰ç†µæ˜¯ç”¨æ¥è¯„ä¼°å½“å‰è®­ç»ƒå¾—åˆ°çš„æ¦‚ç‡åˆ†å¸ƒä¸çœŸå®åˆ†å¸ƒçš„å·®å¼‚æƒ…å†µã€‚ å®ƒåˆ»ç”»çš„æ˜¯å®é™…è¾“å‡ºï¼ˆæ¦‚ç‡ï¼‰ä¸æœŸæœ›è¾“å‡ºï¼ˆæ¦‚ç‡ï¼‰çš„è·ç¦»ï¼Œä¹Ÿå°±æ˜¯äº¤å‰ç†µçš„å€¼è¶Šå°ï¼Œä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå°±è¶Šæ¥è¿‘ã€‚\n\n\n\næ¥æº\n\n7.1.2 åˆ†ç±»ä¸ºä½•ä¸ç”¨MSE\nåˆ†ç±»é—®é¢˜ï¼Œæœ€åå¿…é¡»æ˜¯ one hot å½¢å¼ç®—å‡ºå„ label çš„æ¦‚ç‡ï¼Œ ç„¶åé€šè¿‡ argmax é€‰å‡ºæœ€ç»ˆçš„åˆ†ç±»ã€‚ åœ¨è®¡ç®—å„ä¸ª label æ¦‚ç‡çš„æ—¶å€™ï¼Œç”¨çš„æ˜¯ softmax å‡½æ•°ã€‚å¦‚æœç”¨ MSE è®¡ç®— lossï¼Œ è¾“å‡ºçš„æ›²çº¿æ˜¯æ³¢åŠ¨çš„ï¼Œæœ‰å¾ˆå¤šå±€éƒ¨çš„æå€¼ç‚¹ã€‚ å³ï¼Œéå‡¸ä¼˜åŒ–é—®é¢˜ (non-convex) cross entropy è®¡ç®— lossï¼Œåˆ™ä¾æ—§æ˜¯ä¸€ä¸ªå‡¸ä¼˜åŒ–é—®é¢˜ï¼Œç”¨æ¢¯åº¦ä¸‹é™æ±‚è§£æ—¶ï¼Œå‡¸ä¼˜åŒ–é—®é¢˜æœ‰å¾ˆå¥½çš„æ”¶æ•›ç‰¹æ€§ã€‚ &gt; å½“æ¢¯åº¦å¾ˆå°çš„æ—¶å€™ï¼Œåº”è¯¥å‡å°æ­¥é•¿ï¼ˆå¦åˆ™å®¹æ˜“åœ¨æœ€ä¼˜è§£é™„è¿‘äº§ç”Ÿæ¥å›éœ‡è¡ï¼‰ï¼Œä½†æ˜¯å¦‚æœé‡‡ç”¨ MSE ï¼Œå½“æ¢¯åº¦å¾ˆå°çš„æ—¶å€™ï¼Œæ— æ³•çŸ¥é“æ˜¯ç¦»ç›®æ ‡å¾ˆè¿œè¿˜æ˜¯å·²ç»åœ¨ç›®æ ‡é™„è¿‘äº†ã€‚ï¼ˆç¦»ç›®æ ‡å¾ˆè¿‘å’Œç¦»ç›®æ ‡å¾ˆè¿œï¼Œå…¶æ¢¯åº¦éƒ½å¾ˆå°ï¼‰----çŸ¥ä¹\n7.1.3 äº¤å‰ç†µä¸ºä»€ä¹ˆæœ‰logé¡¹\nä¸å¸¦logï¼Œå¯¹pçš„æ±‚å¯¼å¤„å¤„ä¸º1ï¼› log(p)ï¼Œå½“pæ¥è¿‘1æ—¶ï¼ˆæ¥è¿‘ç›®æ ‡ï¼‰ï¼Œå¯¼æ•°å°ï¼Œæ¥è¿‘0æ—¶ï¼Œå¯¼æ•°å¤§ å¸¦logå¯ä»¥ä½¿å¾—ä¼˜åŒ–æ—¶æ›´åé‡äºç¦»ç›®æ ‡è¿œçš„é‚£äº›pï¼Œè€ŒéåŒç­‰å¯¹å¾…ã€‚\n7.1.4 ç†µã€äº¤å‰ç†µã€KLæ•£åº¦çš„å…³ç³»\näº¤å‰ç†µå…¶å®åªæ˜¯KLæ•£åº¦çš„ä¸€éƒ¨åˆ†\n\nå…¶ä¸­pä»£è¡¨labelæˆ–è€…å«groundtruthï¼Œqä»£è¡¨é¢„æµ‹å€¼.åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬éœ€è¦è¯„ä¼°labelå’Œpredictsä¹‹é—´çš„å·®è·ï¼Œä½¿ç”¨KLæ•£åº¦åˆšåˆšå¥½ï¼Œå³ï¼š \nç”±äºKLæ•£åº¦ä¸­çš„å‰ä¸€éƒ¨åˆ†æ°å·§å°±æ˜¯pçš„ç†µï¼Œpä»£è¡¨labelæˆ–è€…å«groundtruthï¼Œæ•…âˆ’H(p(x))ä¸å˜ï¼Œæ•…åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œåªéœ€è¦å…³æ³¨DKL()çš„åä¸€éƒ¨åˆ†ï¼šäº¤å‰ç†µ(H(p, q)) å°±å¯ä»¥äº†ã€‚\n7.2 L1 loss, L2 loss, smooth L1 loss\nå‡ºå¤„\n\n\n\n\n\n\n\n\n\nå¯¹äºå¤§å¤šæ•°CNNç½‘ç»œï¼Œæˆ‘ä»¬ä¸€èˆ¬æ˜¯ä½¿ç”¨L2-lossè€Œä¸æ˜¯L1-lossï¼Œå› ä¸ºL2-lossçš„æ”¶æ•›é€Ÿåº¦è¦æ¯”L1-lossè¦å¿«å¾—å¤š\nå¯¹äºè¾¹æ¡†é¢„æµ‹å›å½’é—®é¢˜ï¼Œé€šå¸¸ä¹Ÿå¯ä»¥é€‰æ‹©å¹³æ–¹æŸå¤±å‡½æ•°ï¼ˆL2æŸå¤±ï¼‰ï¼Œä½†L2èŒƒæ•°çš„ç¼ºç‚¹æ˜¯å½“å­˜åœ¨ç¦»ç¾¤ç‚¹ï¼ˆoutliers)çš„æ—¶å€™ï¼Œè¿™äº›ç‚¹ä¼šå lossçš„ä¸»è¦ç»„æˆéƒ¨åˆ†ã€‚æ¯”å¦‚è¯´çœŸå®å€¼ä¸º1ï¼Œé¢„æµ‹10æ¬¡ï¼Œæœ‰ä¸€æ¬¡é¢„æµ‹å€¼ä¸º1000ï¼Œå…¶ä½™æ¬¡çš„é¢„æµ‹å€¼ä¸º1å·¦å³ï¼Œæ˜¾ç„¶losså€¼ä¸»è¦ç”±1000ä¸»å®°ã€‚æ‰€ä»¥FastRCNNé‡‡ç”¨ç¨å¾®ç¼“å’Œä¸€ç‚¹ç»å¯¹æŸå¤±å‡½æ•°ï¼ˆsmooth L1æŸå¤±ï¼‰ï¼Œå®ƒæ˜¯éšç€è¯¯å·®çº¿æ€§å¢é•¿ï¼Œè€Œä¸æ˜¯å¹³æ–¹å¢é•¿ã€‚\n\n\n\n\n\n\n\n\n\næ³¨æ„ï¼šsmooth L1å’ŒL1-losså‡½æ•°çš„åŒºåˆ«åœ¨äºï¼ŒL1-lossåœ¨0ç‚¹å¤„å¯¼æ•°ä¸å”¯ä¸€ï¼Œå¯èƒ½å½±å“æ”¶æ•›ã€‚smooth L1çš„è§£å†³åŠæ³•æ˜¯åœ¨0ç‚¹é™„è¿‘ä½¿ç”¨å¹³æ–¹å‡½æ•°ä½¿å¾—å®ƒæ›´åŠ å¹³æ»‘ã€‚\n\n\n\n\n\n\n\n\n\nsmooth L1 losså¹¶ä¸æ˜¯ä¸ºäº†è§£å†³L1-lossåœ¨0ç‚¹å¤„å¯¼æ•°ä¸å”¯ä¸€ï¼Œæ¯•ç«Ÿç›´æ¥å®šä¹‰L1 lossåœ¨0å¤„çš„å¯¼æ•°ä¸º0å°±è¡Œäº†ã€‚æ›´åƒæ˜¯ï¼Œå½“é¢„æµ‹å€¼ä¸æ ‡ç­¾ä¹‹å·®å°äº1æ—¶ï¼Œsmooth l1çš„å¯¼æ•°æ›´å°ï¼Œä½¿å¾—lossæ”¶æ•›çš„æ›´åŠ ç¨³å®šï¼Œæ›´å®¹æ˜“æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜ï¼Œè€Œä¸ä¼šè·³å‡ºå±€éƒ¨æœ€ä¼˜ã€‚\nå…¬å¼ï¼š \n\n\n\n\næ¥æº\n\n\n\n\n\n\n\n\n\n\nsmooth L1 lossè®©losså¯¹äºç¦»ç¾¤ç‚¹æ›´åŠ é²æ£’ï¼Œå³ï¼šç›¸æ¯”äºL2æŸå¤±å‡½æ•°ï¼Œå…¶å¯¹ç¦»ç¾¤ç‚¹ã€å¼‚å¸¸å€¼ï¼ˆoutlierï¼‰ä¸æ•æ„Ÿï¼Œæ¢¯åº¦å˜åŒ–ç›¸å¯¹æ›´å°ï¼Œè®­ç»ƒæ—¶ä¸å®¹æ˜“è·‘é£ã€‚\ncosè·ç¦»å’Œl2ä»€ä¹ˆæƒ…å†µä¸‹ç›¸ç­‰?\nL2å½’ä¸€åŒ–åæ¬§æ‹‰è·ç¦»çš„å¹³æ–¹ä¸cosineç›¸ä¼¼åº¦çš„å…³ç³»ä¸º; &gt; L2å½’ä¸€åŒ–å°±æ˜¯å¯¹å‘é‡çš„æ¯ä¸€ä¸ªå€¼éƒ½é™¤ä»¥å‘é‡çš„å¹³æ–¹å’Œçš„å¼€æ–¹\n\n7.3 focal loss\næ¥æºçŸ¥ä¹\nFocal Lossçš„å¼•å…¥ä¸»è¦æ˜¯ä¸ºäº†è§£å†³éš¾æ˜“æ ·æœ¬æ•°é‡ä¸å¹³è¡¡ï¼ˆæ³¨æ„ï¼Œæœ‰åŒºåˆ«äºæ­£è´Ÿæ ·æœ¬æ•°é‡ä¸å¹³è¡¡ï¼‰çš„é—®é¢˜ï¼Œå®é™…å¯ä»¥ä½¿ç”¨çš„èŒƒå›´éå¸¸å¹¿æ³›ï¼Œä¸ºäº†æ–¹ä¾¿è§£é‡Šï¼Œè¿˜æ˜¯æ‹¿ç›®æ ‡æ£€æµ‹çš„åº”ç”¨åœºæ™¯æ¥è¯´æ˜ï¼š å•é˜¶æ®µçš„ç›®æ ‡æ£€æµ‹å™¨é€šå¸¸ä¼šäº§ç”Ÿé«˜è¾¾100kçš„å€™é€‰ç›®æ ‡ï¼Œåªæœ‰æå°‘æ•°æ˜¯æ­£æ ·æœ¬ï¼Œæ­£è´Ÿæ ·æœ¬æ•°é‡éå¸¸ä¸å¹³è¡¡ã€‚æˆ‘ä»¬åœ¨è®¡ç®—åˆ†ç±»çš„æ—¶å€™å¸¸ç”¨çš„æŸå¤±â€”â€”äº¤å‰ç†µçš„å…¬å¼å¦‚ä¸‹ï¼š \nä¸ºäº†è§£å†³æ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡çš„é—®é¢˜ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šåœ¨äº¤å‰ç†µæŸå¤±çš„å‰é¢åŠ ä¸Šä¸€ä¸ªå‚æ•°ï¼Œå³ï¼š å…¬å¼ï¼ˆ2ï¼‰ \nä½†è¿™å¹¶ä¸èƒ½è§£å†³å…¨éƒ¨é—®é¢˜ã€‚æ ¹æ®æ­£ã€è´Ÿã€éš¾ã€æ˜“ï¼Œæ ·æœ¬ä¸€å…±å¯ä»¥åˆ†ä¸ºä»¥ä¸‹å››ç±»ï¼š\n\n\n\n\néš¾\næ˜“\n\n\n\n\næ­£\næ­£éš¾\næ­£æ˜“\n\n\nè´Ÿ\nè´Ÿéš¾\nè´Ÿæ˜“\n\n\n\nå°½ç®¡å¹³è¡¡äº†æ­£è´Ÿæ ·æœ¬ï¼Œä½†å¯¹éš¾æ˜“æ ·æœ¬çš„ä¸å¹³è¡¡æ²¡æœ‰ä»»ä½•å¸®åŠ©ã€‚è€Œå®é™…ä¸Šï¼Œç›®æ ‡æ£€æµ‹ä¸­å¤§é‡çš„å€™é€‰ç›®æ ‡éƒ½æ˜¯æ˜“åˆ†æ ·æœ¬ã€‚ è¿™äº›æ ·æœ¬çš„æŸå¤±å¾ˆä½ï¼Œä½†æ˜¯ç”±äºæ•°é‡æä¸å¹³è¡¡ï¼Œæ˜“åˆ†æ ·æœ¬çš„æ•°é‡ç›¸å¯¹æ¥è®²å¤ªå¤šï¼Œæœ€ç»ˆä¸»å¯¼äº†æ€»çš„æŸå¤±ã€‚è€Œæœ¬æ–‡çš„ä½œè€…è®¤ä¸ºï¼Œæ˜“åˆ†æ ·æœ¬ï¼ˆå³ï¼Œç½®ä¿¡åº¦é«˜çš„æ ·æœ¬ï¼‰å¯¹æ¨¡å‹çš„æå‡æ•ˆæœéå¸¸å°ï¼Œæ¨¡å‹åº”è¯¥ä¸»è¦å…³æ³¨ä¸é‚£äº›éš¾åˆ†æ ·æœ¬ï¼ˆè¿™ä¸ªå‡è®¾æ˜¯æœ‰é—®é¢˜çš„ï¼Œæ˜¯GHMçš„ä¸»è¦æ”¹è¿›å¯¹è±¡ï¼‰\nè¿™æ—¶å€™ï¼ŒFocal Losså°±ä¸Šåœºäº†ï¼ ä¸€ä¸ªç®€å•çš„æ€æƒ³ï¼šæŠŠé«˜ç½®ä¿¡åº¦(p)æ ·æœ¬çš„æŸå¤±å†é™ä½ä¸€äº›ä¸å°±å¥½äº†å—ï¼ å…¬å¼ï¼ˆ3ï¼‰ \nä¸¾ä¸ªä¾‹ï¼Œ Î³å–2æ—¶ï¼Œå¦‚æœp=0.968, (1-0.968)^2=0.001ï¼ŒæŸå¤±è¡°å‡äº†1000å€ï¼\nFocal Lossçš„æœ€ç»ˆå½¢å¼ç»“åˆäº†ä¸Šé¢çš„å…¬å¼ï¼ˆ2ï¼‰. è¿™å¾ˆå¥½ç†è§£ï¼Œå…¬å¼(3)è§£å†³äº†éš¾æ˜“æ ·æœ¬çš„ä¸å¹³è¡¡ï¼Œå…¬å¼(2)è§£å†³äº†æ­£è´Ÿæ ·æœ¬çš„ä¸å¹³è¡¡ï¼Œå°†å…¬å¼ï¼ˆ2ï¼‰ä¸ï¼ˆ3ï¼‰ç»“åˆä½¿ç”¨ï¼ŒåŒæ—¶è§£å†³æ­£è´Ÿéš¾æ˜“2ä¸ªé—®é¢˜ï¼\næœ€ç»ˆçš„Focal Losså½¢å¼å¦‚ä¸‹ï¼š\n\n\n\n\n\n\n\n\n\n\nå®éªŒè¡¨æ˜Î±=0.25, Î³=2çš„æ—¶å€™æ•ˆæœæœ€ä½³ã€‚æ³¨æ„åœ¨ä½œè€…çš„ä»»åŠ¡ä¸­ï¼Œæ­£æ ·æœ¬æ˜¯å±äºå°‘æ•°æ ·æœ¬ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œæœ¬æ¥æ­£æ ·æœ¬éš¾ä»¥â€œåŒ¹æ•Œâ€è´Ÿæ ·æœ¬ï¼Œä½†ç»è¿‡ (1âˆ’yÌ‚)^Î³ å’Œ yÌ‚^Î³ çš„â€œæ“æ§â€åï¼Œä¹Ÿè®¸å½¢åŠ¿è¿˜é€†è½¬äº†ï¼Œè¿˜è¦å¯¹æ­£æ ·æœ¬é™æƒã€‚\n7.4 äººè„¸è¯†åˆ«loss\nå‡ºå¤„1\nå‡ºå¤„2\n7.4.1 Softmax Loss\nè§3.2èŠ‚\n7.4.2 Center Loss\nå¯¹MNISTæ•°æ®é›†è¿›è¡Œåˆ†ç±»ï¼Œè‹¥æŸå¤±å‡½æ•°é‡‡ç”¨ä¸Šè¿°ä»‹ç»çš„Softmax Loss(å› ä¸ºSoftmax Lossèƒ½å¤Ÿä½¿ç‰¹å¾å¯åˆ†)ï¼Œé‚£ä¹ˆæœ€åæ¯ä¸ªç±»åˆ«æ•°å­—å­¦å‡ºæ¥çš„ç‰¹å¾åˆ†å¸ƒä¸‹å›¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºç±»é—´è·ç¦»è¿˜æ˜¯æ¯”è¾ƒå°ï¼Œç±»å†…è·ç¦»æ¯”è¾ƒå¤§çš„ï¼Œè™½ç„¶æ•ˆæœå¾ˆå¥½ï¼š\n\nå¦‚æœæŸå¤±å‡½æ•°é‡‡ç”¨Center Lossï¼Œé‚£ä¹ˆç‰¹å¾åˆ†å¸ƒå¦‚ä¸‹å›¾ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹å‡ºç›¸æ¯”äºSoftmax Loss, ç±»é—´è·ç¦»å˜å¤§äº†ï¼Œç±»å†…è·ç¦»å˜å°äº†ï¼š\n\næ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹å‡ºCenter Lossèƒ½å¤Ÿæœ€å°åŒ–ç±»å†…è·ç¦»çš„åŒæ—¶ä¿è¯ç‰¹å¾å¯åˆ†ï¼Œæ¥æé«˜ç‰¹å¾ä¹‹é—´çš„å¯åˆ¤åˆ«æ€§ï¼ç®€å•åœ°è¯´ï¼Œç»™æ¯ä¸€ç±»(lable)å®šä¹‰ä¸€ä¸ªç±»ä¸­å¿ƒ(Center)ï¼ŒåŒä¸€ç±»çš„æ•°æ®å‘ç±»ä¸­å¿ƒé è¿‘ï¼Œç¦»å¾—è¿œè¦æƒ©ç½šï¼äºæ˜¯Center Losså°±å‡ºç°äº†ã€‚\n\nå…¶ä¸­ è¡¨ç¤ºè¿™ä¸ªæ ·æœ¬æ‰€å¯¹åº”çš„ç¬¬ç±»åˆ«çš„ç‰¹å¾ä¸­å¿ƒï¼Œ mè¡¨ç¤ºæ¯ä¸€ä¸ªbatchå¤§å°ã€‚ä¸Šè¿°å…¬å¼çš„æ„ä¹‰æ˜¯ï¼šå¸Œæœ›batchä¸­çš„æ¯ä¸ªæ ·æœ¬ç‰¹å¾è·ç¦»ç‰¹å¾ä¸­å¿ƒçš„è·ç¦»çš„å¹³æ–¹å’Œè¶Šå°è¶Šå¥½ï¼Œä¹Ÿå°±æ˜¯è´Ÿè´£ç±»å†…å·®è·ã€‚\né‚£ä¹ˆä¸Šè¿°çš„æ¯ä¸€batchæ€ä¹ˆç¡®å®šçš„å‘¢ï¼Ÿç†æƒ³æƒ…å†µä¸‹ï¼Œéœ€è¦éšç€å­¦ä¹ åˆ°çš„featureè¿›è¡Œå®æ—¶æ›´æ–°ï¼Œä¹Ÿå°±æ˜¯åœ¨æ¯ä¸€æ¬¡è¿­ä»£çš„æ—¶å€™ç”¨æ•´ä¸ªæ•°æ®é›†çš„featureæ¥è®¡ç®—æ¯ä¸ªç±»çš„ä¸­å¿ƒã€‚ä½†æ˜¯è¿™æ ·æ—¶é—´å¤æ‚åº¦é«˜ï¼Œäºæ˜¯ï¼šç”¨ batchæ¥æ›´æ–°enterï¼Œæ¯ä¸€è½®è®¡ç®—ä¸€ä¸‹å½“å‰batchæ•°æ®ä¸centerçš„è·ç¦»ï¼Œç„¶åè¿™ä¸ªè·ç¦»ä»¥æ¢¯åº¦çš„å½¢å¼å åŠ åˆ°centerä¸Šã€‚ æˆ‘ä»¬ä¸‹é¢å¯¹æ±‚å¯¼ï¼š\n\nè¿™é‡Œå› ä¸ºæ¯ä¸ª batchçš„æ•°é‡må¤ªå°ï¼Œé‚£ä¹ˆæ¯æ¬¡æ›´æ–°centerå¯èƒ½ä¼šå¼•èµ·æŠ–åŠ¨ã€‚é‚£ä¹ˆæ¢¯åº¦ä¸Šé¢åŠ ä¸ªé™åˆ¶ï¼Œè¿™ä¸ªå€¼åœ¨0-1ä¹‹é—´ï¼š\nâ–³\nä¸ºäº†æœ€å°åŒ–ç±»å†…ï¼Œæœ€å¤§åŒ–ç±»é—´ï¼Œå³æ»¡è¶³ç‰¹å¾å¯åˆ†å’Œç‰¹å¾å¯åˆ¤åˆ«ï¼Œè®ºæ–‡ä¸­å°†Softmax Losså’ŒCenter Lossç»“åˆã€‚\n\n7.4.3 A-Softmax Loss\nä¼ ç»Ÿçš„Softmaxå¾ˆå®¹æ˜“ä¼˜åŒ–ï¼Œå› ä¸ºå®ƒæ²¡æœ‰å°½å¯èƒ½çš„æ‰©å¤§ç±»é—´è·ç¦»ï¼Œç¼©å°ç±»å†…è·ç¦»ã€‚\n7.4.4 L-Softmax Loss\n7.4.5 CosFace Loss\n7.4.6 AM-Softmax Loss\n7.4.7 ArcFace/Insight Face\n7.4.8 Triplet Loss\n7.5 Gan loss\n7.5.1 JSæ•£åº¦\nå‡ºå¤„\nGANå®é™…æ˜¯é€šè¿‡å¯¹å…ˆéªŒåˆ†å¸ƒæ–½åŠ ä¸€ä¸ªè¿ç®—G, æ¥æ‹Ÿåˆä¸€ä¸ªæ–°çš„åˆ†å¸ƒ\n\nå¦‚æœä»ä¼ ç»Ÿçš„åˆ¤åˆ«å¼ç½‘ç»œçš„æ€è·¯å‡ºå‘ï¼Œåªè¦é€‰å®šåˆé€‚çš„lossï¼Œå°±å¯ä»¥ä½¿ç”Ÿæˆåˆ†å¸ƒå’ŒçœŸå®åˆ†å¸ƒä¹‹é—´çš„è·ç¦»å°½å¯èƒ½é€¼è¿‘ KLæ•£åº¦ç»å¸¸ç”¨æ¥è¡¡é‡åˆ†å¸ƒä¹‹é—´è·ç¦»:  ä½†KLæ•£åº¦æ˜¯ä¸å¯¹ç§°çš„ã€‚ä¸å¯¹ç§°æ„å‘³ç€ï¼Œå¯¹äºåŒä¸€ä¸ªè·ç¦»ï¼Œè§‚å¯Ÿæ–¹å¼ä¸åŒï¼Œè·å–çš„lossä¹Ÿä¸åŒï¼Œé‚£ä¹ˆæ•´ä½“lossä¸‹é™çš„æ–¹å‘å°±ä¼šè¶‹å‘äºæŸä¸ªç‰¹å®šæ–¹å‘ã€‚è¿™åœ¨GANä¸­éå¸¸å®¹æ˜“é€ æˆæ¨¡å¼å´©å¡Œï¼Œå³ç”Ÿæˆæ•°æ®çš„å¤šæ ·æ€§ä¸è¶³\nJSæ•£åº¦åœ¨KLæ•£åº¦çš„åŸºç¡€ä¸Šè¿›è¡Œäº†ä¿®æ­£ï¼Œä¿è¯äº†è·ç¦»çš„å¯¹ç§°æ€§ï¼š \nå®é™…ä¸Šï¼Œæ— è®ºKLæ•£åº¦è¿˜æ˜¯JSæ•£åº¦ï¼Œåœ¨ç›´æ¥ç”¨ä½œlossæ—¶ï¼Œéƒ½æ˜¯éš¾ä»¥è®­ç»ƒçš„ï¼šç”±äºåˆ†å¸ƒåªèƒ½é€šè¿‡å–æ ·è®¡ç®—ï¼Œè¿™ä¸ªlossåœ¨æ¯æ¬¡è¿­ä»£æ—¶éƒ½å‡ ä¹ä¸ºé›¶\n7.5.2 GAN loss\næ¨è\næœ¬è´¨å°±æ˜¯åœ¨åšä¸€ä¸ªæå¤§ä¼¼ç„¶ä¼°è®¡çš„äº‹æƒ…ï¼Œæˆ‘ä»¬å¸Œæœ›å¯ä»¥ç”¨æŸä¸€ç§å…·ä½“çš„åˆ†å¸ƒå½¢å¼å°½å¯èƒ½é€¼çœŸåœ°è¡¨è¾¾åˆ†å¸ƒï¼Œè¿™æ ·æˆ‘ä»¬å°±ç›¸å½“äºæ˜¯å¾—åˆ°äº†ï¼Œå¹¶æ®æ­¤åˆ†å¸ƒ é‡‡æ ·ï¼ˆä¹Ÿå°±æ˜¯åšç”Ÿæˆå¼çš„ä»»åŠ¡ï¼‰ï¼š\nå¯¹äºç”Ÿæˆå™¨Gï¼š\n\nGæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥ï¼Œè¾“å‡ºä¸Šx~\nå…ˆéªŒåˆ†å¸ƒ, å’ŒGå…±åŒå†³å®šçš„åˆ†å¸ƒ\n\nå¯¹äºåˆ¤åˆ«å™¨D:\n\nDæ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥x~ï¼Œè¾“å‡ºä¸€ä¸ªscalar\nDç”¨äºè¯„ä¼°å’Œä¹‹é—´çš„å·®å¼‚\n\né‚£ä¹ˆï¼ŒGANçš„æœ€ç»ˆç›®æ ‡--&gt;ç”¨ç¬¦å·åŒ–è¯­è¨€è¡¨ç¤ºå°±æ˜¯ï¼š\n\næˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¾—åˆ°ä½¿å¾—å¼å­maxV(G,D)æœ€å°çš„ç”Ÿæˆå™¨.\nå…³äºV:\n\n7.5.3 Wasserstein GAN\næ¨è * åˆ¤åˆ«å™¨æœ€åä¸€å±‚å»æ‰sigmoid * ç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨çš„lossä¸å–log * æ¯æ¬¡æ›´æ–°åˆ¤åˆ«å™¨çš„å‚æ•°ä¹‹åæŠŠå®ƒä»¬çš„ç»å¯¹å€¼æˆªæ–­åˆ°ä¸è¶…è¿‡ä¸€ä¸ªå›ºå®šå¸¸æ•°c * ä¸è¦ç”¨åŸºäºåŠ¨é‡çš„ä¼˜åŒ–ç®—æ³•ï¼ˆåŒ…æ‹¬momentumå’ŒAdamï¼‰ï¼Œæ¨èRMSPropï¼ŒSGDä¹Ÿè¡Œ\n7.5.3 WGAN-GP\næ¨è\nè·ŸWGANä¸åŒçš„ä¸»è¦æœ‰å‡ å¤„ï¼š1ï¼‰ç”¨gradient penaltyå–ä»£weight clippingï¼›2ï¼‰åœ¨ç”Ÿæˆå›¾åƒä¸Šå¢åŠ é«˜æ–¯å™ªå£°ï¼›3ï¼‰ä¼˜åŒ–å™¨ç”¨Adamå–ä»£RMSPropã€‚\n\n\n\n\n\n\n\n\n\nè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªGPçš„å¼•å…¥ï¼Œè·Ÿä¸€èˆ¬GANã€WGANä¸­é€šå¸¸éœ€è¦åŠ çš„Batch Normalizationä¼šèµ·å†²çªã€‚å› ä¸ºè¿™ä¸ªGPè¦æ±‚criticçš„ä¸€ä¸ªè¾“å…¥å¯¹åº”ä¸€ä¸ªè¾“å‡ºï¼Œä½†æ˜¯BNä¼šå°†ä¸€ä¸ªæ‰¹æ¬¡ä¸­çš„æ ·æœ¬è¿›è¡Œå½’ä¸€åŒ–ï¼ŒBNæ˜¯ä¸€æ‰¹è¾“å…¥å¯¹åº”ä¸€æ‰¹è¾“å‡ºï¼Œå› è€Œç”¨BNåæ— æ³•æ­£ç¡®æ±‚å‡ºcriticå¯¹äºæ¯ä¸ªè¾“å…¥æ ·æœ¬çš„æ¢¯åº¦ã€‚\n\n\n\n\n\n\n\n\n\nå¯¹äºWGAN-gpçš„åˆ¤åˆ«å™¨ï¼Œæ˜¯ä¸èƒ½åŠ  batchNorm çš„ï¼ŒåŸå› å¾ˆç®€å•ï¼Œ æ˜¯å› ä¸ºWGAN-gpçš„æƒ©ç½šé¡¹è®¡ç®—ä¸­ï¼Œæƒ©ç½šçš„æ˜¯å•ä¸ªæ•°æ®çš„gradient normï¼Œå¦‚æœä½¿ç”¨ batchNormï¼Œå°±ä¼šæ‰°ä¹±è¿™ç§æƒ©ç½šï¼Œè®©è¿™ç§ç‰¹åˆ«çš„æƒ©ç½šå¤±æ•ˆã€‚ å½“ç„¶ä½ å¯ä»¥ç»•è¿‡ batchNorm, ä½¿ç”¨ layerNorm æˆ–è€… InstanceNormã€‚\n8. æ¨¡å‹ç»“æ„\n8.1 ä¸ºä»€ä¹ˆresnetæ•ˆæœä¼šé‚£ä¹ˆå¥½\nå‡ºå¤„\n\nä½¿ç½‘ç»œæ›´å®¹æ˜“åœ¨æŸäº›å±‚å­¦åˆ°æ’ç­‰å˜æ¢ï¼ˆidentity mappingï¼‰ã€‚åœ¨æŸäº›å±‚æ‰§è¡Œæ’ç­‰å˜æ¢æ˜¯ä¸€ç§æ„é€ æ€§è§£ï¼Œä½¿æ›´æ·±çš„æ¨¡å‹çš„æ€§èƒ½è‡³å°‘ä¸ä½äºè¾ƒæµ…çš„æ¨¡å‹ã€‚è¿™ä¹Ÿæ˜¯ä½œè€…åŸå§‹è®ºæ–‡æŒ‡å‡ºçš„åŠ¨æœºã€‚Deep Residual Learning for Image Recognition\næ®‹å·®ç½‘ç»œæ˜¯å¾ˆå¤šæµ…å±‚ç½‘ç»œçš„é›†æˆï¼ˆensembleï¼‰ï¼Œå±‚æ•°çš„æŒ‡æ•°çº§é‚£ä¹ˆå¤šã€‚ä¸»è¦çš„å®éªŒè¯æ®æ˜¯ï¼šæŠŠ ResNet ä¸­çš„æŸäº›å±‚ç›´æ¥åˆ æ‰ï¼Œæ¨¡å‹çš„æ€§èƒ½å‡ ä¹ä¸ä¸‹é™ã€‚ Residual Networks Behave Like Ensembles of Relatively Shallow Networks\næ®‹å·®ç½‘ç»œä½¿ä¿¡æ¯æ›´å®¹æ˜“åœ¨å„å±‚ä¹‹é—´æµåŠ¨ï¼ŒåŒ…æ‹¬åœ¨å‰å‘ä¼ æ’­æ—¶æä¾›ç‰¹å¾é‡ç”¨ï¼Œåœ¨åå‘ä¼ æ’­æ—¶ç¼“è§£æ¢¯åº¦ä¿¡å·æ¶ˆå¤±ã€‚åŸä½œè€…åœ¨ä¸€ç¯‡åç»­æ–‡ç« ä¸­ç»™å‡ºäº†è®¨è®ºã€‚Identity Mappings in Deep Residual Networks\n\n\n\n\n\n\n\n\n\n\nhigh way(å½“é—¨ä¸º1çš„æ—¶å€™ï¼Œå…¨éƒ¨è¾“å‡ºåŸxï¼Œä¸ç”¨æ¿€æ´»ã€‚) æ¯”è¾ƒ: https://blog.csdn.net/qq_27009517/article/details/84028568\n8.2 mobilenet\nå‚è€ƒ\n8.3 shuffle net\nå‚è€ƒ\nSEæ¨¡å—\n9. å®é™…è®­ç»ƒç›¸å…³\n9.1 å­¦ä¹ è¿‡ç¨‹ä¸­å­¦ä¹ æ›²çº¿äº§ç”ŸæŒ¯è¡ï¼Œå¯èƒ½åŸå› ï¼Ÿ\n\nè®­ç»ƒçš„batch_sizeå¤ªå°\n\nbatchæ•°å¤ªå°ï¼Œè€Œç±»åˆ«åˆæ¯”è¾ƒå¤šçš„æ—¶å€™ï¼Œå¯èƒ½ä¼šå¯¼è‡´losså‡½æ•°éœ‡è¡è€Œä¸æ”¶æ•›ï¼Œå°¤å…¶æ˜¯åœ¨ç½‘ç»œæ¯”è¾ƒå¤æ‚çš„æ—¶å€™ã€‚\néšç€batchsizeå¢å¤§ï¼Œå¤„ç†ç›¸åŒçš„æ•°æ®é‡çš„é€Ÿåº¦è¶Šå¿«ã€‚\néšç€batchsizeå¢å¤§ï¼Œè¾¾åˆ°ç›¸åŒç²¾åº¦æ‰€éœ€è¦çš„epochæ•°é‡è¶Šæ¥è¶Šå¤šã€‚\nç”±äºä¸Šè¿°ä¸¤ç§å› ç´ çš„çŸ›ç›¾ï¼Œ Batch_Size å¢å¤§åˆ°æŸä¸ªæ—¶å€™ï¼Œè¾¾åˆ°æ—¶é—´ä¸Šçš„æœ€ä¼˜ã€‚\nè¿‡å¤§çš„batchsizeçš„ç»“æœæ˜¯ç½‘ç»œå¾ˆå®¹æ˜“æ”¶æ•›åˆ°ä¸€äº›ä¸å¥½çš„å±€éƒ¨æœ€ä¼˜ç‚¹ã€‚åŒæ ·å¤ªå°çš„batchä¹Ÿå­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œæ¯”å¦‚è®­ç»ƒé€Ÿåº¦å¾ˆæ…¢ï¼Œè®­ç»ƒä¸å®¹æ˜“æ”¶æ•›ç­‰ã€‚\nä½“çš„batch sizeçš„é€‰å–å’Œè®­ç»ƒé›†çš„æ ·æœ¬æ•°ç›®ç›¸å…³\n\n\n\n\n\n\n\n\n\n\n\nä¸€å®šèŒƒå›´å†…ï¼Œbatchsizeè¶Šå¤§ï¼Œå…¶ç¡®å®šçš„ä¸‹é™æ–¹å‘å°±è¶Šå‡†ï¼Œå¼•èµ·è®­ç»ƒéœ‡è¡è¶Šå°ã€‚ batchsizeå¢å¤§åˆ°ä¸€å®šçš„ç¨‹åº¦ï¼Œå…¶ç¡®å®šçš„ä¸‹é™æ–¹å‘å·²ç»åŸºæœ¬ä¸å†å˜åŒ–ã€‚ä¸€å‘³åœ°å¢åŠ batch sizeå°±å¥½ï¼Œå¤ªå¤§çš„batch size å®¹æ˜“é™·å…¥sharp minimaï¼Œæ³›åŒ–æ€§ä¸å¥½\n\nå­¦ä¹ ç‡ï¼šå­¦ä¹ ç‡å¤ªå¤§ï¼Œä¸€æ­¥å‰è¿›çš„è·¯ç¨‹å¤ªé•¿ï¼Œä¼šå‡ºç°æ¥å›éœ‡è¡çš„æƒ…å†µï¼Œä½†æ˜¯å­¦ä¹ ç‡å¤ªå°ï¼Œæ”¶æ•›é€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢ã€‚\næ˜¯å¦æ‰¾åˆ°åˆé€‚çš„losså‡½æ•°ï¼šåœ¨æ·±åº¦å­¦ä¹ é‡Œé¢ï¼Œä¸åŒçš„lossé’ˆå¯¹çš„ä»»åŠ¡æ˜¯æœ‰ä¸åŒçš„ï¼Œæœ‰äº›losså‡½æ•°æ¯”è¾ƒé€šç”¨ä¾‹å¦‚L1/L2ç­‰ï¼Œè€Œå¦‚perceptual lossåˆ™æ¯”è¾ƒé€‚åˆåœ¨å›¾åƒæ¢å¤/ç”Ÿæˆé¢†åŸŸçš„ä»»åŠ¡ä¸Šã€‚å½“losså‡ºç°é—®é¢˜çš„é€‚åˆï¼Œæƒ³ä¸€æƒ³ï¼Œæ˜¯ä¸æ˜¯lossè®¾ç½®çš„æœ‰é—®é¢˜ï¼Œåˆ«äººåœ¨æ­¤é¢†åŸŸçš„ä»»åŠ¡çš„æ–¹æ³•æ˜¯å¦ä¹Ÿä½¿ç”¨å’Œä½ ä¸€æ ·çš„lossã€‚\næ˜¯å¦ä½¿ç”¨åˆé€‚çš„æ¿€æ´»å‡½æ•°ï¼šä¸€èˆ¬æ¥è¯´ï¼Œéƒ½å‡ ä¹ä½¿ç”¨RELUä½œä¸ºå…¨å±€æ¿€æ´»å‡½æ•°ï¼Œå°½å¯èƒ½å°‘çš„ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°ï¼ˆæ¿€æ´»èŒƒå›´å¤ªå°ï¼‰ï¼Œå®¹æ˜“é€ æˆæ¢¯åº¦å¼¥æ•£ã€æ¶ˆå¤±\næ˜¯å¦é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–ç®—æ³•ï¼šä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘éƒ½ä½¿ç”¨Adamä½œä¸ºä¼˜åŒ–å™¨ï¼ˆé»˜è®¤å‚æ•°ï¼‰ã€‚å¦‚æœç»è¿‡ä»”ç»†è°ƒæ•´çš„SGDç®—æ³•æ€§èƒ½å¯èƒ½æ›´å¥½ï¼Œä½†æ˜¯æ—¶é—´ä¸Šä¸å¤ªå…è®¸è¿™æ ·åšã€‚\n\n9.2 loss nanåŸå› \n\nå¦‚æœåœ¨è¿­ä»£çš„100è½®ä»¥å†…ï¼Œå‡ºç°NaNï¼Œä¸€èˆ¬æƒ…å†µä¸‹çš„åŸå› æ˜¯å› ä¸ºä½ çš„å­¦ä¹ ç‡è¿‡é«˜ï¼Œéœ€è¦é™ä½å­¦ä¹ ç‡ã€‚å¯ä»¥ä¸æ–­é™ä½å­¦ä¹ ç‡ç›´è‡³ä¸å‡ºç°NaNä¸ºæ­¢ï¼Œä¸€èˆ¬æ¥è¯´ä½äºç°æœ‰å­¦ä¹ ç‡1-10å€å³å¯ã€‚\nå¦‚æœå½“å‰çš„ç½‘ç»œæ˜¯ç±»ä¼¼äºRNNçš„å¾ªç¯ç¥ç»ç½‘ç»œçš„è¯ï¼Œå‡ºç°NaNå¯èƒ½æ˜¯å› ä¸ºæ¢¯åº¦çˆ†ç‚¸çš„åŸå› ï¼Œä¸€ä¸ªæœ‰æ•ˆçš„æ–¹å¼æ˜¯å¢åŠ â€œgradient clippingâ€ï¼ˆæ¢¯åº¦æˆªæ–­æ¥è§£å†³ï¼‰\nå¯èƒ½ç”¨0ä½œä¸ºäº†é™¤æ•°;\nå¯èƒ½0æˆ–è€…è´Ÿæ•°ä½œä¸ºè‡ªç„¶å¯¹æ•°\néœ€è¦è®¡ç®—lossçš„æ•°ç»„è¶Šç•Œï¼ˆå°¤å…¶æ˜¯è‡ªå·±ï¼Œè‡ªå®šä¹‰äº†ä¸€ä¸ªæ–°çš„ç½‘ç»œï¼Œå¯èƒ½å‡ºç°è¿™ç§æƒ…å†µï¼‰\nåœ¨æŸäº›æ¶‰åŠæŒ‡æ•°è®¡ç®—ï¼Œå¯èƒ½æœ€åç®—å¾—å€¼ä¸ºINFï¼ˆæ— ç©·ï¼‰ï¼ˆæ¯”å¦‚ä¸åšå…¶ä»–å¤„ç†çš„softmaxä¸­åˆ†å­åˆ†æ¯éœ€è¦è®¡ç®—expï¼ˆxï¼‰ï¼Œå€¼è¿‡å¤§ï¼Œæœ€åå¯èƒ½ä¸ºINF/INFï¼Œå¾—åˆ°NaNï¼Œæ­¤æ—¶ä½ è¦ç¡®è®¤ä½ ä½¿ç”¨çš„softmaxä¸­åœ¨è®¡ç®—expï¼ˆxï¼‰åšäº†ç›¸å…³å¤„ç†ï¼ˆæ¯”å¦‚å‡å»æœ€å¤§å€¼ç­‰ç­‰ï¼‰ï¼‰\n\n9.3 lossä¸é™/ç½‘ç»œä¸æ”¶æ•›æ€ä¹ˆåŠï¼Œvalid lossä¸é™ï¼ˆè¿‡æ‹Ÿåˆï¼‰æ€ä¹ˆåŠ\nè®­ç»ƒé›†lossä¸ä¸‹é™ï¼š\nå‡ºå¤„\n\næ¨¡å‹ç»“æ„å’Œç‰¹å¾å·¥ç¨‹å­˜åœ¨é—®é¢˜\næƒé‡åˆå§‹åŒ–æ–¹æ¡ˆæœ‰é—®é¢˜ &gt; å»ºè®®æ— è„‘xaiver normalåˆå§‹åŒ–æˆ–è€… he normal\næ­£åˆ™åŒ–è¿‡åº¦ L1 L2å’ŒDropoutæ˜¯é˜²æ­¢è¿‡æ‹Ÿåˆç”¨çš„ï¼Œå½“è®­ç»ƒé›†lossä¸‹ä¸æ¥æ—¶ï¼Œå°±è¦è€ƒè™‘ä¸€ä¸‹æ˜¯ä¸æ˜¯æ­£åˆ™åŒ–è¿‡åº¦ï¼Œå¯¼è‡´æ¨¡å‹æ¬ æ‹Ÿåˆäº†ã€‚\né€‰æ‹©åˆé€‚çš„æ¿€æ´»å‡½æ•°ã€æŸå¤±å‡½æ•°\né€‰æ‹©åˆé€‚çš„ä¼˜åŒ–å™¨å’Œå­¦ä¹ é€Ÿç‡\næ¨¡å‹è®­ç»ƒé‡åˆ°ç“¶é¢ˆ è¿™é‡Œçš„ç“¶é¢ˆä¸€èˆ¬åŒ…æ‹¬ï¼šæ¢¯åº¦æ¶ˆå¤±ã€å¤§é‡ç¥ç»å…ƒå¤±æ´»ã€æ¢¯åº¦çˆ†ç‚¸å’Œå¼¥æ•£ã€å­¦ä¹ ç‡è¿‡å¤§æˆ–è¿‡å°ç­‰ã€‚\nbatch sizeè¿‡å¤§ batch sizeè¿‡å°ï¼Œä¼šå¯¼è‡´æ¨¡å‹åæœŸæ‘‡æ‘†ä¸å®šï¼Œè¿Ÿè¿Ÿéš¾ä»¥æ”¶æ•›ï¼Œè€Œè¿‡å¤§æ—¶ï¼Œæ¨¡å‹å‰æœŸç”±äºæ¢¯åº¦çš„å¹³å‡ï¼Œå¯¼è‡´æ”¶æ•›é€Ÿåº¦è¿‡æ…¢ã€‚\næ•°æ®é›†æœªæ‰“ä¹±ï¼Œæ•°æ®é›†é—®é¢˜ï¼Œæœªå½’ä¸€åŒ–\n\nvalid lossä¸é™ï¼ˆè¿‡æ‹Ÿåˆï¼‰ï¼š\n\nRegularization(æ­£åˆ™åŒ–) æƒé‡è¡°å‡(Weight Decay)ã€‚åˆ°è®­ç»ƒçš„åæœŸï¼Œé€šè¿‡è¡°å‡å› å­ä½¿æƒé‡çš„æ¢¯åº¦ä¸‹é™åœ°è¶Šæ¥è¶Šç¼“ã€‚\n\n\nBatch Normalization\nDropout\nL1 , L2\n\n\nè°ƒæ•´ç½‘ç»œç»“æ„ è¿‡æ‹Ÿåˆå¾ˆé‡è¦çš„ä¸€ä¸ªåŸå› ä¹Ÿæ˜¯æ¨¡å‹çš„å¤æ‚åº¦å¤ªé«˜ï¼Œé™¤äº†æ­£åˆ™åŒ–æ‰‹æ®µä»¥å¤–ï¼Œé€‚å½“å‡å°æ¨¡å‹çš„è§„æ¨¡ä¹Ÿæ˜¯å¾ˆé‡è¦çš„ï¼Œå°½é‡è®©ç¥ç»ç½‘ç»œç»“æ„çš„å‡è®¾ç©ºé—´ä¸é¢„æœŸç›®æ ‡æ¨¡å‹éœ€è¦å­˜å‚¨çš„ä¿¡æ¯é‡ç›¸åŒ¹é…ã€‚\nå¢å¤§è®­ç»ƒæ•°æ®é‡ è¿™æ˜¯ç»ˆæè§£å†³æ–¹æ¡ˆï¼Œæ·±åº¦å­¦ä¹ å°±æ˜¯åœ¨æœ‰å¤§é‡æ•°æ®çš„åŸºç¡€ä¸Šå‘å±•èµ·æ¥çš„ã€‚æ·±åº¦å­¦ä¹ çš„ä¸‰ä»¶å¥—ï¼šæ•°æ®ã€æ¨¡å‹å’Œç¡¬ä»¶ã€‚æ¨¡å‹å¯ä»¥ç›´æ¥æ‹¿æ¥ç”¨ï¼Œç¡¬ä»¶å¯ä»¥èŠ±é’±ä¹°ï¼Œä½†æ˜¯æ•°æ®éœ€è¦ä¸€ç‚¹ä¸€ç‚¹å»æ”¶é›†ï¼Œè€Œä¸”å¾ˆå¤šé—®é¢˜çš„è§£å†³å°±ä¾èµ–äºå¤§é‡çš„æ•°æ®ï¼Œæ²¡æ•°æ®å°±æ²¡æœ‰ä¸€åˆ‡ã€‚\nEarly Stopping(æ—©åœæ³•) (è¯¦ç»†è§£é‡Š)æ—©åœæ³•å°†æ•°æ®åˆ†æˆè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼Œè®­ç»ƒé›†ç”¨æ¥è®¡ç®—æ¢¯åº¦ã€æ›´æ–°æƒé‡å’Œé˜ˆå€¼ï¼ŒéªŒè¯é›†ç”¨æ¥ä¼°è®¡è¯¯å·®ï¼Œè‹¥è®­ç»ƒé›†è¯¯å·®é™ä½ä½†éªŒè¯é›†è¯¯å·®å‡é«˜ï¼Œåˆ™åœæ­¢è®­ç»ƒï¼ŒåŒæ—¶è¿”å›å…·æœ‰æœ€å°éªŒè¯é›†è¯¯å·®çš„è¿æ¥æƒå’Œé˜ˆå€¼ã€‚\n\n9.4 åˆ¤æ–­è¿‡æ‹Ÿåˆï¼Œæ¬ æ‹Ÿåˆ\nå‡ºå¤„\n\n\n\n\n\n\n\n\n\nå­¦ä¹ æ›²çº¿å°±æ˜¯é€šè¿‡ç”»å‡ºä¸åŒè®­ç»ƒé›†å¤§å°æ—¶è®­ç»ƒé›†å’Œäº¤å‰éªŒè¯çš„å‡†ç¡®ç‡ï¼Œå¯ä»¥çœ‹åˆ°æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„è¡¨ç°ï¼Œè¿›è€Œæ¥åˆ¤æ–­æ¨¡å‹æ˜¯å¦æ–¹å·®åé«˜æˆ–åå·®è¿‡é«˜ï¼Œä»¥åŠå¢å¤§è®­ç»ƒé›†æ˜¯å¦å¯ä»¥å‡å°è¿‡æ‹Ÿåˆã€‚\n\næ¬ æ‹Ÿåˆ: å½“è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„è¯¯å·®æ”¶æ•›ä½†å´å¾ˆé«˜æ—¶ï¼Œä¸ºé«˜åå·®ã€‚ å·¦ä¸Šè§’çš„åå·®å¾ˆé«˜ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„å‡†ç¡®ç‡éƒ½å¾ˆä½ï¼Œå¾ˆå¯èƒ½æ˜¯æ¬ æ‹Ÿåˆã€‚ æˆ‘ä»¬å¯ä»¥å¢åŠ æ¨¡å‹å‚æ•°ï¼Œæ¯”å¦‚ï¼Œæ„å»ºæ›´å¤šçš„ç‰¹å¾ï¼Œå‡å°æ­£åˆ™é¡¹ã€‚ æ­¤æ—¶é€šè¿‡å¢åŠ æ•°æ®é‡æ˜¯ä¸èµ·ä½œç”¨çš„ã€‚\nè¿‡æ‹Ÿåˆ: å½“è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„è¯¯å·®ä¹‹é—´æœ‰å¤§çš„å·®è·æ—¶ï¼Œä¸ºé«˜æ–¹å·®ã€‚ å½“è®­ç»ƒé›†çš„å‡†ç¡®ç‡æ¯”å…¶ä»–ç‹¬ç«‹æ•°æ®é›†ä¸Šçš„æµ‹è¯•ç»“æœçš„å‡†ç¡®ç‡è¦é«˜æ—¶ï¼Œä¸€èˆ¬éƒ½æ˜¯è¿‡æ‹Ÿåˆã€‚ å³ä¸Šè§’æ–¹å·®å¾ˆé«˜ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„å‡†ç¡®ç‡ç›¸å·®å¤ªå¤šï¼Œåº”è¯¥æ˜¯è¿‡æ‹Ÿåˆã€‚ æˆ‘ä»¬å¯ä»¥å¢å¤§è®­ç»ƒé›†ï¼Œé™ä½æ¨¡å‹å¤æ‚åº¦ï¼Œå¢å¤§æ­£åˆ™é¡¹ï¼Œæˆ–è€…é€šè¿‡ç‰¹å¾é€‰æ‹©å‡å°‘ç‰¹å¾æ•°ã€‚\n\n\n\n\n\n\n\n\n\nç†æƒ³æƒ…å†µæ˜¯æ˜¯æ‰¾åˆ°åå·®å’Œæ–¹å·®éƒ½å¾ˆå°çš„æƒ…å†µï¼Œå³æ”¶æ•›ä¸”è¯¯å·®è¾ƒå°ã€‚\n9.5 æ¢¯åº¦æ¶ˆå¤±å’Œæ¢¯åº¦çˆ†ç‚¸ï¼Œå“ªäº›å‡½æ•°ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±\n\n\n\n\n\n\n\n\n\næ¢¯åº¦æ¶ˆå¤±é—®é¢˜å’Œæ¢¯åº¦çˆ†ç‚¸é—®é¢˜ä¸€èˆ¬éšç€ç½‘ç»œå±‚æ•°çš„å¢åŠ ä¼šå˜å¾—è¶Šæ¥è¶Šæ˜æ˜¾ã€‚\nå…¶å®æ¢¯åº¦çˆ†ç‚¸å’Œæ¢¯åº¦æ¶ˆå¤±é—®é¢˜éƒ½æ˜¯å› ä¸ºç½‘ç»œå¤ªæ·±ï¼Œç½‘ç»œæƒå€¼æ›´æ–°ä¸ç¨³å®šé€ æˆçš„ï¼Œæœ¬è´¨ä¸Šæ˜¯å› ä¸ºæ¢¯åº¦åå‘ä¼ æ’­ä¸­çš„è¿ä¹˜æ•ˆåº”ã€‚å¯¹äºæ›´æ™®éçš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå¯ä»¥è€ƒè™‘ç”¨ReLUæ¿€æ´»å‡½æ•°å–ä»£sigmoidæ¿€æ´»å‡½æ•°ã€‚å¦å¤–ï¼ŒLSTMçš„ç»“æ„è®¾è®¡ä¹Ÿå¯ä»¥æ”¹å–„RNNä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ã€‚\n\n\n\n\n\n\n\n\n\nå“ªäº›å‡½æ•°ä¼šå¯¼è‡´æ¢¯åº¦æ¶ˆå¤±? sigmoid\nè§£å†³æ–¹æ³•ï¼š 1. å¥½çš„å‚æ•°åˆå§‹åŒ–æ–¹å¼ï¼Œå¦‚Heåˆå§‹åŒ– 2. éé¥±å’Œçš„æ¿€æ´»å‡½æ•°ï¼ˆå¦‚ ReLUï¼‰ 3. æ‰¹é‡è§„èŒƒåŒ–ï¼ˆBatch Normalizationï¼‰ 4. æ¢¯åº¦æˆªæ–­ï¼ˆGradient Clippingï¼‰ 5. æ›´å¿«çš„ä¼˜åŒ–å™¨ 6. LSTM\n9.6 cnnä¸­ç½‘ç»œæƒé‡åˆå§‹åŒ–ä¸º0æœ‰ä»€ä¹ˆé—®é¢˜ï¼Œä¸ºä»€ä¹ˆä¸èƒ½ï¼Œå…¨éƒ¨åˆå§‹åŒ–ä¸ºå¸¸æ•°å‘¢\n\n\n\n\n\n\n\n\n\nç»“è®ºï¼šåœ¨è®­ç»ƒç¥ç»ç½‘ç»œçš„æ—¶å€™ï¼Œæƒé‡åˆå§‹åŒ–è¦è°¨æ…ï¼Œä¸èƒ½åˆå§‹åŒ–ä¸º0\nå‚è€ƒ å¦‚æœç¥ç»å…ƒçš„æƒé‡è¢«åˆå§‹åŒ–ä¸º0ï¼Œ åœ¨ç¬¬ä¸€æ¬¡æ›´æ–°çš„æ—¶å€™ï¼Œé™¤äº†è¾“å‡ºä¹‹å¤–ï¼Œæ‰€æœ‰çš„ä¸­é—´å±‚çš„èŠ‚ç‚¹çš„å€¼éƒ½ä¸ºé›¶ã€‚ä¸€èˆ¬ç¥ç»ç½‘ç»œæ‹¥æœ‰å¯¹ç§°çš„ç»“æ„ï¼Œé‚£ä¹ˆåœ¨è¿›è¡Œç¬¬ä¸€æ¬¡è¯¯å·®åå‘ä¼ æ’­æ—¶ï¼Œæ›´æ–°åçš„ç½‘ç»œå‚æ•°å°†ä¼šç›¸åŒï¼Œåœ¨ä¸‹ä¸€æ¬¡æ›´æ–°æ—¶ï¼Œç›¸åŒçš„ç½‘ç»œå‚æ•°å­¦ä¹ æå–ä¸åˆ°æœ‰ç”¨çš„ç‰¹å¾ï¼Œå› æ­¤æ·±åº¦å­¦ä¹ æ¨¡å‹éƒ½ä¸ä¼šä½¿ç”¨0åˆå§‹åŒ–æ‰€æœ‰å‚æ•°ã€‚\n\næ¨¡å‹æ‰€æœ‰æƒé‡wåˆå§‹åŒ–ä¸º0ï¼Œæ‰€æœ‰åç½®båˆå§‹åŒ–ä¸º0 ç®€å•æ¥è¯´ï¼Œå°±ä¼šå‡ºç°åŒä¸€éšè—å±‚æ‰€æœ‰ç¥ç»å…ƒçš„è¾“å‡ºéƒ½ä¸€è‡´ï¼Œå¯¹äºåæœŸä¸åŒçš„batchï¼Œæ¯ä¸€éšè—å±‚çš„æƒé‡éƒ½èƒ½å¾—åˆ°æ›´æ–°ï¼Œä½†æ˜¯å­˜åœ¨æ¯ä¸€éšè—å±‚çš„éšè—ç¥ç»å…ƒæƒé‡éƒ½æ˜¯ä¸€è‡´çš„ï¼Œå¤šä¸ªéšè—ç¥ç»å…ƒçš„ä½œç”¨å°±å¦‚åŒ1ä¸ªç¥ç»å…ƒã€‚\næ¨¡å‹æ‰€æœ‰æƒé‡wåˆå§‹åŒ–ä¸º0ï¼Œæ‰€æœ‰åç½®béšæœºåˆå§‹åŒ– è¿™ç§æ–¹å¼å­˜åœ¨æ›´æ–°è¾ƒæ…¢ã€æ¢¯åº¦æ¶ˆå¤±ã€æ¢¯åº¦çˆ†ç‚¸ç­‰é—®é¢˜ï¼Œåœ¨å®è·µä¸­ï¼Œé€šå¸¸ä¸ä¼šé€‰æ‹©æ­¤æ–¹å¼ã€‚\næ¨¡å‹æ‰€æœ‰çš„æƒé‡wéšæœºåˆå§‹åŒ–ï¼Œæ‰€æœ‰åç½®båˆå§‹åŒ–ä¸º0 åœ¨åå‘ä¼ æ’­çš„è¿‡ç¨‹ä¸­æ‰€æœ‰æƒé‡çš„å¯¼æ•°éƒ½ä¸ç›¸åŒï¼Œæ‰€ä»¥æƒé‡å’Œåç½®béƒ½èƒ½å¾—åˆ°æ›´æ–°ã€‚\n\n9.7 åˆå§‹åŒ–æ–¹æ³•ï¼ŒHeè§£å†³äº†å•¥\nå‚è€ƒ\nXavier Xavieråˆå§‹åŒ–å°†ä¸€ä¸ªå±‚çš„æƒé‡è®¾ç½®ä¸ºä»ä¸€ä¸ªæœ‰ç•Œçš„éšæœºå‡åŒ€åˆ†å¸ƒä¸­é€‰æ‹©çš„å€¼\n\nå…¶ä¸­ï¼Œæ˜¯ä¼ å…¥ç½‘ç»œè¿æ¥çš„æ•°é‡å«â€œæ‰‡å…¥â€ï¼Œæ˜¯ä»é‚£å±‚å‡ºå»çš„ç½‘ç»œè¿æ¥çš„æ•°é‡ï¼Œä¹Ÿè¢«ç§°ä¸ºâ€œæ‰‡å‡ºâ€ã€‚\nHe\n\n\n\n\n\n\n\n\n\næ¢ç´¢å¦‚ä½•ç”¨ç±»reluçš„æ¿€æ´»å‡½æ•°åœ¨ç½‘ç»œä¸­æœ€å¥½åœ°åˆå§‹åŒ–æƒé‡æ˜¯kobjective Heç­‰äººï¼Œæå‡ºä»–ä»¬è‡ªå·±çš„åˆå§‹åŒ–æ–¹æ¡ˆçš„åŠ¨æœºï¼Œè¿™æ˜¯ä¸ºä½¿ç”¨è¿™äº›éå¯¹ç§°ã€éçº¿æ€§æ¿€æ´»çš„æ·±å±‚ç¥ç»ç½‘ç»œé‡èº«å®šåˆ¶çš„ã€‚\næ–¹æ³•ï¼š 1. ä¸ºç»™å®šå±‚ä¸Šçš„æƒå€¼çŸ©é˜µåˆ›å»ºä¸€ä¸ªå¼ é‡ï¼Œå¹¶ç”¨ä»æ ‡å‡†æ­£æ€åˆ†å¸ƒä¸­éšæœºé€‰æ‹©çš„æ•°å­—å¡«å……å®ƒã€‚ 2. å°†æ¯ä¸ªéšæœºé€‰æ‹©çš„æ•°å­—ä¹˜ä»¥âˆš2/âˆšnï¼Œå…¶ä¸­næ˜¯ä»ä¸Šä¸€å±‚çš„è¾“å‡º(ä¹Ÿç§°ä¸ºâ€œæ‰‡å…¥â€)è¿›å…¥ç»™å®šå±‚çš„è¿æ¥æ•°ã€‚ 3. åç½®å¼ é‡åˆå§‹åŒ–ä¸ºé›¶ã€‚\n9.8 åå‘ä¼ æ’­æ—¶ï¼ŒåŒä¸€ä¸ªmini-batchåœ¨å…±äº«å·ç§¯å±‚çš„æœ«ç«¯æ˜¯å¦éœ€è¦é™¤ä»¥batch-sizeï¼Ÿ\nä¸ªäººè§‰å¾—ä¸éœ€è¦ã€‚\nç”±äºç›®å‰ä¸»æµæ·±åº¦å­¦ä¹ æ¡†æ¶å¤„ç†mini-batchçš„åå‘ä¼ æ’­æ—¶ï¼Œé»˜è®¤éƒ½æ˜¯å…ˆå°†æ¯ä¸ªmini-batchä¸­æ¯ä¸ªinstanceå¾—åˆ°çš„losså¹³å‡åŒ–ä¹‹åå†åæ±‚æ¢¯åº¦ï¼Œä¹Ÿå°±æ˜¯è¯´æ¯æ¬¡åå‘ä¼ æ’­çš„æ¢¯åº¦æ˜¯å¯¹mini-batchä¸­æ¯ä¸ªinstanceçš„æ¢¯åº¦å¹³å‡ä¹‹åçš„ç»“æœã€‚\n9.9 åç½®å’Œæ–¹å·®åŒºåˆ«ï¼Œæ¨¡å‹æ¯”è¾ƒå¤æ‚æ—¶ï¼Œåç½®å’Œæ–¹å·®å˜åŒ–ï¼šåç½®å˜å°ï¼Œæ–¹å·®å˜å¤§\n\n\n\n\n\n\n\n\n\næ¨¡å‹å¤æ‚åº¦å¢åŠ æ—¶ï¼Œæ¨¡å‹é¢„æµ‹çš„æ–¹å·®ä¼šå¢å¤§ï¼Œåå·®ä¼šå‡å°\nå‡ºå¤„\n\nåå·®(Bias)ï¼šåœ¨ä¸åŒè®­ç»ƒé›†ä¸Šè®­ç»ƒå¾—åˆ°çš„æ‰€æœ‰æ¨¡å‹çš„å¹³å‡æ€§èƒ½å’Œæœ€ä¼˜æ¨¡å‹çš„å·®å¼‚ï¼Œå¯ä»¥ç”¨æ¥è¡¡é‡æ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›ã€‚\næ–¹å·®(Variance)ï¼šåœ¨ä¸åŒçš„è®­ç»ƒé›†ä¸Šè®­ç»ƒå¾—åˆ°çš„æ¨¡å‹ä¹‹é—´çš„æ€§èƒ½å·®å¼‚ï¼Œè¡¨ç¤ºæ•°æ®æ‰°åŠ¨å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œå¯ä»¥ç”¨æ¥è¡¡é‡æ¨¡å‹æ˜¯å¦å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œå³æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚\n\næ‰€ä»¥ï¼Œå½“æ¨¡å‹çš„å¤æ‚åº¦å¢åŠ æ—¶ï¼Œæ¨¡å‹çš„æ‹Ÿåˆèƒ½åŠ›å¾—åˆ°å¢å¼ºï¼Œåå·®ä¾¿ä¼šå‡å°ï¼Œä½†å¾ˆæœ‰å¯èƒ½ä¼šç”±äºæ‹Ÿåˆâ€œè¿‡åº¦â€ï¼Œä»è€Œå¯¹æ•°æ®æ‰°åŠ¨æ›´åŠ æ•æ„Ÿï¼Œå¯¼è‡´æ–¹å·®å¢å¤§ã€‚ä»æ¨¡å‹è¯„ä»·ä¸Šæ¥çœ‹ï¼Œæ¨¡å‹å¤æ‚åº¦å¢åŠ åï¼Œå‡ºç°éªŒè¯é›†æ•ˆæœæå‡ï¼Œä½†æ˜¯æµ‹è¯•é›†æ•ˆæœä¸‹é™çš„ç°è±¡ã€‚\n9.10 å¤šå¡è®­ç»ƒï¼Œæ¢¯åº¦ä¸ºä»€ä¹ˆå¹³å‡\nå‡ºå¤„\nå•GPUæƒ…å†µä¸‹ï¼Œä¹Ÿè¦å¯¹ä¸€ä¸ª batch ä¸­ æ¯ä¸ª data sample çš„gradient æ±‚å¹³å‡ã€‚ç°åœ¨å›åˆ°å¤šå¡çš„æƒ…å†µï¼Œç›¸å½“äºæŠŠä¸€ä¸ª batch åˆ†åˆ°å¤šä¸ªå¡ä¸Šå»è·‘ï¼Œä»ç„¶å¸Œæœ›åœ¨è¿™ä¸ª batch å†…æ±‚å¹³å‡ã€‚ç°åœ¨å‡è®¾æˆ‘ä»¬ä¸€ä¸ª batch æœ‰ 20 çš„ data sampleï¼Œæœ¬æ¥å•å¡æˆ‘ä»¬å¯ä»¥ç›´æ¥å¯¹è¿™ 20 ä¸ª data sample æ±‚å¹³å‡ï¼Œç°åœ¨åŠ å…¥æˆ‘ä»¬æœ‰ 5 ä¸ªå¡ï¼Œé‚£ä¹ˆæ¯ä¸ªå¡è·‘ 4 ä¸ª data sampleï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å…ˆ 4 ä¸ª 4 ä¸ªçš„æ±‚å¹³å‡ï¼Œç„¶åæŠŠå¾—åˆ°çš„ 5 ä¸ªå‡å€¼æ±‚å¹³å‡ï¼Œå¾—åˆ°çš„ç»“æœå’Œç›´æ¥å¯¹ 20 ä¸ª data sample æ±‚å¹³å‡æ˜¯ä¸€æ ·çš„ã€‚\n9.11 è’¸é¦\nè¯¦è§\n9.12 æ€ä¹ˆåšæ¨¡å‹å‹ç¼©ï¼Ÿ\nè¯¦è§\n9.1x int8é‡åŒ–å’Œå·ç§¯åŠ é€Ÿçš„æ–¹å¼\nfftï¼Œwinogradï¼Œim2col+sgemm è¯¦è§\n10. åˆ†ç±»\né›¶æ ·æœ¬åˆ†ç±»é—®é¢˜ï¼Œå¦‚æœæµ‹è¯•å‡ºç°ä¸€ä¸ªå›¾ç‰‡æ˜¯è®­ç»ƒæ—¶æ²¡æœ‰çš„ï¼Œæ€ä¹ˆåš\né›¶æ¬¡å­¦ä¹ \nçŸ¥ä¹: ä¸ç”¨é‚£ä¹ˆéº»çƒ¦ï¼Œæˆ‘ä¹‹å‰åšinsç”¨æˆ·åˆ†ç±»çš„æ—¶å€™ä¹Ÿé‡åˆ°è¿‡ç±»ä¼¼çš„é—®é¢˜ä¸è¿‡æˆ‘ç”¨çš„æ˜¯å‘é‡åŒ–æ–‡æœ¬æ•°æ®ä¹‹åä¸Šlightgbmæµ‹è¯•ï¼Œè®­ç»ƒé›†å¤§æ¦‚æœ‰åå‡ ä¸ªç±»åˆ«åŒ…æ‹¬å¨å¸ˆï¼Œå® ç‰©ï¼Œç”»å®¶ï¼Œæ‘„å½±å¸ˆç­‰ï¼Œæµ‹è¯•çš„æ—¶å€™å‘ç°äº†æµ‹è¯•é›†ä¸­å‡ºç°äº†â€œé»‘äººè¯´å”±æ­Œæ‰‹â€è¿™ä¸ªç¾¤ä½“è®­ç»ƒé›†ä¸­æ²¡æœ‰çš„ç¾¤ä½“ï¼Œä½†æ˜¯å› ä¸ºæ¨¡å‹å·²ç»è®­ç»ƒå‡ºäº†åå‡ ä¸ªåˆ†ç±»çš„ç»“æ„äº†æ‰€ä»¥æœ€ç»ˆé»‘äººè¯´å”±æ­Œæ‰‹è¢«é¢„æµ‹ä¸ºå® ç‰©ï¼Œåæ¥æƒ³äº†ä¸€ä¸ªåŠæ³•å°±æ˜¯æŠŠå¤šåˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºå¤šä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œç„¶åè®¾å®šé¢„æµ‹æ¦‚ç‡è¶…è¿‡æ¯”å¦‚0.8çš„æ—¶å€™åˆ¤å®šä¸ºæŸä¸ªç±»åˆ«å¦åˆ™åˆ¤å®šä¸ºå…¶å®ƒç±»ï¼Œè¿™æ ·å°±å¯ä»¥è§£å†³é—®é¢˜äº†ï¼Œé»‘äººè¯´å”±æ­Œæ‰‹æœ€ç»ˆå› ä¸ºæ²¡æœ‰è¾¾åˆ°é¢„å…ˆè®¾å®šçš„é˜ˆå€¼æ‰€ä»¥æ²¡æœ‰è¢«åˆ¤å®šä¸ºä»»ä½•ç±»åˆ«ã€‚\n11. ç›®æ ‡æ£€æµ‹\n11.1 roi poolingå’Œroi alignåŒºåˆ«ï¼Œæ€ä¹ˆåšæ’å€¼\nå‚è€ƒ1å‚è€ƒ2\nè¿™ä¸¤ä¸ªéƒ½æ˜¯ç”¨åœ¨rpnä¹‹åçš„ã€‚å…·ä½“æ¥è¯´ï¼Œä»feature mapä¸Šç»è¿‡RPNå¾—åˆ°ä¸€ç³»åˆ—çš„proposalsï¼Œå¤§æ¦‚2kä¸ªï¼Œè¿™äº›bboxå¤§å°ä¸ç­‰ï¼Œå¦‚ä½•å°†è¿™äº›bboxçš„ç‰¹å¾è¿›è¡Œç»Ÿä¸€è¡¨ç¤ºå°±å˜æˆäº†ä¸€ä¸ªé—®é¢˜ã€‚å³éœ€è¦æ‰¾ä¸€ä¸ªåŠæ³•ä»å¤§å°ä¸ç­‰çš„æ¡†ä¸­æå–ç‰¹å¾ä½¿è¾“å‡ºç»“æœæ˜¯ç­‰é•¿çš„ã€‚\næœ€å¼€å§‹ç›®æ ‡æ£€æµ‹æ¨¡å‹Faster RCNNä¸­ç”¨äº†ä¸€ä¸ªç®€å•ç²—æš´çš„åŠæ³•ï¼Œå«ROI Poolingã€‚ è¯¥æ–¹å¼åœ¨è¯­ä¹‰åˆ†å‰²è¿™ç§ç²¾ç»†ç¨‹åº¦é«˜çš„ä»»åŠ¡ä¸­ï¼Œä¸å¤Ÿç²¾å‡†ã€‚RoI Align åœ¨ Mask RCNN ä¸­è¢«é¦–æ¬¡æå‡ºã€‚é’ˆå¯¹RoI Poolingåœ¨è¯­ä¹‰åˆ†å‰²ç­‰ç²¾ç»†åº¦ä»»åŠ¡ä¸­ç²¾ç¡®åº¦çš„é—®é¢˜æå‡ºçš„æ”¹è¿›æ–¹æ¡ˆã€‚\n11.1.1 ROI Pooling\n\nå‡å¦‚ç°åœ¨æœ‰ä¸€ä¸ª8x8çš„feature mapï¼Œç°åœ¨å¸Œæœ›å¾—åˆ°2x2çš„è¾“å‡ºï¼Œæœ‰ä¸€ä¸ªbboxåæ ‡ä¸º[0,3,7,8]ã€‚ è¿™ä¸ªbboxçš„w=7ï¼Œh=5ï¼Œå¦‚æœè¦ç­‰åˆ†æˆå››å—æ˜¯åšä¸åˆ°çš„ï¼Œå› æ­¤åœ¨ROI Poolingä¸­ä¼šè¿›è¡Œå–æ•´ã€‚å°±æœ‰äº†ä¸Šå›¾çœ‹åˆ°çš„hè¢«åˆ†å‰²ä¸º2,3ï¼Œwè¢«åˆ†å‰²æˆ3,4ã€‚è¿™æ ·ä¹‹ååœ¨æ¯ä¸€å—(ç§°ä¸ºbin)ä¸­åšmax poolingï¼Œå¯ä»¥å¾—åˆ°ä¸‹å›¾çš„ç»“æœã€‚\n\nè¿™æ ·å°±å¯ä»¥å°†ä»»æ„å¤§å°bboxè½¬æˆ2x2è¡¨ç¤ºçš„featureã€‚ ROI Poolingéœ€è¦å–æ•´ï¼Œè¿™æ ·çš„å–æ•´æ“ä½œè¿›è¡Œäº†ä¸¤æ¬¡ï¼Œä¸€æ¬¡æ˜¯å¾—åˆ°bboxåœ¨feature mapä¸Šçš„åæ ‡æ—¶ã€‚\nä¾‹å¦‚ï¼šåŸå›¾ä¸Šçš„bboxå¤§å°ä¸º665x665ï¼Œç»backboneåï¼Œspatial scale=1/32ã€‚å› æ­¤bboxä¹Ÿç›¸åº”åº”è¯¥ç¼©å°ä¸º665/32=20.78ï¼Œä½†æ˜¯è¿™å¹¶ä¸æ˜¯ä¸€ä¸ªçœŸå®çš„pixelæ‰€åœ¨çš„ä½ç½®ï¼Œå› æ­¤è¿™ä¸€æ­¥ä¼šå–ä¸º20ã€‚0.78çš„å·®è·åé¦ˆåˆ°åŸå›¾å°±æ˜¯0.78x32=25ä¸ªåƒç´ çš„å·®è·ã€‚å¦‚æœæ˜¯å¤§ç›®æ ‡è¿™25çš„å·®è·å¯èƒ½çœ‹ä¸å‡ºæ¥ï¼Œä½†å¯¹äºå°ç›®æ ‡è€Œè¨€å·®è·å°±æ¯”è¾ƒå·¨å¤§äº†ã€‚\n\nä¸¤æ¬¡é‡åŒ– ä»¥è¾“å‡ºç›®æ ‡ç‰¹å¾å›¾å°ºå¯¸å¤§å°ä¸º2x2x512è¿›è¡Œè¯´æ˜ 1. å¯¹é½åˆ°ç½‘æ ¼å•å…ƒï¼ˆsnap to grid cellï¼‰ é¦–å…ˆå°†ä¸€ä¸ªæµ®ç‚¹æ•°RoIé‡åŒ–ä¸ºç‰¹å¾æ˜ å°„çš„ç¦»æ•£ç²’åº¦ã€‚è¡¨ç°ä¸ºRoIå¯¹åº”çš„ç‰¹å¾å›¾çš„ä¸åŸå§‹ç‰¹å¾å›¾çš„ç½‘æ ¼å•å…ƒå¯¹é½ã€‚è¿™é‡Œä¸ºç¬¬ä¸€æ¬¡é‡åŒ–æ“ä½œã€‚ ä¸‹å›¾ä¸­ç»¿è‰²æ¡†ä¸ºRoIå¯¹åº”çš„å®é™…åŒºåŸŸï¼ˆç”±äºç»è¿‡ç‰¹å¾å°ºåº¦å˜æ¢ï¼Œå¯¼è‡´RoIçš„åæ ‡ä¼šå¯èƒ½ä¼šè½åˆ°ç‰¹å¾å›¾çš„å•å…ƒä¹‹é—´ï¼‰ï¼Œ è“è‰²æ¡†ä»£è¡¨é‡åŒ–(ç½‘æ ¼å¯¹é½)åçš„RoIæ‰€å¯¹åº”çš„ç‰¹å¾å›¾ã€‚ï¼ˆå¾—åˆ°åˆ°é‡åŒ–ç‰¹å¾å›¾å°ºå¯¸ä¸º5x7x512ï¼‰ \n\nåˆ’åˆ†ç½‘æ ¼ä¸ºå­åŒºåŸŸï¼ˆbinï¼‰ ç²—ç•¥åœ°å°†ç½‘æ ¼åˆ†ä¸ºH*Wï¼ˆFast RCNN ä¸­è®¾ä¸º7x7ï¼‰ä¸ªå­ç½‘æ ¼åŒºåŸŸã€‚å°†ä¸Šä¸€æ­¥å¾—åˆ°çš„é‡åŒ–RoI ç‰¹å¾è¿›ä¸€æ­¥ç»†åˆ†ä¸ºé‡åŒ–çš„ç©ºé—´å•å…ƒ(bin)ã€‚è¿™é‡Œè¿›è¡Œäº†ç¬¬äºŒæ¬¡é‡åŒ–æ“ä½œã€‚ ä¸ºäº†å¾—åˆ°è¾“å‡ºçš„ç‰¹å¾å›¾ä¸º2x2x512ï¼Œè¿™é‡Œçš„é‡åŒ–æ“ä½œå°±æ˜¯å°†ä¸Šä¸€æ­¥çš„åˆ°é‡åŒ–ç‰¹å¾å›¾åˆ’åˆ†ä¸º2x2ä¸ªç‰¹å¾å•å…ƒã€‚å¦‚æœæ— æ³•é€šè¿‡ç›´æ¥å‡åˆ†å¾—åˆ°é‡åŒ–çš„å­åŒºåŸŸï¼Œé€šè¿‡åˆ†åˆ«é‡‡å–å‘ä¸Šå–æ•´ï¼ˆceilï¼‰å’Œå‘ä¸‹å–æ•´ï¼ˆfloorï¼‰çš„åˆ°å¯¹åº”çš„å•å…ƒå°ºå¯¸å¤§å°ã€‚ä»¥å½“å‰4x5å°ºå¯¸çš„ç‰¹å¾å›¾ä¸ºä¾‹ï¼Œå¯¹äºå®½åº¦æ–¹å‘4/2=2ï¼Œä½†æ˜¯å¯¹äºé«˜åº¦æ–¹å‘ç”±äº5/2=2.5ï¼Œ é€šè¿‡å‘ä¸Šå’Œå‘ä¸‹å–æ•´æ•´ï¼Œç¡®å®šé«˜åº¦æ–¹å‘ç‰¹å¾å­åŒºåŸŸçš„å¤§å°åˆ†åˆ«ä¸º2å’Œ3ã€‚ \n\nç¼ºç‚¹ æ¯ä¸€æ¬¡é‡åŒ–æ“ä½œéƒ½ä¼šå¯¹åº”ç€è½»å¾®çš„åŒºåŸŸç‰¹å¾é”™ä½ï¼ˆmisalignedï¼‰ï¼Œ è¿™äº›é‡åŒ–æ“ä½œåœ¨RoIå’Œæå–åˆ°çš„ç‰¹å¾ä¹‹é—´å¼•å…¥äº†åå·®ã€‚è¿™äº›é‡åŒ–å¯èƒ½ä¸ä¼šå½±å“å¯¹åˆ†ç±»ä»»åŠ¡ï¼Œä½†å®ƒå¯¹é¢„æµ‹åƒç´ ç²¾åº¦æ©æ¨¡æœ‰å¾ˆå¤§çš„è´Ÿé¢å½±å“ã€‚\n11.1.2 ROI Align\nå› æ­¤æœ‰äººæå‡ºä¸éœ€è¦è¿›è¡Œå–æ•´æ“ä½œï¼Œå¦‚æœè®¡ç®—å¾—åˆ°å°æ•°ï¼Œä¹Ÿå°±æ˜¯æ²¡æœ‰è½åˆ°çœŸå®çš„pixelä¸Šï¼Œé‚£ä¹ˆå°±ç”¨æœ€è¿‘çš„pixelå¯¹è¿™ä¸€ç‚¹è™šæ‹Ÿpixelè¿›è¡ŒåŒçº¿æ€§æ’å€¼ï¼Œå¾—åˆ°è¿™ä¸ªâ€œpixelâ€çš„å€¼ã€‚ å…·ä½“åšæ³•å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š \n\næ¥æºè§æ°´å°\n\n\nå°†bboxåŒºåŸŸæŒ‰è¾“å‡ºè¦æ±‚çš„sizeè¿›è¡Œç­‰åˆ†ï¼Œå¾ˆå¯èƒ½ç­‰åˆ†åå„é¡¶ç‚¹è½ä¸åˆ°çœŸå®çš„åƒç´ ç‚¹ä¸Š\næ²¡å…³ç³»ï¼Œåœ¨æ¯ä¸ªbinä¸­å†å–å›ºå®šçš„4ä¸ªç‚¹(ä½œè€…å®éªŒåå‘ç°å–4æ•ˆæœè¾ƒå¥½)ï¼Œä¹Ÿå°±æ˜¯å›¾äºŒå³ä¾§çš„è“è‰²ç‚¹\né’ˆå¯¹æ¯ä¸€ä¸ªè“ç‚¹ï¼Œè·ç¦»å®ƒæœ€è¿‘çš„4ä¸ªçœŸå®åƒç´ ç‚¹çš„å€¼åŠ æƒ(åŒçº¿æ€§æ’å€¼)ï¼Œæ±‚å¾—è¿™ä¸ªè“ç‚¹çš„å€¼\nä¸€ä¸ªbinå†…ä¼šç®—å‡º4ä¸ªæ–°å€¼ï¼Œåœ¨è¿™äº›æ–°å€¼ä¸­å–maxï¼Œä½œä¸ºè¿™ä¸ªbinçš„è¾“å‡ºå€¼\næœ€åå°±èƒ½å¾—åˆ°2x2çš„è¾“å‡º\n\nâ€‹ ä¸‹é¢ä»¥è¾“å‡ºç›®æ ‡ç‰¹å¾å›¾å°ºå¯¸å¤§å°ä¸º2x2x512è¿›è¡Œè¯´æ˜ 1. éå†å€™é€‰æ¯ä¸ªå€™é€‰åŒºåŸŸï¼Œä¿æŒæµ®ç‚¹æ•°è¾¹ç•Œä¸åšé‡åŒ–ï¼ˆä¸å¯¹é½ç½‘æ ¼å•å…ƒï¼‰ï¼›åŒæ—¶å¹³å‡åˆ†ç½‘æ ¼åˆ†ä¸ºHxWï¼ˆè¿™é‡Œä¸º2x2ï¼‰ä¸ªå­ç½‘æ ¼åŒºåŸŸï¼Œæ¯ä¸ªå•å…ƒçš„è¾¹ç•Œä¹Ÿä¸åšé‡åŒ–ã€‚ \n\nå¯¹äºæ¯ä¸ªåŒºåŸŸé€‰æ‹©4ä¸ªè§„åˆ™é‡‡æ ·ç‚¹ï¼ˆåˆ†åˆ«å¯¹åº”å°†åŒºåŸŸè¿›ä¸€æ­¥å¹³å‡åˆ†ä¸ºå››ä¸ªåŒºåŸŸï¼Œå–æ¯ä¸ªå­åŒºåŸŸçš„ä¸­ç‚¹ï¼‰ã€‚ \nåˆ©ç”¨åŒçº¿æ€§æ’å€¼è®¡ç®—å¾—åˆ°å››ä¸ªé‡‡ç”¨ç‚¹çš„åƒç´ å€¼å¤§å°ã€‚ä¸‹å›¾ä¸ºä¸€ä¸ªè§„åˆ™é‡‡æ ·ç‚¹æ‰€å¯¹åº”çš„é‚»è¿‘åŒºåŸŸç¤ºæ„å›¾ã€‚ \nåˆ©ç”¨æœ€å¤§æ± åŒ–ï¼ˆmax poolingï¼‰æˆ–å¹³å‡æ± åŒ–(average pooling)åˆ†åˆ«å¯¹æ¯ä¸ªå­åŒºåŸŸæ‰§è¡Œèšåˆæ“ä½œï¼Œå¾—åˆ°æœ€ç»ˆçš„ç‰¹å¾å›¾ã€‚ \n\n11.2 OHEM\nTraining Region-based Object Detectors with Online Hard Example Mining\n\n\n\n\n\n\n\n\n\néœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªOHEMé€‚åˆäºbatch sizeï¼ˆimagesï¼‰è¾ƒå°‘ï¼Œä½†æ¯å¼ imageçš„exampleså¾ˆå¤šçš„æƒ…å†µã€‚\nOHEMç®—æ³•çš„æ ¸å¿ƒæ˜¯é€‰æ‹©ä¸€äº›hard exampleä½œä¸ºè®­ç»ƒçš„æ ·æœ¬ä»è€Œæ”¹å–„ç½‘ç»œå‚æ•°æ•ˆæœï¼Œhard exampleæŒ‡çš„æ˜¯æœ‰å¤šæ ·æ€§å’Œé«˜æŸå¤±çš„æ ·æœ¬ã€‚ hard exampleæ˜¯æ ¹æ®æ¯ä¸ªROIçš„æŸå¤±æ¥é€‰æ‹©çš„ï¼Œé€‰æ‹©æŸå¤±æœ€å¤§çš„ä¸€äº›ROIã€‚ä½†æ˜¯è¿™é‡Œæœ‰ä¸€ä¸ªé—®é¢˜ï¼šé‡åˆç‡æ¯”è¾ƒå¤§çš„ROIä¹‹é—´çš„æŸå¤±ä¹Ÿæ¯”è¾ƒç›¸ä¼¼ã€‚å› æ­¤è¿™é‡Œä½œè€…é‡‡ç”¨NMSï¼ˆnon-maximum suppresisonï¼‰å»é™¤é‡åˆç‡è¾ƒå¤§çš„ROIï¼Œè¿™é‡Œä½œè€…ç»™çš„é˜ˆå€¼æ˜¯å½“IOUå¤§äº0.7å°±è®¤ä¸ºé‡åˆç‡è¾ƒé«˜ï¼Œéœ€å»é™¤ã€‚\næ³¨æ„ï¼Œè¿™é‡Œä½œè€…æ²¡æœ‰é‡‡ç”¨è®¾å®šèƒŒæ™¯å’Œç›®æ ‡æ ·æœ¬æ•°çš„æ¯”ä¾‹æ–¹å¼å¤„ç†æ•°æ®çš„ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚å› ä¸ºå¦‚æœå“ªä¸ªç±»åˆ«ä¸å¹³è¡¡ï¼Œé‚£ä¹ˆè¿™ä¸ªç±»åˆ«çš„æŸå¤±å°±ä¼šæ¯”è¾ƒå¤§ï¼Œè¿™æ ·è¢«é‡‡æ ·çš„å¯èƒ½æ€§ä¹Ÿæ¯”è¾ƒå¤§ã€‚ è®ºæ–‡ä¸­æŠŠOHEMåº”ç”¨åœ¨Fast R-CNNä¸­å…·ä½“å‚çœ‹åšæ–‡ï¼Œæ˜¯å› ä¸ºFast R-CNNç›¸å½“äºç›®æ ‡æ£€æµ‹å„å¤§æ¡†æ¶çš„æ¯ä½“ï¼Œå¾ˆå¤šæ¡†æ¶éƒ½æ˜¯å®ƒçš„å˜å½¢ï¼Œæ‰€ä»¥ä½œè€…åœ¨Fast R-CNNä¸Šåº”ç”¨å¾ˆæœ‰è¯´æ˜æ€§ã€‚\n\nä½œè€…å°†OHEMåº”ç”¨åœ¨Fast RCNNçš„ç½‘ç»œç»“æ„ï¼Œå¦‚ä¸Šå›¾ã€‚è¿™é‡ŒåŒ…å«ä¸¤ä¸ªROI networkï¼Œä¸Šé¢ä¸€ä¸ªROI networkæ˜¯åªè¯»çš„ï¼Œä¸ºæ‰€æœ‰çš„ROIåœ¨å‰å‘ä¼ é€’çš„æ—¶å€™åˆ†é…ç©ºé—´ã€‚ä¸‹é¢ä¸€ä¸ªROI networkåˆ™åŒæ—¶ä¸ºå‰å‘å’Œåå‘åˆ†é…ç©ºé—´ã€‚\né¦–å…ˆï¼ŒROIç»è¿‡ROI ploolingå±‚ç”Ÿæˆfeature mapï¼Œç„¶åè¿›å…¥åªè¯»çš„ROI networkå¾—åˆ°æ‰€æœ‰ROIçš„lossï¼›ç„¶åæ˜¯hard ROI samplerç»“æ„æ ¹æ®æŸå¤±æ’åºé€‰å‡ºhard exampleï¼Œå¹¶æŠŠè¿™äº›hard exampleä½œä¸ºä¸‹é¢é‚£ä¸ªROI networkçš„è¾“å…¥ã€‚\nå®é™…è®­ç»ƒçš„æ—¶å€™ï¼Œæ¯ä¸ªmini-batchåŒ…å«Nä¸ªå›¾åƒï¼Œå…±|R|ä¸ªROIï¼Œä¹Ÿå°±æ˜¯æ¯å¼ å›¾åƒåŒ…å«|R|/Nä¸ªROIã€‚ç»è¿‡hard ROI samplerç­›é€‰åå¾—åˆ°Bä¸ªhard exampleã€‚ä½œè€…åœ¨æ–‡ä¸­é‡‡ç”¨N=2ï¼Œ|R|=4000ï¼ŒB=128ã€‚\nå¦å¤–å…³äºæ­£è´Ÿæ ·æœ¬çš„é€‰æ‹©ï¼šå½“ä¸€ä¸ªROIå’Œä¸€ä¸ªground truthçš„IOUå¤§äº0.5ï¼Œåˆ™ä¸ºæ­£æ ·æœ¬ï¼›å½“ä¸€ä¸ªROIå’Œæ‰€æœ‰ground truthçš„IOUçš„æœ€å¤§å€¼å°äº0.5æ—¶ä¸ºè´Ÿæ ·æœ¬ã€‚\næ€»ç»“æ¥è¯´ï¼Œå¯¹äºç»™å®šå›¾åƒï¼Œç»è¿‡selective search RoIsï¼ŒåŒæ ·è®¡ç®—å‡ºå·ç§¯ç‰¹å¾å›¾ã€‚ä½†æ˜¯åœ¨ç»¿è‰²éƒ¨åˆ†çš„ï¼ˆaï¼‰ä¸­ï¼Œä¸€ä¸ªåªè¯»çš„RoIç½‘ç»œå¯¹ç‰¹å¾å›¾å’Œæ‰€æœ‰RoIè¿›è¡Œå‰å‘ä¼ æ’­ï¼Œç„¶åHard RoI moduleåˆ©ç”¨è¿™äº›RoIçš„lossé€‰æ‹©Bä¸ªæ ·æœ¬ã€‚åœ¨çº¢è‰²éƒ¨åˆ†ï¼ˆbï¼‰ä¸­ï¼Œè¿™äº›é€‰æ‹©å‡ºçš„æ ·æœ¬ï¼ˆhard examplesï¼‰è¿›å…¥RoIç½‘ç»œï¼Œè¿›ä¸€æ­¥è¿›è¡Œå‰å‘å’Œåå‘ä¼ æ’­ã€‚\n\n\n\n\n\n\n\n\n\nè®ºæ–‡æåŠåˆ°å¯ä»¥ç”¨ä¸€ç§ç®€å•çš„æ–¹å¼æ¥å®Œæˆhard miningï¼šåœ¨åŸæœ‰çš„Fast-RCNNé‡Œçš„loss layeré‡Œé¢å¯¹æ‰€æœ‰çš„propsè®¡ç®—å…¶lossï¼Œæ ¹æ®losså¯¹å…¶è¿›è¡Œæ’åºï¼Œï¼ˆè¿™é‡Œå¯ä»¥é€‰ç”¨NMSï¼‰ï¼Œé€‰å‡ºK KKä¸ªhard examplesï¼ˆå³propsï¼‰ã€‚åå‘ä¼ æ’­æ—¶ï¼Œåªå¯¹è¿™K KKä¸ªpropsçš„æ¢¯åº¦/æ®‹å·®å›ä¼ ï¼Œè€Œå…¶ä»–çš„propsçš„æ¢¯åº¦/æ®‹å·®è®¾ä¸º0 00å³å¯ã€‚ç”±äºè¿™æ ·åšï¼Œå®¹æ˜“å¯¼è‡´æ˜¾å­˜æ˜¾è‘—å¢åŠ ï¼Œè¿­ä»£æ—¶é—´å¢åŠ ï¼Œ\nFocal-Lossä¸OHEMçš„å…³ç³» OHEMæ˜¯åªå–3:1çš„è´Ÿæ ·æœ¬å»è®¡ç®—lossï¼Œä¹‹å¤–çš„è´Ÿæ ·æœ¬æƒé‡ç½®é›¶ï¼Œè€Œfocal losså–äº†æ‰€æœ‰è´Ÿæ ·æœ¬ï¼Œæ ¹æ®éš¾åº¦ç»™äº†ä¸åŒçš„æƒé‡ã€‚ focal lossç›¸æ¯”OHEMçš„æå‡ç‚¹åœ¨äºï¼Œ3:1çš„æ¯”ä¾‹æ¯”è¾ƒç²—æš´ï¼Œé‚£äº›æœ‰äº›éš¾åº¦çš„è´Ÿæ ·æœ¬å¯èƒ½æ¸¸ç¦»äº3:1ä¹‹å¤–ã€‚ä¹‹å‰å®éªŒä¸­æ›¾ç»è°ƒæ•´è¿‡OHEMè¿™ä¸ªæ¯”ä¾‹ï¼Œå‘ç°æ˜¯æœ‰å¥½å¤„çš„ï¼Œç°åœ¨å¯ä»¥è¯•è¯•focal lossäº†ã€‚\n11.3 æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹\nä¸€æŠŠæƒ…å†µä¸‹ï¼Œnegativa default box &gt;&gt; positive default boxæ•°é‡ï¼Œç›´æ¥è®­ç»ƒä¼šå¯¼è‡´ç½‘ç»œè¿‡äºé‡è§†è´Ÿæ ·æœ¬ï¼Œä»è€Œlossä¸ç¨³å®šã€‚æ‰€ä»¥ï¼ŒSSDåœ¨è‡­æ°§æ˜¯æŒ‰ç…§ç½®ä¿¡åº¦è¯¯å·®ï¼ˆé¢„æµ‹èƒŒæ™¯çš„ç½®ä¿¡åº¦è¶Šå°ï¼Œè¯¯å·®è¶Šå¤§ï¼‰è¿›è¡Œé™åºæ’åˆ—ï¼Œé€‰å–è¯¯å·®è¾ƒå¤§çš„top-kä½œä¸ºè®­ç»ƒçš„è´Ÿæ ·æœ¬ï¼Œæ§åˆ¶positiveï¼šnegtive=1:3ã€‚ä½œè€…å‘ç°è¿™å¯å¯¼è‡´æ¨¡å‹æ›´å¿«çš„ä¼˜åŒ–å’Œæ›´ç¨³å®šçš„è®­ç»ƒã€‚\n11.4 æ ·æœ¬ä¸å‡è¡¡\næ£€æµ‹\nåˆ†ç±»\nå¤„ç†ä¸å¹³è¡¡é—®é¢˜çš„loss\nä¸å¹³è¡¡æ•°æ®é›†å¤„ç†æ–¹æ³•\n11.5 nmsæ—¶é—´å¤æ‚åº¦\nå‡å¦‚ä¸€å¼ å›¾ç‰‡ä¸­æœ‰nä¸ªæ£€æµ‹æ¡†ï¼Œç”±äºé¡ºåºå¤„ç†çš„åŸå› ï¼ŒæŸä¸€ä¸ªæ¡†ä¸å…¶ä»–æ¡†è®¡ç®—IoUï¼Œæœ€å°‘ä¸€æ¬¡ï¼Œæœ€å¤šæœ‰n-1æ¬¡ã€‚å†åŠ ä¸Šé¡ºåºè¿­ä»£æŠ‘åˆ¶ï¼ŒNMSç®—æ³•åœ¨è®¡ç®—IoUæ–¹é¢ï¼Œå…±éœ€è¦è®¡ç®—IoUè‡³å°‘n-1æ¬¡ï¼Œæœ€å¤š(n-1)+(n-2)+...+1=æ¬¡ã€‚\n11.6 å°é—®é¢˜\n11.6.1 ç›®æ ‡æ£€æµ‹æœ‰ä¸€ä¸ªç±»åˆ«apå¾ˆä½\n\nä½APæ•°æ®ç±»åˆ«å¢å¼º\nä½AP lossæƒé‡\n\n11.6.2 æ£€æµ‹å‡ºç°ä¸€åŠçš„ç‰©ä½“å¤„ç†æ–¹å¼\næœ€å¥½è¦æ ‡æ³¨é®æŒ¡çš„ç¨‹åº¦ã€‚è¿™ä¸ªä¸ä»…å¯¹è®­ç»ƒæœ‰å¸®åŠ©ï¼Œå¯ä»¥å› ä¸ºå¯ä»¥é€‰æ‹©è®­ç»ƒçš„æ ·æœ¬ã€‚ä½†æ˜¯æ›´é‡è¦çš„æ˜¯å¯¹æµ‹è¯•çš„å¸®åŠ©ã€‚å¦‚æœæœ‰äº†é®æŒ¡çš„æ ‡æ³¨ï¼Œå°±å¯ä»¥æŠŠæµ‹è¯•æ•°æ®é›†åˆ†ä¸ºä¸åŒçš„é›†åˆï¼Œæ¯”å¦‚è¯´æ— é®æŒ¡é›†åˆï¼Œä¸­åº¦é®æŒ¡é›†åˆå’Œé‡åº¦é®æŒ¡é›†åˆã€‚è¿™æ ·å¯ä»¥å¾—åˆ°æ›´åŠ ç»†è‡´å’Œç²¾ç¡®çš„æµ‹è¯•ç»“æœï¼Œæœ‰åˆ©äºé—®é¢˜çš„åˆ†æå’Œè§£å†³ã€‚\n11.6.3 å°ç›®æ ‡\nå‚è€ƒ 1. ä¼ ç»Ÿçš„å›¾åƒé‡‘å­—å¡”å’Œå¤šå°ºåº¦æ»‘åŠ¨çª—å£æ£€æµ‹ï¼Œå¦‚MTCNN 2. FPN 3. Data Augmentation\n11.6.4 å¦‚ä½•è§£å†³ç±»å†…æ£€æµ‹/é‡å \n\nRepulsion lossï¼Œå‚è§CVPR 2018è®ºæ–‡ repulsion lossï¼Œç”¨ä½œæ‹¥æŒ¤äººç¾¤æ£€æµ‹ï¼›\nSoft NMSï¼Œé™ä½confidenceè€Œä¸æ˜¯ç›´æ¥å»æ‰ï¼›\nNMSçš„æ”¹è¿› Acquisition of Localization Confidence for Accurate Object Detection\nPart basedï¼Œåˆ†è§£ç‰©ä½“ä¸ºå¤šä¸ªéƒ¨ä½çš„ç»„åˆï¼Œæ˜¯ä¸€ä¸ªæ€è·¯ï¼›å¦‚OR-CNN\nèåˆå…¶ä»–ä¿¡æ¯ï¼Œå¦‚åˆ†å‰²çš„ä¿¡æ¯ï¼Œè¯­ä¹‰ä¿¡æ¯ï¼›\n\n11.6.5 æ£€æµ‹çš„æ¡†åç§»45åº¦ï¼Œæ€ä¹ˆå¤„ç†\nå‚è€ƒ\n11.7 soft-nms\nå‡ºå¤„\nNMSç¼ºç‚¹ 1ã€NMSç®—æ³•ä¸­çš„æœ€å¤§é—®é¢˜å°±æ˜¯å®ƒå°†ç›¸é‚»æ£€æµ‹æ¡†çš„åˆ†æ•°å‡å¼ºåˆ¶å½’é›¶(å³å°†é‡å éƒ¨åˆ†å¤§äºé‡å é˜ˆå€¼Ntçš„æ£€æµ‹æ¡†ç§»é™¤)ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¦‚æœä¸€ä¸ªçœŸå®ç‰©ä½“åœ¨é‡å åŒºåŸŸå‡ºç°ï¼Œåˆ™å°†å¯¼è‡´å¯¹è¯¥ç‰©ä½“çš„æ£€æµ‹å¤±è´¥å¹¶é™ä½äº†ç®—æ³•çš„å¹³å‡æ£€æµ‹ç‡ã€‚ 2ã€NMSçš„é˜ˆå€¼ä¹Ÿä¸å¤ªå®¹æ˜“ç¡®å®šï¼Œè®¾ç½®è¿‡å°ä¼šå‡ºç°è¯¯åˆ ï¼Œè®¾ç½®è¿‡é«˜åˆå®¹æ˜“å¢å¤§è¯¯æ£€ã€‚\nNMSç®—æ³•æ˜¯ç•¥æ˜¾ç²—æš´ï¼Œå› ä¸ºNMSç›´æ¥å°†åˆ é™¤æ‰€æœ‰IoUå¤§äºé˜ˆå€¼çš„æ¡†ã€‚soft-NMSå¸å–äº†NMSçš„æ•™è®­ï¼Œåœ¨ç®—æ³•æ‰§è¡Œè¿‡ç¨‹ä¸­ä¸æ˜¯ç®€å•çš„å¯¹IoUå¤§äºé˜ˆå€¼çš„æ£€æµ‹æ¡†åˆ é™¤ï¼Œè€Œæ˜¯é™ä½å¾—åˆ†ã€‚ç®—æ³•æµç¨‹åŒNMSç›¸åŒï¼Œä½†æ˜¯å¯¹åŸç½®ä¿¡åº¦å¾—åˆ†ä½¿ç”¨å‡½æ•°è¿ç®—ï¼Œç›®æ ‡æ˜¯é™ä½ç½®ä¿¡åº¦å¾—åˆ†.\n\n\næ¥æºè§æ°´å°\n\nä¸ºå¾…å¤„ç†BBoxæ¡†ï¼ŒBä¸ºå¾…å¤„ç†BBoxæ¡†é›†åˆï¼Œæ˜¯æ¡†æ›´æ–°å¾—åˆ†ï¼Œæ˜¯NMSçš„é˜ˆå€¼ï¼ŒDé›†åˆç”¨æ¥æ”¾æœ€ç»ˆçš„BBoxï¼Œfæ˜¯ç½®ä¿¡åº¦å¾—åˆ†çš„é‡ç½®å‡½æ•°ã€‚ å’ŒMçš„IOUè¶Šå¤§ï¼Œçš„å¾—åˆ†å°±ä¸‹é™çš„è¶Šå‰å®³ã€‚\nç»å…¸çš„NMSç®—æ³•å°†IOUå¤§äºé˜ˆå€¼çš„çª—å£çš„å¾—åˆ†å…¨éƒ¨ç½®ä¸º0ï¼Œå¯è¡¨è¿°å¦‚ä¸‹ï¼š\n\nè®ºæ–‡ç½®ä¿¡åº¦é‡ç½®å‡½æ•°æœ‰ä¸¤ç§å½¢å¼æ”¹è¿›ï¼Œä¸€ç§æ˜¯çº¿æ€§åŠ æƒçš„ï¼š\n ä¸€ç§æ˜¯é«˜æ–¯åŠ æƒå½¢å¼ï¼š \nå…·ä½“ä»£ç å®ç°ï¼š if method==1: # linear\n    if ov&gt;Nt:\n        weight=1-ov\n    else:\n        weight=1\nelif method==2: # Gaussian\n    weight=p.exp(-(ov*ov)/sigma)\nelse:          # Original NMS\n    if ov&gt;Nt:\n        weight=0\n    else:\n        weight=1\nä¼˜ç‚¹ï¼š\n1ã€Soft-NMSå¯ä»¥å¾ˆæ–¹ä¾¿åœ°å¼•å…¥åˆ°object detectionç®—æ³•ä¸­ï¼Œä¸éœ€è¦é‡æ–°è®­ç»ƒåŸæœ‰çš„æ¨¡å‹ã€ä»£ç å®¹æ˜“å®ç°ï¼Œä¸å¢åŠ è®¡ç®—é‡ï¼ˆè®¡ç®—é‡ç›¸æ¯”æ•´ä¸ªobject detectionç®—æ³•å¯å¿½ç•¥ï¼‰ã€‚å¹¶ä¸”å¾ˆå®¹æ˜“é›†æˆåˆ°ç›®å‰æ‰€æœ‰ä½¿ç”¨NMSçš„ç›®æ ‡æ£€æµ‹ç®—æ³•ã€‚ 2ã€soft-NMSåœ¨è®­ç»ƒä¸­é‡‡ç”¨ä¼ ç»Ÿçš„NMSæ–¹æ³•ï¼Œä»…åœ¨æ¨æ–­ä»£ç ä¸­å®ç°soft-NMSã€‚ä½œè€…åº”è¯¥åšè¿‡å¯¹æ¯”è¯•éªŒï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é‡‡ç”¨soft-NMSæ²¡æœ‰æ˜¾è‘—æé«˜ã€‚ 3ã€NMSæ˜¯Soft-NMSç‰¹æ®Šå½¢å¼ï¼Œå½“å¾—åˆ†é‡ç½®å‡½æ•°é‡‡ç”¨äºŒå€¼åŒ–å‡½æ•°æ—¶ï¼ŒSoft-NMSå’ŒNMSæ˜¯ç›¸åŒçš„ã€‚soft-NMSç®—æ³•æ˜¯ä¸€ç§æ›´åŠ é€šç”¨çš„éæœ€å¤§æŠ‘åˆ¶ç®—æ³•ã€‚\nç¼ºç‚¹ï¼š soft-NMSä¹Ÿæ˜¯ä¸€ç§è´ªå¿ƒç®—æ³•ï¼Œå¹¶ä¸èƒ½ä¿è¯æ‰¾åˆ°å…¨å±€æœ€ä¼˜çš„æ£€æµ‹æ¡†åˆ†æ•°é‡ç½®ã€‚é™¤äº†ä»¥ä¸Šè¿™ä¸¤ç§åˆ†æ•°é‡ç½®å‡½æ•°ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è€ƒè™‘å¼€å‘å…¶ä»–åŒ…å«æ›´å¤šå‚æ•°çš„åˆ†æ•°é‡ç½®å‡½æ•°ï¼Œæ¯”å¦‚Gompertzå‡½æ•°ç­‰ã€‚ä½†æ˜¯å®ƒä»¬åœ¨å®Œæˆåˆ†æ•°é‡ç½®çš„è¿‡ç¨‹ä¸­å¢åŠ äº†é¢å¤–çš„å‚æ•°ã€‚\nsofter-nms\n11.8 å‡ ç§iou\nè§\n11.9 å°æ’ä»¶\n\nSPP\n\n\n\n\n\n\n\n\n\n\nSPPçš„æœ¬è´¨å°±æ˜¯å¤šå±‚maxpool\n\nSPPä¼˜ç‚¹:\nï¼ˆ1ï¼‰å¯¹äºä¸åŒå°ºå¯¸çš„CNN_Preè¾“å‡ºèƒ½å¤Ÿè¾“å‡ºå›ºå®šå¤§å°çš„å‘é‡ã€‚ ï¼ˆ2ï¼‰å¯ä»¥æå–ä¸åŒå°ºå¯¸çš„ç©ºé—´ç‰¹å¾ä¿¡æ¯ï¼Œå¯ä»¥æå‡æ¨¡å‹å¯¹äºç©ºé—´å¸ƒå±€å’Œç‰©ä½“å˜æ€§çš„é²æ£’æ€§ã€‚ ï¼ˆ3ï¼‰å¯ä»¥é¿å…å°†å›¾ç‰‡resizeã€cropæˆå›ºå®šå¤§å°è¾“å…¥æ¨¡å‹çš„å¼Šç«¯ã€‚\n\nFPN\n\n1. ä¸åŒæ·±åº¦çš„ feature map ä¸ºä»€ä¹ˆå¯ä»¥ç»è¿‡ upsample åç›´æ¥ç›¸åŠ ï¼Ÿ\nAï¼šä½œè€…è§£é‡Šè¯´è¿™ä¸ªåŸå› åœ¨äºæˆ‘ä»¬åšäº† end-to-end çš„ trainingï¼Œå› ä¸ºä¸åŒå±‚çš„å‚æ•°ä¸æ˜¯å›ºå®šçš„ï¼Œä¸åŒå±‚åŒæ—¶ç»™ç›‘ç£åš end-to-end trainingï¼Œæ‰€ä»¥ç›¸åŠ è®­ç»ƒå‡ºæ¥çš„ä¸œè¥¿èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°èåˆæµ…å±‚å’Œæ·±å±‚çš„ä¿¡æ¯ã€‚ #### 2. ä¸ºä»€ä¹ˆ FPN ç›¸æ¯”å»æ‰æ·±å±‚ç‰¹å¾ upsample(bottom-up pyramid) å¯¹äºå°ç‰©ä½“æ£€æµ‹æå‡æ˜æ˜¾ï¼Ÿï¼ˆRPN æ­¥éª¤ AR ä» 30.5 åˆ° 44.9ï¼ŒFast RCNN æ­¥éª¤ AP ä» 24.9 åˆ° 33.9ï¼‰ Aï¼šå¯¹äºå°ç‰©ä½“ï¼Œä¸€æ–¹é¢å®ƒæé«˜äº†å°ç›®æ ‡çš„åˆ†è¾¨ç‡ä¿¡æ¯ï¼› å¦ä¸€æ–¹é¢ï¼Œå¦‚å›¾ä¸­çš„æŒåŒ…ä¸€æ ·ï¼Œä»ä¸Šåˆ°ä¸‹ä¼ é€’è¿‡æ¥çš„æ›´å…¨å±€çš„æƒ…æ™¯ä¿¡æ¯å¯ä»¥æ›´å‡†ç¡®åˆ¤æ–­æŒåŒ…çš„å­˜åœ¨åŠä½ç½®ã€‚ \n\nPAN\n\n\nFPNåŠ å…¥top-downçš„æ—è·¯è¿æ¥ï¼Œèƒ½ç»™featureå¢åŠ high-levelè¯­ä¹‰,æœ‰åˆ©äºåˆ†ç±»ã€‚ä½†æ˜¯PANè®ºæ–‡ä½œè€…è§‰å¾—low-levelçš„featureå¾ˆæœ‰åˆ©äºå®šä½ï¼Œè™½ç„¶FPNä¸­P5ä¹Ÿé—´æ¥èåˆäº†low-levelçš„ç‰¹å¾ï¼Œä½†æ˜¯ä¿¡æ¯æµåŠ¨è·¯çº¿å¤ªé•¿äº†å¦‚çº¢è‰²è™šçº¿æ‰€ç¤ºï¼Œå…¶ä¸­ä¼šç»è¿‡è¶…å¤šconvæ“ä½œï¼Œæœ¬æ–‡åœ¨FPNçš„P2-P5åˆåŠ äº†low-levelçš„ç‰¹å¾ï¼Œæœ€åº•å±‚çš„ç‰¹å¾æµåŠ¨åˆ°N2-N5åªéœ€è¦ç»è¿‡å¾ˆå°‘çš„å±‚å¦‚ç»¿è‰²éœ€è¦æ‰€ç¤ºï¼Œä¸»è¦ç›®çš„æ˜¯åŠ é€Ÿä¿¡æ¯èåˆ,ç¼©çŸ­åº•å±‚ç‰¹å¾å’Œé«˜å±‚ç‰¹å¾ä¹‹é—´çš„ä¿¡æ¯è·¯å¾„.\n11.10 ç»å…¸ç®—æ³•\nFaster RCNN maskrcnnï¼Œ cascade rcnn\nFaster RCNN\nanchor boxä¸bbox æ­£è´Ÿæ ·æœ¬é€‰å–çš„é—®é¢˜\nMask RCNN\nå‚è€ƒ1 å‚è€ƒ2\ncascade rcnn\nå‚è€ƒ1 å‚è€ƒ2\nyoloç³»åˆ—\nfcos\ncenter net\nmismatché—®é¢˜\n\n\næ¥æºè§æ°´å°\n\nä¸€å¼ å›¾è¯´æ˜é—®é¢˜ï¼Œåœ¨ä¸Šé¢è¿™å¼ å›¾ä¸­ï¼ŒæŠŠRPNæå‡ºçš„Proposalsçš„å¤§è‡´åˆ†å¸ƒç”»äº†ä¸‹ï¼Œæ¨ªè½´è¡¨ç¤ºProposalså’Œgtä¹‹é—´çš„iouå€¼ï¼Œçºµè½´è¡¨ç¤ºæ»¡è¶³å½“å‰iouå€¼çš„Proposalsæ•°é‡ã€‚\n\nåœ¨trainingé˜¶æ®µï¼Œç”±äºæˆ‘ä»¬çŸ¥é“gtï¼Œæ‰€ä»¥å¯ä»¥å¾ˆè‡ªç„¶çš„æŠŠä¸gtçš„iouå¤§äºthresholdï¼ˆ0.5ï¼‰çš„Proposalsä½œä¸ºæ­£æ ·æœ¬ï¼Œè¿™äº›æ­£æ ·æœ¬å‚ä¸ä¹‹åçš„bboxå›å½’å­¦ä¹ ã€‚\nåœ¨inferenceé˜¶æ®µï¼Œç”±äºæˆ‘ä»¬ä¸çŸ¥é“gtï¼Œæ‰€ä»¥åªèƒ½æŠŠæ‰€æœ‰çš„proposaléƒ½å½“åšæ­£æ ·æœ¬ï¼Œè®©åé¢çš„bboxå›å½’å™¨å›å½’åæ ‡ã€‚\n\næˆ‘ä»¬å¯ä»¥æ˜æ˜¾çš„çœ‹åˆ°trainingé˜¶æ®µå’Œinferenceé˜¶æ®µï¼Œbboxå›å½’å™¨çš„è¾“å…¥åˆ†å¸ƒæ˜¯ä¸ä¸€æ ·çš„ï¼Œtrainingé˜¶æ®µçš„è¾“å…¥proposalsè´¨é‡æ›´é«˜(è¢«é‡‡æ ·è¿‡ï¼ŒIoU&gt;threshold)ï¼Œinferenceé˜¶æ®µçš„è¾“å…¥proposalsè´¨é‡ç›¸å¯¹è¾ƒå·®(æ²¡æœ‰è¢«é‡‡æ ·è¿‡ï¼Œå¯èƒ½åŒ…æ‹¬å¾ˆå¤šIoU &lt; thresholdçš„)ï¼Œè¿™å°±æ˜¯è®ºæ–‡ä¸­æåˆ°mismatché—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜æ˜¯å›ºæœ‰å­˜åœ¨çš„ï¼Œé€šå¸¸thresholdå–0.5æ—¶ï¼Œmismatché—®é¢˜è¿˜ä¸ä¼šå¾ˆä¸¥é‡ã€‚\n12. å…¶ä»–\n12.1 æ³¨æ„åŠ›æœºåˆ¶\næ¥æº github\nSE,SK,CBAM\nattentionæ€ä¹ˆåšï¼Œself-attentionæ€ä¹ˆåšï¼ŒåŸç†æ˜¯ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Œmulti attentionï¼ˆå¤šå¤´ï¼‰ï¼Œattentioné‡Œé¢çš„QKVæ˜¯å•¥\nå›¾è§£Self-Attention\nè®¡ç®— attention çš„è¿‡ç¨‹ï¼Œå³ä½¿ç”¨ ä¸€ä¸ª Q(uery)ï¼Œè®¡ç®—å®ƒå’Œæ¯ä¸ªK(ey)çš„ç›¸ä¼¼åº¦ä½œä¸ºæƒé‡,å¯¹æ‰€æœ‰çš„ V(alue)è¿›è¡ŒåŠ æƒæ±‚å’Œã€‚\nencoder-decoderä¸­ï¼Œå¦‚æœdecoderåŸºäºattentionåº”è¯¥æ€ä¹ˆåš\nPCA\nå‚è€ƒ\n","slug":"CVé¢è¯•åŸºç¡€æ€»ç»“","date":"2021-10-12T07:57:22.000Z","categories_index":"","tags_index":"interview summary","author_index":"Hulk Wang"},{"id":"06a101cf6ba6fad0463c3458164de1c3","title":"Faster RCNN è®°å½•","content":"\n\n\n\n\n\n\n\n\nå‚è€ƒæ¥æºï¼š https://zhuanlan.zhihu.com/p/31426458 https://zhuanlan.zhihu.com/p/86403390\n\n\nFaster RCNNåŸºæœ¬ç»“æ„\n\nFaster RCNNå…¶å®å¯ä»¥åˆ†ä¸º4ä¸ªä¸»è¦å†…å®¹ï¼š\n\nç‰¹å¾æå–ï¼šFaster RCNNé¦–å…ˆä½¿ç”¨ä¸€ç»„åŸºç¡€çš„conv+relu+poolingå±‚æå–imageçš„feature mapsã€‚è¯¥feature mapsè¢«å…±äº«ç”¨äºåç»­RPNå±‚å’Œå…¨è¿æ¥å±‚ã€‚\nRPNï¼šRPNç½‘ç»œç”¨äºç”Ÿæˆregion proposalsã€‚è¯¥å±‚é€šè¿‡softmaxåˆ¤æ–­anchorså±äºpositiveæˆ–è€…negativeï¼Œå†åˆ©ç”¨bounding box regressionä¿®æ­£anchorsè·å¾—ç²¾ç¡®çš„proposalsã€‚\nRoi Poolingï¼šè¯¥å±‚æ”¶é›†è¾“å…¥çš„feature mapså’Œproposalsï¼Œç»¼åˆè¿™äº›ä¿¡æ¯åæå–proposal feature mapsï¼Œé€å…¥åç»­å…¨è¿æ¥å±‚åˆ¤å®šç›®æ ‡ç±»åˆ«ã€‚\nClassificationï¼šåˆ©ç”¨proposal feature mapsè®¡ç®—proposalçš„ç±»åˆ«ï¼ŒåŒæ—¶å†æ¬¡bounding box regressionè·å¾—æ£€æµ‹æ¡†æœ€ç»ˆçš„ç²¾ç¡®ä½ç½®ã€‚\n\n\n\nFaster RCNN(VGG16)ç½‘ç»œç»“æ„\n\nç‰¹å¾æå–\næ²¡å•¥å¯è¯´çš„ï¼Œç‰¹å¾æå–ï¼Œè¾“å…¥MxNï¼ŒVGG16ä¸ºä¾‹ï¼Œ4ä¸ªpoolingå±‚ï¼Œå¾—åˆ°çš„feature mapåˆ†è¾¨ç‡ä¸ºï¼šï¼ˆM/16ï¼‰xï¼ˆN/16ï¼‰\nRPN\n\n\nRPNç»“æ„\n\nRPNç½‘ç»œå®é™…åˆ†ä¸º2æ¡çº¿ï¼Œä¸Šé¢ä¸€æ¡é€šè¿‡softmaxåˆ†ç±»anchorsè·å¾—positiveå’Œnegativeåˆ†ç±»ï¼Œä¸‹é¢ä¸€æ¡ç”¨äºè®¡ç®—å¯¹äºanchorsçš„bounding box regressionåç§»é‡ï¼Œä»¥è·å¾—ç²¾ç¡®çš„proposalã€‚è€Œæœ€åçš„Proposalå±‚åˆ™è´Ÿè´£ç»¼åˆpositive anchorså’Œå¯¹åº”bounding box regressionåç§»é‡è·å–proposalsï¼ŒåŒæ—¶å‰”é™¤å¤ªå°å’Œè¶…å‡ºè¾¹ç•Œçš„proposalsã€‚å…¶å®æ•´ä¸ªç½‘ç»œåˆ°äº†Proposal Layerè¿™é‡Œï¼Œå°±å®Œæˆäº†ç›¸å½“äºç›®æ ‡å®šä½çš„åŠŸèƒ½ã€‚\nanchors\nä»¥tfä»£ç ä¸ºä¾‹ï¼š def _anchor_component(self):  #è·å¾—é”šçš„æ•°é‡å’Œä½ç½®\n    with tf.variable_scope('ANCHOR_' + 'default'):\n        # just to get the shape right  åªæ˜¯ä¸ºäº†è®©å½¢çŠ¶æ­£ç¡®\n        height = tf.to_int32(tf.ceil(self._im_info[0, 0] / np.float32(self._feat_stride[0]))) #é«˜åº¦ä¸ºå›¾ç‰‡é«˜/16,ï¼Œå°±æ˜¯ç‰¹å¾å›¾çš„é«˜ï¼Œtf.ceilå‘ä¸Šå–æ•´\n        width = tf.to_int32(tf.ceil(self._im_info[0, 1] / np.float32(self._feat_stride[0]))) #å®½åº¦ä¸ºå›¾ç‰‡å®½/16ï¼Œä¸ºç‰¹å¾å›¾çš„å®½\n        anchors, anchor_length = tf.py_func(generate_anchors_pre,\n                                            [height, width,                                        self._feat_stride,self._anchor_scales, self._anchor_ratios],\n                                            [tf.float32, tf.int32], name=\"generate_anchors\")  #æ„å»ºç”Ÿæˆé”šçš„pyå‡½æ•°ï¼Œè¿™ä¸ªé”šæœ‰9*ï¼ˆ50*38ï¼‰ä¸ªï¼Œanchor_lengthæ˜¯é”šçš„ä¸ªæ•°\n        anchors.set_shape([None, 4])  #é”šå®šä¹‰ä¸º4åˆ—\n        anchor_length.set_shape([]) #è¡Œå‘é‡ï¼Œlengthä¸ºé”šçš„ä¸ªæ•°\n        self._anchors = anchors\n        self._anchor_length = anchor_length  #lengthä¸ºç‰¹å¾å›¾é¢ç§¯*9 å‡½æ•°generate_anchors_preæ¥ç”Ÿæˆanchorï¼š\ndef generate_anchors_pre(height, width, feat_stride, anchor_scales=(8, 16, 32), anchor_ratios=(0.5, 1, 2)):\n    \"\"\" A wrapper function to generate anchors given different scales\n      Also return the number of anchors in variable 'length' ç»™å®šä¸åŒæ¯”ä¾‹ç”Ÿæˆé”šç‚¹çš„åŒ…è£…å‡½æ•°ä¹Ÿè¿”å›å¯å˜â€œé•¿åº¦â€çš„é”šç‚¹æ•°é‡\n    \"\"\"\n    anchors = generate_anchors(ratios=np.array(anchor_ratios), scales=np.array(anchor_scales))\n    A = anchors.shape[0] #anchorçš„æ•°é‡ï¼Œä¸º9\n    shift_x = np.arange(0, width) * feat_stride  #å°†ç‰¹å¾å›¾çš„å®½åº¦è¿›è¡Œ16å€å»¶ä¼¸è‡³åŸå›¾ï¼Œä»¥width=4ä¸ºä¾‹å­ï¼Œåˆ™shfit_x=[0,16,32,48]\n    shift_y = np.arange(0, height) * feat_stride  #å°†ç‰¹å¾å›¾çš„é«˜åº¦è¿›è¡Œ16å€è¡ç”Ÿè‡³åŸå›¾\n    shift_x, shift_y = np.meshgrid(shift_x, shift_y)  #ç”ŸæˆåŸå›¾çš„ç½‘æ ¼ç‚¹\n    shifts = np.vstack((shift_x.ravel(), shift_y.ravel(), shift_x.ravel(), shift_y.ravel())).transpose()  #è‹¥width=50ï¼Œheight=38ï¼Œç”Ÿæˆï¼ˆ50*38ï¼‰*4çš„æ•°ç»„\n    #å¦‚ [[0,0,0,0],[16,0,16,0],[32,0,32,0].......]ï¼Œshiftä¸­çš„å‰ä¸¤ä¸ªåæ ‡å’Œåä¸¤ä¸ªä¸€æ ·ï¼ˆä¿æŒå³ä¸‹å’Œå·¦ä¸Šçš„åæ ‡ä¸€æ ·ï¼‰ï¼Œæ˜¯ä»å·¦åˆ°å³ï¼Œä»ä¸Šåˆ°ä¸‹çš„åæ ‡ç‚¹ï¼ˆæ˜ å°„åˆ°åŸå›¾ï¼‰\n    K = shifts.shape[0]  #k=50*38\n    # width changes faster, so here it is H, W, C\n    anchors = anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2))  #åˆ—æ•°ç›¸åŒçš„listç›¸åŠ å°±æ˜¯ç®€å•çš„æ·»åŠ ï¼Œè€Œæ•°ç»„ä¸ä¸€æ ·ï¼Œ1*9*4å’Œï¼ˆ50*38ï¼‰*1*4è¿›è¡Œç›¸åŠ ï¼Œç”Ÿæˆäº†ï¼ˆ50*38ï¼‰*9*4çš„æ•°ç»„\n    #å…¶å®æ„æ€å°±æ˜¯å³ä¸‹è§’åæ ‡å’Œå·¦ä¸Šè§’çš„å·¦è¾¹éƒ½åŠ ä¸ŠåŒä¸€ä¸ªå˜æ¢åæ ‡\n    anchors = anchors.reshape((K * A, 4)).astype(np.float32, copy=False) #ä¸‰ç»´å˜ä¸¤ç»´ï¼Œï¼ˆ50*38*9ï¼Œ4ï¼‰ï¼Œæ­¤å¤„å°±æ˜¯å°†ç‰¹å¾å±‚çš„anchoråæ ‡è½¬åˆ°åŸå›¾ä¸Šçš„åŒºåŸŸ\n    length = np.int32(anchors.shape[0])  #length=50*38*9\n\n    return anchors, length\nè§‚å¯Ÿç¬¬ä¸€è¡Œä»£ç ï¼Œå³ anchors = generate_anchors(ratios=np.array(anchor_ratios),scales=np.array(anchor_scales)) è¿™é‡Œæ˜¯3x3=9ä¸ªåŸºç¡€anchorçš„ç”Ÿæˆï¼Œæˆ‘ä»¬è¿›å…¥å‡½æ•°generate_anchorsä¸­ï¼Œå‘ç°å…¶å®ç”Ÿæˆå°±æ˜¯ä¸€ä¸ªæ•°ç»„ï¼Œè¿™ä¸ªæ•°ç»„æ˜¯ï¼š # array([[ -83.,  -39.,  100.,   56.],\n#       [-175.,  -87.,  192.,  104.],\n#       [-359., -183.,  376.,  200.],\n#       [ -55.,  -55.,   72.,   72.],\n#       [-119., -119.,  136.,  136.],\n#       [-247., -247.,  264.,  264.],\n#       [ -35.,  -79.,   52.,   96.],\n#       [ -79., -167.,   96.,  184.],\n#       [-167., -343.,  184.,  360.]]) å…¶ä¸­æ¯è¡Œçš„4ä¸ªå€¼ï¼ˆx1ï¼Œy1, x2, y2ï¼‰è¡¨çŸ©å½¢å·¦ä¸Šå’Œå³ä¸‹è§’ç‚¹åæ ‡ã€‚9ä¸ªçŸ©å½¢å…±æœ‰3ç§å½¢çŠ¶ï¼Œé•¿å®½æ¯”ä¸ºå¤§çº¦ä¸º{1:1, 1:2, 2:1}ä¸‰ç§ï¼Œå®é™…ä¸Šé€šè¿‡anchorså°±å¼•å…¥äº†æ£€æµ‹ä¸­å¸¸ç”¨åˆ°çš„å¤šå°ºåº¦æ–¹æ³•ã€‚\nç”Ÿæˆè¿™ä¸ªæ•°ç»„çš„ä»£ç æ˜¯ï¼š def generate_anchors(base_size=16, ratios=[0.5, 1, 2],\n                     scales=2 ** np.arange(3, 6)):\n    \"\"\"\n    Generate anchor (reference) windows by enumerating aspect ratios X\n    scales wrt a reference (0, 0, 15, 15) window.  é€šè¿‡æšä¸¾å‚è€ƒ(0ï¼Œ0ï¼Œ15ï¼Œ15)çª—å£çš„é•¿å®½æ¯”æ¥ç”Ÿæˆé”š(å‚è€ƒ)çª—å£ã€‚\n    \"\"\"\n\n    base_anchor = np.array([1, 1, base_size, base_size]) - 1  #ç”Ÿæˆä¸€ä¸ªbase_anchor = [0, 0, 15, 15]ï¼Œå…¶ä¸­(0, 0)æ˜¯anchorå·¦ä¸Šç‚¹çš„åæ ‡\n    # (15, 15)æ˜¯anchorå³ä¸‹ç‚¹çš„åæ ‡ï¼Œé‚£ä¹ˆè¿™ä¸ªanchorçš„ä¸­å¿ƒç‚¹çš„åæ ‡æ˜¯(7.5, 7.5)\n    ratio_anchors = _ratio_enum(base_anchor, ratios)#ç„¶åäº§ç”Ÿratio_anchorsï¼Œå°±æ˜¯å°†base_anchorå’Œratios[0.5, 1, 2],ratio_anchorsç”Ÿæˆä¸‰ä¸ªanchors\n    # ä¼ å…¥åˆ°_ratio_enum()å‡½æ•°ï¼Œratiosä»£è¡¨çš„æ˜¯ä¸‰ç§å®½é«˜æ¯”ã€‚\n    anchors = np.vstack([_scale_enum(ratio_anchors[i, :], scales)  #åœ¨åˆšåˆš3ä¸ªanchoråŸºç¡€ä¸Šç»§ç»­ç”Ÿæˆanchor\n                         for i in range(ratio_anchors.shape[0])])\n    return anchors æˆ‘ä»¬å‘ç°è¿™ä¸ªæ•°ç»„ä¸­çš„æ¯è¡Œæ•°æ®ï¼ˆå¦‚ç¬¬ä¸€è¡Œï¼š[ -83., -39., 100., 56.] )ï¼Œå®ƒä»¬çš„ä¸­å¿ƒä½ç½®éƒ½ä¸ºï¼ˆ7.5ï¼Œ7.5ï¼‰ï¼Œå³ï¼ˆ0ï¼Œ0ï¼Œ15ï¼Œ15ï¼‰çš„ä¸­å¿ƒï¼ˆå› ä¸ºé€šè¿‡ä»£ç ä¹Ÿå¯ä»¥å¾—çŸ¥ï¼Œè¿™9ä¸ªåŸºç¡€æ¡†çš„ç”Ÿæˆä¹Ÿæ˜¯ä»¥ï¼ˆ0ï¼Œ0ï¼Œ15ï¼Œ15ï¼‰ä¸ºåŸºç¡€çš„ï¼Œä»£ç ä¸­base_anchorå°±æ˜¯ï¼ˆ0ï¼Œ0ï¼Œ15ï¼Œ15ï¼‰ï¼‰ã€‚\né€šè¿‡3ç§anchor ratioå’Œ3ç§anchor scaleç”Ÿæˆçš„9ä¸ªæ•°ç»„ï¼Œè¿™9ä¸ªæ•°ç»„åœ¨åæ ‡å›¾ä¸Šå¦‚å›¾2æ‰€ç¤ºã€‚ \n\nanchor\n\n\n\n\n\n\n\n\n\n\nä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡å‘¢ï¼Ÿæˆ‘ä»¬çŸ¥é“ï¼Œå…¶å®ä¸€å¼ å›¾ç‰‡é€šè¿‡ç‰¹å¾æå–ç½‘è·¯VGG16åï¼Œé•¿å®½æ¯”éƒ½ç¼©å°äº†16å€å¾—åˆ°äº†ç‰¹å¾å›¾ã€‚æ¯”å¦‚åŸå…ˆçš„800*600çš„åŸå›¾é€šè¿‡VGG16åå¾—åˆ°äº†50*38çš„ç‰¹å¾å›¾ï¼ˆä»¥ä¸Šå…ˆä¸è€ƒè™‘é€šé“æ•°ï¼‰ï¼Œæˆ‘ä»¬å°±å‡è®¾ï¼Œç‰¹å¾å›¾ä¸Šçš„æ¯ä¸€ä¸ªç‚¹ï¼ˆå¤§å°ä¸º1*1ï¼‰ï¼Œå’ŒåŸå›¾16*16åŒºåŸŸå¯¹åº”ï¼ˆè¿™é‡Œè®°ä½ï¼Œå¯¹åº”ä¸æ˜¯æŒ‡ä»£æ„Ÿå—é‡ï¼Œåªæ˜¯ä¾¿äºç†è§£).è¿™é‡Œï¼Œä½¿ç”¨å¯¹åº”çš„å¥½å¤„ï¼Œå°±æ˜¯ç‰¹å¾å›¾ä¸Šçš„æ¯ä¸ªç‚¹ï¼ˆå¤§å°ä¸º1*1ï¼‰è´Ÿè´£ç”±åŸå›¾å¯¹åº”åŒºåŸŸ(å¤§å°ä¸º16*16ï¼‰ä¸­å¿ƒç”Ÿæˆçš„9ä¸ªanchorçš„è®­ç»ƒå’Œå­¦ä¹ ã€‚æ‰€ä»¥Faster RCNNå…±äº§ç”Ÿ50x38x9=17100ä¸ªanchorï¼ŒåŸºæœ¬è¦†ç›–äº†å…¨å›¾å„ä¸ªåŒºåŸŸã€‚\nçœ‹generate_anchors_preå‡½æ•°ï¼Œshiftså°±æ˜¯å¯¹ï¼ˆshift_x, shift_yï¼‰è¿›è¡Œç»„åˆï¼Œå…¶ä¸­shift_xæ˜¯å¯¹xåæ ‡è¿›è¡Œç§»åŠ¨ï¼Œshift_yæ˜¯å¯¹yåæ ‡è¿›è¡Œç§»åŠ¨ï¼Œç»¼åˆèµ·æ¥å°±æ˜¯å°†åŸºç¡€çš„ä¸­å¿ƒä¸ºï¼ˆ7.5ï¼Œ7.5ï¼‰çš„9ä¸ªanchorå¹³ç§»åˆ°å…¨å›¾ä¸Šï¼Œè¦†ç›–æ‰€æœ‰å¯èƒ½çš„åŒºåŸŸã€‚ anchors = anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2)) #åˆ—æ•°ç›¸åŒçš„listç›¸åŠ å°±æ˜¯ç®€å•çš„æ·»åŠ ï¼Œè€Œæ•°ç»„ä¸ä¸€æ ·ï¼Œ1*9*4å’Œï¼ˆ50*38ï¼‰*1*4è¿›è¡Œç›¸åŠ ï¼Œç”Ÿæˆäº†ï¼ˆ50*38ï¼‰*9*4çš„æ•°ç»„\n#å…¶å®æ„æ€å°±æ˜¯å³ä¸‹è§’åæ ‡å’Œå·¦ä¸Šè§’çš„å·¦è¾¹éƒ½åŠ ä¸ŠåŒä¸€ä¸ªå˜æ¢åæ ‡\nanchors = anchors.reshape((K * A, 4)).astype(np.float32, copy=False) #ä¸‰ç»´å˜ä¸¤ç»´ï¼Œï¼ˆ50*38*9ï¼Œ4ï¼‰ï¼Œæ­¤å¤„å°±æ˜¯å°†ç‰¹å¾å±‚çš„anchoråæ ‡è½¬åˆ°åŸå›¾ä¸Šçš„åŒºåŸŸ\nlength = np.int32(anchors.shape[0]) #length=50*38*9 ä¸Šè¿°ä»£ç å°±æ˜¯å®Œæˆäº†9ä¸ªbase anchor çš„ç§»åŠ¨ï¼Œè¾“å‡ºç»“æœå°±æ˜¯50*38*9ä¸ªanchorã€‚é‚£ä¹ˆåˆ°æ­¤ï¼Œæ‰€æœ‰çš„anchoréƒ½ç”Ÿæˆäº†ï¼Œå½“ç„¶äº†ï¼Œæ‰€æœ‰çš„anchorä¹Ÿå’Œç‰¹å¾å›¾äº§ç”Ÿäº†ä¸€ä¸€å¯¹åº”çš„å…³ç³»äº†ã€‚\n\n\n\n\n\n\n\n\n\nanchoræ˜¯è¾…åŠ©æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ï¼Œèƒ½è®©æ¨¡å‹å¯¹ç‰©ä½“çš„å¤§å°å’Œå½¢çŠ¶æœ‰ä¸ªå¤§è‡´çš„è®¤çŸ¥ï¼Œä¹Ÿç®—æ˜¯äººä¸ºæ·»åŠ çš„å…ˆéªŒçŸ¥è¯†äº†ã€‚\nRPNæœ€ç»ˆå°±æ˜¯åœ¨åŸå›¾å°ºåº¦ä¸Šï¼Œè®¾ç½®äº†å¯†å¯†éº»éº»çš„å€™é€‰Anchorã€‚ç„¶åç”¨cnnå»åˆ¤æ–­å“ªäº›Anchoræ˜¯é‡Œé¢æœ‰ç›®æ ‡çš„positive anchorï¼Œå“ªäº›æ˜¯æ²¡ç›®æ ‡çš„negative anchorã€‚æ‰€ä»¥ï¼Œä»…ä»…æ˜¯ä¸ªäºŒåˆ†ç±»è€Œå·²ï¼\n\nè§£é‡Šä¸€ä¸‹ä¸Šé¢è¿™å¼ å›¾çš„æ•°å­—ã€‚\n\nåœ¨åŸæ–‡ä¸­ä½¿ç”¨çš„æ˜¯ZF modelä¸­ï¼Œå…¶Conv Layersä¸­æœ€åçš„conv5å±‚num_output=256ï¼Œå¯¹åº”ç”Ÿæˆ256å¼ ç‰¹å¾å›¾ï¼Œæ‰€ä»¥ç›¸å½“äºfeature mapæ¯ä¸ªç‚¹éƒ½æ˜¯256-dimensions\nåœ¨conv5ä¹‹åï¼Œåšäº†rpn_conv/3x3å·ç§¯ä¸”num_output=256ï¼Œç›¸å½“äºæ¯ä¸ªç‚¹åˆèåˆäº†å‘¨å›´3x3çš„ç©ºé—´ä¿¡æ¯\nå‡è®¾åœ¨conv5 feature mapä¸­æ¯ä¸ªç‚¹ä¸Šæœ‰kä¸ªanchorï¼ˆé»˜è®¤k=9ï¼‰ï¼Œè€Œæ¯ä¸ªanhcorè¦åˆ†positiveå’Œnegativeï¼Œæ‰€ä»¥æ¯ä¸ªç‚¹ç”±256d featureè½¬åŒ–ä¸ºcls=2â€¢k scoresï¼›è€Œæ¯ä¸ªanchoréƒ½æœ‰(x, y, w, h)å¯¹åº”4ä¸ªåç§»é‡ï¼Œæ‰€ä»¥reg=4â€¢k coordinates\nå…¨éƒ¨anchorsæ‹¿å»è®­ç»ƒå¤ªå¤šäº†ï¼Œè®­ç»ƒç¨‹åºä¼šåœ¨åˆé€‚çš„anchorsä¸­éšæœºé€‰å–128ä¸ªpostive anchors+128ä¸ªnegative anchorsè¿›è¡Œè®­ç»ƒ\n\nrpnä¸­çš„äºŒåˆ†ç±»\nä¸€å‰¯MxNå¤§å°çš„çŸ©é˜µé€å…¥Faster RCNNç½‘ç»œåï¼Œåˆ°RPNç½‘ç»œå˜ä¸º(M/16)x(N/16)ï¼Œä¸å¦¨è®¾ W=M/16ï¼ŒH=N/16ã€‚åœ¨è¿›å…¥reshapeä¸softmaxä¹‹å‰ï¼Œå…ˆåšäº†1x1å·ç§¯ï¼ˆæ­¤æ—¶anchorå·²ç»ç”Ÿæˆå®Œæ¯•ï¼‰ï¼Œå¦‚å›¾9ï¼š\n\nå¯ä»¥çœ‹åˆ°å…¶num_output=18ï¼Œä¹Ÿå°±æ˜¯ç»è¿‡è¯¥å·ç§¯çš„è¾“å‡ºå›¾åƒä¸ºWxHx18å¤§å°,è¿™ä¹Ÿå°±åˆšå¥½å¯¹åº”äº†feature mapsæ¯ä¸€ä¸ªç‚¹éƒ½æœ‰9ä¸ªanchorsï¼ŒåŒæ—¶æ¯ä¸ªanchorsåˆæœ‰å¯èƒ½æ˜¯positiveå’Œnegativeï¼Œæ‰€æœ‰è¿™äº›ä¿¡æ¯éƒ½ä¿å­˜WxHx(9*2)å¤§å°çš„çŸ©é˜µã€‚\n\n\n\n\n\n\n\n\n\nç»¼ä¸Šæ‰€è¿°ï¼ŒRPNç½‘ç»œä¸­åˆ©ç”¨anchorså’Œsoftmaxåˆæ­¥æå–å‡ºpositive anchorsä½œä¸ºå€™é€‰åŒºåŸŸï¼ˆå¦å¤–ä¹Ÿæœ‰å®ç°ç”¨sigmoidä»£æ›¿softmaxï¼Œè¾“å‡º[1, 1, 9xH, W]åæ¥sigmoidè¿›è¡Œpositive/negativeäºŒåˆ†ç±»ï¼ŒåŸç†ä¸€æ ·ï¼‰ã€‚\nbounding box regression\n\n\n\n\n\n\n\n\n\nåœ¨RPNç½‘ç»œä¸­ï¼Œè¿›è¡Œbbox regressionå¾—åˆ°çš„æ˜¯æ¯ä¸ªanchorçš„åç§»é‡ã€‚å†ä¸anchorçš„åæ ‡è¿›è¡Œè°ƒæ•´ä»¥åï¼Œå¾—åˆ°proposalçš„åæ ‡ï¼Œç»è¿‡ä¸€ç³»åˆ—åå¤„ç†ï¼Œæ¯”å¦‚NMSï¼Œtop-Kæ“ä½œä»¥åï¼Œå¾—åˆ°å¾—åˆ†æœ€é«˜çš„å‰Nä¸ªproposalä¼ å…¥åˆ†ç±»ç½‘ç»œã€‚\nå¦‚å›¾æ‰€ç¤ºç»¿è‰²æ¡†ä¸ºé£æœºçš„Ground Truth(GT)ï¼Œçº¢è‰²ä¸ºæå–çš„positive anchorsï¼Œå³ä¾¿çº¢è‰²çš„æ¡†è¢«åˆ†ç±»å™¨è¯†åˆ«ä¸ºé£æœºï¼Œä½†æ˜¯ç”±äºçº¢è‰²çš„æ¡†å®šä½ä¸å‡†ï¼Œè¿™å¼ å›¾ç›¸å½“äºæ²¡æœ‰æ­£ç¡®çš„æ£€æµ‹å‡ºé£æœºã€‚æ‰€ä»¥æˆ‘ä»¬å¸Œæœ›é‡‡ç”¨ä¸€ç§æ–¹æ³•å¯¹çº¢è‰²çš„æ¡†è¿›è¡Œå¾®è°ƒï¼Œä½¿å¾—positive anchorså’ŒGTæ›´åŠ æ¥è¿‘ã€‚\n\nå¯¹äºçª—å£ä¸€èˆ¬ä½¿ç”¨å››ç»´å‘é‡Â (x, y, w, h)è¡¨ç¤ºï¼Œåˆ†åˆ«è¡¨ç¤ºçª—å£çš„ä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜ã€‚å¯¹äºä¸‹å›¾ï¼Œçº¢è‰²çš„æ¡†Aä»£è¡¨åŸå§‹çš„positive Anchorsï¼Œç»¿è‰²çš„æ¡†Gä»£è¡¨ç›®æ ‡çš„GTï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¯»æ‰¾ä¸€ç§å…³ç³»ï¼Œä½¿å¾—è¾“å…¥åŸå§‹çš„anchor Aç»è¿‡æ˜ å°„å¾—åˆ°ä¸€ä¸ªè·ŸçœŸå®çª—å£Gæ›´æ¥è¿‘çš„å›å½’çª—å£G'ï¼Œå³ï¼š\n\n\nç»™å®šanchorÂ A=(, , , )å’ŒGT=[, , , ]\nå¯»æ‰¾ä¸€ç§å˜æ¢Fï¼Œä½¿å¾—ï¼šF(, , , )= (, , , ),å…¶ä¸­(, , , )â‰ˆ(, , , )\n\næ¯”è¾ƒç®€å•çš„æ€è·¯å°±æ˜¯:\n\nè§‚å¯Ÿä¸Šé¢4ä¸ªå…¬å¼å‘ç°ï¼Œéœ€è¦å­¦ä¹ çš„æ˜¯,,,Â è¿™å››ä¸ªå˜æ¢ã€‚å½“è¾“å…¥çš„anchor Aä¸GTç›¸å·®è¾ƒå°æ—¶ï¼Œå¯ä»¥è®¤ä¸ºè¿™ç§å˜æ¢æ˜¯ä¸€ç§çº¿æ€§å˜æ¢ï¼Œ é‚£ä¹ˆå°±å¯ä»¥ç”¨çº¿æ€§å›å½’æ¥å»ºæ¨¡å¯¹çª—å£è¿›è¡Œå¾®è°ƒï¼ˆæ³¨æ„ï¼Œåªæœ‰å½“anchors Aå’ŒGTæ¯”è¾ƒæ¥è¿‘æ—¶ï¼Œæ‰èƒ½ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹ï¼Œå¦åˆ™å°±æ˜¯å¤æ‚çš„éçº¿æ€§é—®é¢˜äº†ï¼‰ã€‚\næ¥ä¸‹æ¥çš„é—®é¢˜å°±æ˜¯å¦‚ä½•é€šè¿‡çº¿æ€§å›å½’è·,,,Â äº†ã€‚çº¿æ€§å›å½’å°±æ˜¯ç»™å®šè¾“å…¥çš„ç‰¹å¾å‘é‡X, å­¦ä¹ ä¸€ç»„å‚æ•°W, ä½¿å¾—ç»è¿‡çº¿æ€§å›å½’åçš„å€¼è·ŸçœŸå®å€¼Yéå¸¸æ¥è¿‘ï¼Œå³Y=WX.\nå¯¹äºè¯¥é—®é¢˜ï¼Œè¾“å…¥Xæ˜¯cnn feature mapï¼Œå®šä¹‰ä¸ºÎ¦ï¼›åŒæ—¶è¿˜æœ‰è®­ç»ƒä¼ å…¥Aä¸GTä¹‹é—´çš„å˜æ¢é‡ï¼Œå³,,,ã€‚è¾“å‡ºæ˜¯,,,å››ä¸ªå˜æ¢ã€‚é‚£ä¹ˆç›®æ ‡å‡½æ•°å¯ä»¥è¡¨ç¤ºä¸º:\n\næ‰€ä»¥åœ¨RPNä¸­ï¼Œbounding box regressioné€šè¿‡ç¬¬äºŒæ¡çº¿å®Œæˆï¼š\n\n\nRPNä¸­çš„bbox reg\n\nå¯ä»¥çœ‹åˆ°ç»è¿‡è¯¥å·ç§¯è¾“å‡ºå›¾åƒä¸ºWxHx36ï¼Œåœ¨caffe blobå­˜å‚¨ä¸º[1, 4x9, H, W]ï¼Œè¿™é‡Œç›¸å½“äºfeature mapsæ¯ä¸ªç‚¹éƒ½æœ‰9ä¸ªanchorsï¼Œæ¯ä¸ªanchorsåˆéƒ½æœ‰4ä¸ªç”¨äºå›å½’çš„\nVGGè¾“å‡º(M/16)*(N/16)*256çš„ç‰¹å¾ï¼Œå¯¹åº”è®¾ç½®Â (M/16)*(N/16)*k ä¸ªanchorsï¼Œè€ŒRPNè¾“å‡ºï¼š\n\nå¤§å°ä¸º(M/16)*(N/16)*2kçš„positive/negative softmaxåˆ†ç±»ç‰¹å¾çŸ©é˜µ\nå¤§å°ä¸º(M/16)*(N/16)*4kçš„regressionåæ ‡å›å½’ç‰¹å¾çŸ©é˜µ\n\næ°å¥½æ»¡è¶³RPNå®Œæˆpositive/negativeåˆ†ç±»+bounding box regressionåæ ‡å›å½’.\nProposal Layer\nProposal Layerè´Ÿè´£ç»¼åˆæ‰€æœ‰Â ,,,Â å˜æ¢é‡å’Œpositive anchorsï¼Œè®¡ç®—å‡ºç²¾å‡†çš„proposalï¼Œé€å…¥åç»­RoI Pooling Layerã€‚\nProposal Layeræœ‰3ä¸ªè¾“å…¥ï¼š 1. åˆ†ç±»å™¨ç»“æœï¼ˆpositive vs negative anchorsrpn_cls_prob_reshape) 2. bbox regçš„Â ,,,å˜æ¢é‡rpn_bbox_pred 3. im_infoï¼› 4. å¦å¤–è¿˜æœ‰å‚æ•°feat_stride=16ï¼Œè¿™å’Œå›¾4æ˜¯å¯¹åº”çš„ã€‚\né¦–å…ˆè§£é‡Šim_infoã€‚å¯¹äºä¸€å‰¯ä»»æ„å¤§å°PxQå›¾åƒï¼Œä¼ å…¥Faster RCNNå‰é¦–å…ˆreshapeåˆ°å›ºå®šMxNï¼Œim_info=[M, N, scale_factor]åˆ™ä¿å­˜äº†æ­¤æ¬¡ç¼©æ”¾çš„æ‰€æœ‰ä¿¡æ¯ã€‚ç„¶åç»è¿‡Conv Layersï¼Œç»è¿‡4æ¬¡poolingå˜ä¸ºWxH=(M/16)x(N/16)å¤§å°ï¼Œå…¶ä¸­feature_stride=16åˆ™ä¿å­˜äº†è¯¥ä¿¡æ¯ï¼Œç”¨äºè®¡ç®—anchoråç§»é‡ã€‚\nProposal Layer forwardæŒ‰ç…§ä»¥ä¸‹é¡ºåºä¾æ¬¡å¤„ç†ï¼š 1.ç”Ÿæˆanchorsï¼Œåˆ©ç”¨,,, å¯¹æ‰€æœ‰çš„anchorsåšbbox regressionå›å½’ï¼ˆè¿™é‡Œçš„anchorsç”Ÿæˆå’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼‰ 2. æŒ‰ç…§è¾“å…¥çš„positive softmax scoresç”±å¤§åˆ°å°æ’åºanchorsï¼Œæå–å‰pre_nms_topN(e.g. 6000)ä¸ªanchorsï¼Œå³æå–ä¿®æ­£ä½ç½®åçš„positive anchors 3. é™å®šè¶…å‡ºå›¾åƒè¾¹ç•Œçš„positive anchorsä¸ºå›¾åƒè¾¹ç•Œï¼Œé˜²æ­¢åç»­roi poolingæ—¶proposalè¶…å‡ºå›¾åƒè¾¹ç•Œ 4. å‰”é™¤å°ºå¯¸éå¸¸å°çš„positive anchors 5. å¯¹å‰©ä½™çš„positive anchorsè¿›è¡ŒNMSï¼ˆnonmaximum suppressionï¼‰ 6. Proposal Layeræœ‰3ä¸ªè¾“å…¥ï¼špositiveå’Œnegative anchorsåˆ†ç±»å™¨ç»“æœrpn_cls_prob_reshapeï¼Œå¯¹åº”çš„bbox regçš„(e.g. 300)ç»“æœä½œä¸ºproposalè¾“å‡º\nä¹‹åè¾“å‡ºproposal=[x1, y1, x2, y2]ï¼Œæ³¨æ„ï¼Œç”±äºåœ¨ç¬¬ä¸‰æ­¥ä¸­å°†anchorsæ˜ å°„å›åŸå›¾åˆ¤æ–­æ˜¯å¦è¶…å‡ºè¾¹ç•Œï¼Œæ‰€ä»¥è¿™é‡Œè¾“å‡ºçš„proposalæ˜¯å¯¹åº”MxNè¾“å…¥å›¾åƒå°ºåº¦çš„ï¼Œè¿™ç‚¹åœ¨åç»­ç½‘ç»œä¸­æœ‰ç”¨ã€‚\n\n\n\n\n\n\n\n\n\nRPNç½‘ç»œç»“æ„å°±ä»‹ç»åˆ°è¿™é‡Œï¼Œæ€»ç»“èµ·æ¥å°±æ˜¯ï¼š ç”Ÿæˆanchors -&gt; softmaxåˆ†ç±»å™¨æå–positvie anchors -&gt; bbox regå›å½’positive anchors -&gt; Proposal Layerç”Ÿæˆproposals\nRPNç”ŸæˆRoIs\nRPNåœ¨è‡ªèº«è®­ç»ƒçš„åŒæ—¶ï¼Œè¿˜ä¼šæä¾›RoIsï¼ˆregion of interestsï¼‰ç»™Fast RCNNï¼ˆRoIHeadï¼‰ä½œä¸ºè®­ç»ƒæ ·æœ¬ã€‚RPNç”ŸæˆRoIsçš„è¿‡ç¨‹(ProposalCreator)å¦‚ä¸‹ï¼š\n\nå¯¹äºæ¯å¼ å›¾ç‰‡ï¼Œåˆ©ç”¨å®ƒçš„feature mapï¼Œ è®¡ç®— (H/16)Ã— (W/16)Ã—9ï¼ˆå¤§æ¦‚20000ï¼‰ä¸ªanchorå±äºå‰æ™¯çš„æ¦‚ç‡ï¼Œä»¥åŠå¯¹åº”çš„ä½ç½®å‚æ•°ã€‚\né€‰å–æ¦‚ç‡è¾ƒå¤§çš„12000ä¸ªanchor\nåˆ©ç”¨å›å½’çš„ä½ç½®å‚æ•°ï¼Œä¿®æ­£è¿™12000ä¸ªanchorçš„ä½ç½®ï¼Œå¾—åˆ°RoIs\nåˆ©ç”¨éæå¤§å€¼ï¼ˆ(Non-maximum suppression, NMSï¼‰æŠ‘åˆ¶ï¼Œé€‰å‡ºæ¦‚ç‡æœ€å¤§çš„2000ä¸ªRoIs\n\næ³¨æ„ï¼šåœ¨inferenceçš„æ—¶å€™ï¼Œä¸ºäº†æé«˜å¤„ç†é€Ÿåº¦ï¼Œ12000å’Œ2000åˆ†åˆ«å˜ä¸º6000å’Œ300.\næ³¨æ„ï¼šè¿™éƒ¨åˆ†çš„æ“ä½œä¸éœ€è¦è¿›è¡Œåå‘ä¼ æ’­ï¼Œå› æ­¤å¯ä»¥åˆ©ç”¨numpy/tensorå®ç°ã€‚\nROI pooling\nRoI Poolingå±‚åˆ™è´Ÿè´£æ”¶é›†proposalï¼Œå¹¶è®¡ç®—å‡ºproposal feature mapsï¼Œé€å…¥åç»­ç½‘ç»œã€‚ä»å›¾2ä¸­å¯ä»¥çœ‹åˆ°Rol poolingå±‚æœ‰2ä¸ªè¾“å…¥ï¼š\n\nåŸå§‹çš„feature maps\nRPNè¾“å‡ºçš„proposal boxesï¼ˆå¤§å°å„ä¸ç›¸åŒï¼‰\n\nä¸ºä½•éœ€è¦RoI Pooling\nå½“ç½‘ç»œè®­ç»ƒå¥½åè¾“å…¥çš„å›¾åƒå°ºå¯¸å¿…é¡»æ˜¯å›ºå®šå€¼ï¼ŒåŒæ—¶ç½‘ç»œè¾“å‡ºä¹Ÿæ˜¯å›ºå®šå¤§å°çš„vector or matrixã€‚å¦‚æœè¾“å…¥å›¾åƒå¤§å°ä¸å®šï¼Œè¿™ä¸ªé—®é¢˜å°±å˜å¾—æ¯”è¾ƒéº»çƒ¦ã€‚æœ‰2ç§è§£å†³åŠæ³•ï¼š\n\nä»å›¾åƒä¸­cropä¸€éƒ¨åˆ†ä¼ å…¥ç½‘ç»œ\nå°†å›¾åƒwarpæˆéœ€è¦çš„å¤§å°åä¼ å…¥ç½‘ç»œ\n\næ— è®ºé‡‡å–é‚£ç§åŠæ³•éƒ½ä¸å¥½ï¼Œè¦ä¹ˆcropåç ´åäº†å›¾åƒçš„å®Œæ•´ç»“æ„ï¼Œè¦ä¹ˆwarpç ´åäº†å›¾åƒåŸå§‹å½¢çŠ¶ä¿¡æ¯ã€‚\nRPNç½‘ç»œç”Ÿæˆçš„proposalsçš„æ–¹æ³•ï¼šå¯¹positive anchorsè¿›è¡Œbounding box regressionï¼Œé‚£ä¹ˆè¿™æ ·è·å¾—çš„proposalsä¹Ÿæ˜¯å¤§å°å½¢çŠ¶å„ä¸ç›¸åŒï¼Œå³ä¹Ÿå­˜åœ¨ä¸Šè¿°é—®é¢˜ã€‚æ‰€ä»¥Faster R-CNNä¸­æå‡ºäº†RoI Poolingè§£å†³è¿™ä¸ªé—®é¢˜.\nRoI Pooling layer forward\n\nç”±äºproposalæ˜¯å¯¹åº”MxNå°ºåº¦çš„ï¼Œæ‰€ä»¥é¦–å…ˆä½¿ç”¨spatial_scaleå‚æ•°å°†å…¶æ˜ å°„å›(M/16)x(N/16)å¤§å°çš„feature mapå°ºåº¦ï¼›\nå†å°†æ¯ä¸ªproposalå¯¹åº”çš„feature mapåŒºåŸŸæ°´å¹³åˆ†ä¸ºÂ pooled_w*_hçš„ç½‘æ ¼ï¼›\nå¯¹ç½‘æ ¼çš„æ¯ä¸€ä»½éƒ½è¿›è¡Œmax poolingå¤„ç†ã€‚\n\nè¿™æ ·å¤„ç†åï¼Œå³ä½¿å¤§å°ä¸åŒçš„proposalè¾“å‡ºç»“æœéƒ½æ˜¯pooled_w*_hå›ºå®šå¤§å°ï¼Œå®ç°äº†å›ºå®šé•¿åº¦è¾“å‡ºã€‚\nä¸ºä»€ä¹ˆè¦poolingæˆ7Ã—7çš„å°ºåº¦ï¼Ÿ\næ˜¯ä¸ºäº†èƒ½å¤Ÿå…±äº«æƒé‡ã€‚åœ¨ä¹‹å‰è®²è¿‡ï¼Œé™¤äº†ç”¨åˆ°VGGå‰å‡ å±‚çš„å·ç§¯ä¹‹å¤–ï¼Œæœ€åçš„å…¨è¿æ¥å±‚ä¹Ÿå¯ä»¥ç»§ç»­åˆ©ç”¨ã€‚å½“æ‰€æœ‰çš„RoIséƒ½è¢«poolingæˆï¼ˆ512Ã—7Ã—7ï¼‰çš„feature mapåï¼Œå°†å®ƒreshape æˆä¸€ä¸ªä¸€ç»´çš„å‘é‡ï¼Œå°±å¯ä»¥åˆ©ç”¨VGG16é¢„è®­ç»ƒçš„æƒé‡ï¼Œåˆå§‹åŒ–å‰ä¸¤å±‚å…¨è¿æ¥ã€‚æœ€åå†æ¥ä¸¤ä¸ªå…¨è¿æ¥å±‚ï¼Œåˆ†åˆ«æ˜¯ï¼š\nFC 21 ç”¨æ¥åˆ†ç±»ï¼Œé¢„æµ‹RoIså±äºå“ªä¸ªç±»åˆ«ï¼ˆ20ä¸ªç±»+èƒŒæ™¯ï¼‰ FC 84 ç”¨æ¥å›å½’ä½ç½®ï¼ˆ21ä¸ªç±»ï¼Œæ¯ä¸ªç±»éƒ½æœ‰4ä¸ªä½ç½®å‚æ•°ï¼‰\nClassification\nClassificationéƒ¨åˆ†åˆ©ç”¨å·²ç»è·å¾—çš„proposal feature mapsï¼Œé€šè¿‡full connectå±‚ä¸softmaxè®¡ç®—æ¯ä¸ªproposalå…·ä½“å±äºé‚£ä¸ªç±»åˆ«ï¼ˆå¦‚äººï¼Œè½¦ï¼Œç”µè§†ç­‰ï¼‰ï¼Œè¾“å‡ºcls_probæ¦‚ç‡å‘é‡ï¼›åŒæ—¶å†æ¬¡åˆ©ç”¨bounding box regressionè·å¾—æ¯ä¸ªproposalçš„ä½ç½®åç§»é‡bbox_predï¼Œç”¨äºå›å½’æ›´åŠ ç²¾ç¡®çš„ç›®æ ‡æ£€æµ‹æ¡†ã€‚Classificationéƒ¨åˆ†ç½‘ç»œç»“æ„å¦‚å›¾:\n\n\nClassificationéƒ¨åˆ†ç½‘ç»œç»“æ„\n\nä»RoI Poolingè·å–åˆ°7x7=49å¤§å°çš„proposal feature mapsåï¼Œé€å…¥åç»­ç½‘ç»œï¼Œå¯ä»¥çœ‹åˆ°åšäº†å¦‚ä¸‹2ä»¶äº‹ï¼š\n\né€šè¿‡å…¨è¿æ¥å’Œsoftmaxå¯¹proposalsè¿›è¡Œåˆ†ç±»ï¼Œè¿™å®é™…ä¸Šå·²ç»æ˜¯è¯†åˆ«çš„èŒƒç•´äº†\nå†æ¬¡å¯¹proposalsè¿›è¡Œbounding box regressionï¼Œè·å–æ›´é«˜ç²¾åº¦çš„rect box\n\nAnchoråˆ°åº•ä¸ç½‘ç»œè¾“å‡ºå¦‚ä½•å¯¹åº”\nVGGè¾“å‡ºÂ 50*38*512çš„ç‰¹å¾ï¼Œå¯¹åº”è®¾ç½®Â 50*38*kä¸ªanchorsï¼Œè€ŒRPNè¾“å‡º50*38*2kçš„åˆ†ç±»ç‰¹å¾çŸ©é˜µå’Œ50*38*4kçš„åæ ‡å›å½’ç‰¹å¾çŸ©é˜µã€‚\n\nå…¶å®åœ¨å®ç°è¿‡ç¨‹ä¸­ï¼Œæ¯ä¸ªç‚¹çš„2kä¸ªåˆ†ç±»ç‰¹å¾ä¸Â 4kå›å½’ç‰¹å¾ï¼Œä¸Â kä¸ªanchoré€ä¸ªå¯¹åº”å³å¯ï¼Œè¿™å®é™…æ˜¯ä¸€ç§â€œäººä¸ºè®¾ç½®çš„é€»è¾‘æ˜ å°„â€ã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥ä¸è¿™æ ·è®¾ç½®ï¼Œä½†æ˜¯æ— è®ºå¦‚ä½•éƒ½éœ€è¦ä¿è¯åœ¨è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­æ˜ å°„æ–¹å¼å¿…é¡»ä¸€è‡´ã€‚\nLoss\n\nä¸Šè¿°å…¬å¼ä¸­Â i è¡¨ç¤ºanchors indexï¼ŒÂ è¡¨ç¤ºpositive softmax probabilityï¼Œä»£è¡¨å¯¹åº”çš„GT predictæ¦‚ç‡ï¼ˆå³å½“ç¬¬iä¸ªanchorä¸GTé—´IoU&gt;0.7ï¼Œè®¤ä¸ºæ˜¯è¯¥anchoræ˜¯positiveï¼Œ=1 ï¼›åä¹‹IoU&lt;0.3æ—¶ï¼Œè®¤ä¸ºæ˜¯è¯¥anchoræ˜¯negativeï¼Œ=0 ï¼›è‡³äºé‚£äº›0.3&lt;IoU&lt;0.7çš„anchoråˆ™ä¸å‚ä¸è®­ç»ƒï¼‰ï¼›t ä»£è¡¨predict bounding boxï¼Œä»£è¡¨å¯¹åº”positive anchorå¯¹åº”çš„GT boxã€‚å¯ä»¥çœ‹åˆ°ï¼Œæ•´ä¸ªLossåˆ†ä¸º2éƒ¨åˆ†ï¼š\n\nåœ¨è®­ç»ƒFaster RCNNçš„æ—¶å€™æœ‰å››ä¸ªæŸå¤±ï¼š\n\nRPN åˆ†ç±»æŸå¤±ï¼šanchoræ˜¯å¦ä¸ºå‰æ™¯ï¼ˆäºŒåˆ†ç±»ï¼‰\nRPNä½ç½®å›å½’æŸå¤±ï¼šanchorä½ç½®å¾®è°ƒ\nRoI åˆ†ç±»æŸå¤±ï¼šRoIæ‰€å±ç±»åˆ«ï¼ˆ21åˆ†ç±»ï¼Œå¤šäº†ä¸€ä¸ªç±»ä½œä¸ºèƒŒæ™¯ï¼‰\nRoIä½ç½®å›å½’æŸå¤±ï¼šç»§ç»­å¯¹RoIä½ç½®å¾®è°ƒ\n\nå››ä¸ªæŸå¤±ç›¸åŠ ä½œä¸ºæœ€åçš„æŸå¤±ï¼Œåå‘ä¼ æ’­ï¼Œæ›´æ–°å‚æ•°ã€‚\n### æ³¨æ„\n1\n\nåœ¨RPNçš„æ—¶å€™ï¼Œå·²ç»å¯¹anchoråšäº†ä¸€éNMSï¼Œåœ¨RCNNæµ‹è¯•çš„æ—¶å€™ï¼Œè¿˜è¦å†åšä¸€é\nåœ¨RPNçš„æ—¶å€™ï¼Œå·²ç»å¯¹anchorçš„ä½ç½®åšäº†å›å½’è°ƒæ•´ï¼Œåœ¨RCNNé˜¶æ®µè¿˜è¦å¯¹RoIå†åšä¸€é\nåœ¨RPNé˜¶æ®µåˆ†ç±»æ˜¯äºŒåˆ†ç±»ï¼Œè€ŒFast RCNNé˜¶æ®µæ˜¯21åˆ†ç±»(voc)\n\n2\nRPNä¼šäº§ç”Ÿå¤§çº¦2000ä¸ªRoIsï¼Œè¿™2000ä¸ªRoIsä¸æ˜¯éƒ½æ‹¿å»è®­ç»ƒï¼Œè€Œæ˜¯é€‰æ‹©128ä¸ªRoIsç”¨ä»¥è®­ç»ƒã€‚é€‰æ‹©çš„è§„åˆ™å¦‚ä¸‹ï¼š\n\nRoIså’Œgt_bboxes çš„IoUå¤§äº0.5çš„ï¼Œé€‰æ‹©ä¸€äº›ï¼ˆæ¯”å¦‚32ä¸ªï¼‰\né€‰æ‹© RoIså’Œgt_bboxesçš„IoUå°äºç­‰äº0ï¼ˆæˆ–è€…0.1ï¼‰çš„é€‰æ‹©ä¸€äº›ï¼ˆæ¯”å¦‚ 128-32=96ä¸ªï¼‰ä½œä¸ºè´Ÿæ ·æœ¬\n\nä¸ºäº†ä¾¿äºè®­ç»ƒï¼Œå¯¹é€‰æ‹©å‡ºçš„128ä¸ªRoIsï¼Œè¿˜å¯¹ä»–ä»¬çš„gt_roi_loc è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼ˆå‡å»å‡å€¼é™¤ä»¥æ ‡å‡†å·®ï¼‰\n","slug":"Faster-RCNN-è®°å½•","date":"2021-10-11T07:47:29.000Z","categories_index":"","tags_index":"detection","author_index":"Hulk Wang"},{"id":"7f399d762217f0410e81da356daa491f","title":"FCOSå­¦ä¹ ç¬”è®°","content":"FCOSå­¦ä¹ ç¬”è®°\n\n\n\n\n\n\n\n\n\nç¬”è®°æ¥æºï¼šhttps://blog.csdn.net/WZZ18191171661/article/details/89258086 https://zhuanlan.zhihu.com/p/339023466\nFCOSæ˜¯ä¸€ä¸ªåŸºäºFCNçš„per-pixelã€anchor freeçš„one-stageç›®æ ‡æ£€æµ‹ç®—æ³•ï¼Œè®ºæ–‡å…¨:ã€ŠFCOS: Fully Convolutional One-Stage Object Detectionã€‹\nAnchor-basedä¸è¶³ï¼š\n\nanchorä¼šå¼•å…¥å¾ˆå¤šéœ€è¦ä¼˜åŒ–çš„è¶…å‚æ•°ï¼Œ æ¯”å¦‚anchor numberã€anchor sizeã€anchor ratioç­‰ï¼›\nä¸ºäº†ä¿è¯ç®—æ³•æ•ˆæœï¼Œéœ€è¦å¾ˆå¤šçš„anchorsï¼Œå­˜åœ¨æ­£è´Ÿæ ·æœ¬ç±»åˆ«ä¸å‡è¡¡é—®é¢˜ï¼›\nåœ¨è®­ç»ƒçš„æ—¶å€™ï¼Œéœ€è¦è®¡ç®—æ‰€æœ‰anchor boxåŒground truth boxesçš„IoUï¼Œè®¡ç®—é‡è¾ƒå¤§ï¼›\n\nFCOSä¼˜åŠ¿ï¼š 1. å› ä¸ºè¾“å‡ºæ˜¯pixel-basedé¢„æµ‹ï¼Œæ‰€ä»¥å¯ä»¥å¤ç”¨semantic segmentationæ–¹å‘çš„ç›¸å…³tricksï¼› 2. å¯ä»¥ä¿®æ”¹FCOSçš„è¾“å‡ºåˆ†æ”¯ï¼Œç”¨äºè§£å†³instance segmentationå’Œkeypoint detectionä»»åŠ¡ï¼›\n\n\nFCOSç½‘ç»œç»“æ„\n\nå®ç°ç»†èŠ‚\nä¸Anchor Baseå¯¹æ¯”\nå¯¹äºåŸºäºanchorsçš„ç›®æ ‡æ£€æµ‹ç®—æ³•è€Œè¨€ï¼Œæˆ‘ä»¬å°†è¾“å…¥çš„å›¾ç‰‡é€å…¥backboneç½‘ç»œä¹‹åï¼Œä¼šè·å¾—æœ€ç»ˆçš„feature_mapï¼Œæ¯”å¦‚è¯´æ˜¯17x17x256ï¼›ç„¶åæˆ‘ä»¬ä¼šåœ¨è¯¥feature_mapä¸Šçš„æ¯ä¸€ä½ç½®ä¸Šä½¿ç”¨é¢„å…ˆå®šä¹‰å¥½çš„anchorsã€‚è€ŒFCOSçš„æ”¹åŠ¨ç‚¹å°±åœ¨è¿™é‡Œï¼Œå®ƒæ˜¯ç›´æ¥åœ¨feature_mapä¸Šçš„æ¯ä¸€ç‚¹è¿›è¡Œå›å½’æ“ä½œã€‚\nå…·ä½“çš„å®æ–½æ€è·¯å¦‚ä¸‹æ‰€ç¤ºï¼š 1. æˆ‘ä»¬å¯ä»¥å°†feature_mapä¸­çš„æ¯ä¸€ä¸ªç‚¹(x,y)æ˜ å°„å›åŸå§‹çš„è¾“å…¥å›¾ç‰‡ä¸­: (âŒŠs/2âŒ‹ + xs, âŒŠs/2âŒ‹ + ys) å…¶ä¸­: sä¸ºæ­¥é•¿ï¼Œ(x,y)ä¸ºæ”¹ç‚¹å¯¹åº”feature mapä¸Šçš„åæ ‡.\n\nå¦‚æœè¿™ä¸ªæ˜ å°„å›åŸå§‹è¾“å…¥çš„ç‚¹åœ¨ç›¸åº”çš„GTçš„bboxèŒƒå›´ä¹‹å†…ï¼Œè€Œä¸”ç±»åˆ«æ ‡ç­¾å¯¹åº”ï¼Œæˆ‘ä»¬å°†å…¶ä½œä¸ºè®­ç»ƒçš„æ­£æ ·æœ¬å—ï¼Œå¦åˆ™å°†å…¶ä½œä¸ºæ­£æ ·æœ¬å—ï¼›\nå›å½’çš„ç›®æ ‡æ˜¯(l,t,r,b)ï¼Œå³ä¸­å¿ƒç‚¹åšbboxçš„leftã€topã€rightå’Œbottomä¹‹é—´çš„è·ç¦»ï¼Œå…·ä½“å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š\n\nå¦‚æœä¸€ä¸ªä½ç½®åœ¨å¤šä¸ªbboxçš„å†…éƒ¨çš„è¯ï¼Œå¦‚å³å›¾ï¼Œé’ˆå¯¹è¿™æ ·æ ·æœ¬æ–‡ä¸­é‡‡æ ·çš„æ–¹æ³•æ˜¯ç›´æ¥é€‰æ‹©æ‹©é¢ç§¯æœ€å°çš„è¾¹ç•Œæ¡†ä½œä¸ºå…¶å›å½’ç›®æ ‡ã€‚ç”±äºç½‘ç»œä¸­FPNçš„å­˜åœ¨ï¼Œå¯¼è‡´è¿™æ ·çš„æ¨¡ç³Šæ ·æœ¬çš„æ•°é‡å¤§å¤§å‡å°‘ã€‚\nå¦‚æœè¿™ä¸ªä½ç½®(x,y)å’Œä¸€ä¸ªbboxå…³è”çš„è¯ï¼Œè¯¥ä½ç½®å¤„çš„è®­ç»ƒå›å½’ç›®æ ‡å¯åˆ¶å®šä¸º:å…¶ä¸­(x1,y1)å’Œ(x2,y2)åˆ†åˆ«è¡¨ç¤ºbboxçš„å·¦ä¸Šè§’å’Œå³ä¸‹è§’åæ ‡å€¼ã€‚\n\nç”±äºFCOSå¯ä»¥é€šè¿‡è¿™æ ·æ–¹å¼è·å¾—å¾ˆå¤šæ­£æ ·æœ¬å—ï¼Œä½¿ç”¨è¿™æ ·çš„æ­£æ ·æœ¬å—è¿›è¡Œå›å½’æ“ä½œï¼Œå› æ­¤è·å¾—äº†æ¯”è¾ƒå¥½çš„æ€§èƒ½æå‡ï¼Œè€ŒåŸå§‹çš„åŸºäºanchorçš„ç®—æ³•éœ€è¦é€šè¿‡è®¡ç®—é¢„è®¾çš„anchorå’Œå¯¹åº”çš„GTä¹‹é—´çš„IOUå€¼ï¼Œå½“è¯¥IOUå€¼å¤§äºè®¾å®šçš„é˜ˆå€¼æ—¶æ‰å°†å…¶çœ‹åšæ­£æ ·æœ¬å—ã€‚\n\nLoss\n\nlosså‡½æ•°å¦‚ä¸Šå›¾æ‰€ç¤ºï¼ŒåŒ…å«ä¸¤éƒ¨åˆ†ï¼ŒLclsè¡¨ç¤ºåˆ†ç±»lossï¼Œæœ¬æ–‡ä½¿ç”¨çš„æ˜¯Focal_lossï¼›Lregè¡¨ç¤ºå›å½’lossï¼Œæœ¬æ–‡ä½¿ç”¨çš„æ˜¯IOU lossã€‚\ncenter-nessåˆ†æ”¯\nCenter-nessè¡¨ç¤ºçš„æ˜¯(x,y)è·ç›®æ ‡ä¸­å¿ƒçš„æ ‡å‡†åŒ–åçš„è·ç¦»ï¼Œä¸ºäº†åˆ¶æ­¢è¿‡å¤šçš„ä½è´¨é‡ç¦»ç›®æ ‡ä¸­å¿ƒè¿œçš„æ£€æµ‹æ¡†è€Œè®¾è®¡ã€‚\n\n\nå¦‚ä¸Šå›¾ï¼Œçº¢è‰²åˆ°è“è‰²è¡¨ç¤ºcenter-nessä»1åˆ°0ï¼Œå› ä¸ºcenter-nessæ˜¯åœ¨0-1ä¹‹é—´ï¼Œæ‰€ä»¥ç”¨çš„BCE lossï¼Œè¿™ä¸ªlossä¼šä¸€èµ·åŠ åˆ°ä¸Šé¢æˆ‘ä»¬æåˆ°çš„loss functionä¸­ã€‚åœ¨æµ‹è¯•æ—¶ï¼Œæ£€æµ‹æ¡†çš„æ’åºåˆ†æ•°ç”±center-nessä¹˜ä¸Šåˆ†ç±»çš„åˆ†æ•°ã€‚å¦‚æœè¿˜æœ‰ä½è´¨é‡çš„æ¡†ï¼Œæœ€åå¯ç”¨NMSæ¥å‰”é™¤ã€‚\n","slug":"FCOSå­¦ä¹ ç¬”è®°","date":"2021-09-13T08:19:35.000Z","categories_index":"","tags_index":"detection","author_index":"Hulk Wang"},{"id":"57d3aa7cdcc56700d35ee7aa4e8c6558","title":"YOLO-V5å­¦ä¹ ç¬”è®°","content":"YOLO-V5å­¦ä¹ ç¬”è®°\n\n\n\n\n\n\n\n\n\nçŸ¥è¯†ç‚¹æ¥æºäºç½‘ç»œï¼Œä»…è®°å½•å­¦ä¹  æ¥æºï¼šhttps://zhuanlan.zhihu.com/p/172121380\nç½‘ç»œç»“æ„\n\n\nYolov5sç½‘ç»œç»“æ„(æ¥æºè§æ°´å°)\n\nå¦‚ä¸Šå›¾ä¸ºyolov5çš„æ•´ä½“ç½‘ç»œç»“æ„ï¼Œè·Ÿyolov4ä¸€æ ·ï¼Œåˆ†åˆ«æŒ‰inputã€backboneã€Neckä»¥åŠPredictionå››éƒ¨åˆ†æ¥ç†è§£ã€‚\n\n\n\n\n\n\n\n\n\nYolov5å®˜æ–¹ä»£ç ä¸­ï¼Œä¸€å…±æœ‰4ä¸ªç‰ˆæœ¬ï¼Œåˆ†åˆ«æ˜¯Yolov5sã€Yolov5mã€Yolov5lã€Yolov5xå››ä¸ªæ¨¡å‹ã€‚Yolov5sæ˜¯Yolov5ç³»åˆ—ä¸­æ·±åº¦æœ€å°ï¼Œç‰¹å¾å›¾çš„å®½åº¦æœ€å°çš„ç½‘ç»œã€‚åé¢çš„3ç§éƒ½æ˜¯åœ¨æ­¤åŸºç¡€ä¸Šä¸æ–­åŠ æ·±ï¼Œä¸æ–­åŠ å®½ã€‚\nè¾“å…¥ç«¯\nMosaicæ•°æ®å¢å¼º\nä¸v4ä¸€æ ·ï¼Œé‡‡ç”¨Mosaicæ•°æ®å¢å¼ºï¼›\nè‡ªé€‚åº”é”šæ¡†è®¡ç®—\nå°†anchoråˆå§‹è®¡ç®—(èšç±»)é›†æˆåˆ°è®­ç»ƒä»£ç ä¸­ï¼›\nè‡ªé€‚åº”å›¾ç‰‡ç¼©æ”¾\né’ˆå¯¹inferenceé˜¶æ®µçš„ä¼˜åŒ–\nåœ¨å¸¸ç”¨çš„ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸­ï¼Œä¸åŒçš„å›¾ç‰‡é•¿å®½éƒ½ä¸ç›¸åŒï¼Œå› æ­¤å¸¸ç”¨çš„æ–¹å¼æ˜¯å°†åŸå§‹å›¾ç‰‡ç»Ÿä¸€ç¼©æ”¾åˆ°ä¸€ä¸ªæ ‡å‡†å°ºå¯¸ï¼Œå†é€å…¥æ£€æµ‹ç½‘ç»œä¸­ã€‚\n\n\nä¼ ç»Ÿæ–¹æ³•(æ¥æºè§æ°´å°)\n\nä½†Yolov5ä»£ç ä¸­å¯¹æ­¤è¿›è¡Œäº†æ”¹è¿›ï¼Œä¹Ÿæ˜¯Yolov5æ¨ç†é€Ÿåº¦èƒ½å¤Ÿå¾ˆå¿«çš„ä¸€ä¸ªä¸é”™çš„trickã€‚\nä½œè€…è®¤ä¸ºï¼Œåœ¨é¡¹ç›®å®é™…ä½¿ç”¨æ—¶ï¼Œå¾ˆå¤šå›¾ç‰‡çš„é•¿å®½æ¯”ä¸åŒï¼Œå› æ­¤ç¼©æ”¾å¡«å……åï¼Œä¸¤ç«¯çš„é»‘è¾¹å¤§å°éƒ½ä¸åŒï¼Œè€Œå¦‚æœå¡«å……çš„æ¯”è¾ƒå¤šï¼Œåˆ™å­˜åœ¨ä¿¡æ¯å†—ä½™ï¼Œå½±å“æ¨ç†é€Ÿåº¦ã€‚\nå› æ­¤åœ¨Yolov5çš„ä»£ç ä¸­datasets.pyçš„letterboxå‡½æ•°ä¸­è¿›è¡Œäº†ä¿®æ”¹ï¼Œå¯¹åŸå§‹å›¾åƒè‡ªé€‚åº”çš„æ·»åŠ æœ€å°‘çš„é»‘è¾¹ã€‚\n\n\nyolov5(æ¥æºè§æ°´å°)\n\nä¸¾ä¾‹è¯´æ˜å¡«å……æ–¹æ³•ï¼š åŸå§‹ï¼š800x600 ç›®æ ‡ï¼š416\n\né€‰æ‹©å°çš„ç¼©æ”¾ç³»æ•°ï¼ŒçŸ­è¾¹:min(416/800, 416/600);\nå¾—åˆ°æ–°çš„å°ºå¯¸(å³é•¿è¾¹resizeåˆ°ç›®æ ‡å°ºå¯¸,çŸ­è¾¹æŒ‰åŸå§‹é•¿å®½æ¯”å˜æ¢ï¼‰: (416,312);\nè®¡ç®—padå¤§å°(æ‰¾åˆ°å¤§äº312ä¸”èƒ½è¢«32æ•´é™¤çš„æœ€å°æ•´æ•°): (416 - 312) mod 32 = 8 æ‰€ä»¥padå€¼ä¸º8/2=4\n\nBackbone\nFocusç»“æ„\n\n\nfocus(æ¥æºè§æ°´å°)\n\nyolov5ä¸­ï¼ŒFocusæ¨¡å—ä½äºbackboneå‰ã€‚å…·ä½“æ“ä½œæ˜¯åœ¨ä¸€å¼ å›¾ç‰‡ä¸­æ¯éš”ä¸€ä¸ªåƒç´ æ‹¿åˆ°ä¸€ä¸ªå€¼ï¼Œç±»ä¼¼äºé‚»è¿‘ä¸‹é‡‡æ ·ï¼Œè¿™æ ·å°±æ‹¿åˆ°äº†å››å¼ è¿‘ä¼¼ä¸‹é‡‡æ ·çš„å›¾ç‰‡ï¼Œä½†æ˜¯æ²¡æœ‰ä¿¡æ¯ä¸¢å¤±ã€‚ç›¸å½“äºw,hå˜ä¸º1/2ï¼Œè¾“å…¥é€šé“æ‰©å……äº†4å€ï¼Œæœ€åå°†å¾—åˆ°çš„æ–°å›¾ç‰‡å†ç»è¿‡å·ç§¯æ“ä½œï¼Œæœ€ç»ˆå¾—åˆ°äº†æ²¡æœ‰ä¿¡æ¯ä¸¢å¤±æƒ…å†µä¸‹çš„äºŒå€ä¸‹é‡‡æ ·ç‰¹å¾å›¾ã€‚\nä»¥yolov5sä¸ºä¾‹ï¼ŒåŸå§‹çš„640 Ã— 640 Ã— 3çš„å›¾åƒè¾“å…¥Focusç»“æ„ï¼Œé‡‡ç”¨åˆ‡ç‰‡æ“ä½œï¼Œå…ˆå˜æˆ320 Ã— 320 Ã— 12çš„ç‰¹å¾å›¾ï¼Œå†ç»è¿‡ä¸€æ¬¡å·ç§¯æ“ä½œï¼Œæœ€ç»ˆå˜æˆ320 Ã— 320 Ã— 32çš„ç‰¹å¾å›¾ã€‚\nå…·ä½“ä»£ç å®ç°ï¼š\n\nç›®çš„å’Œä½œç”¨ï¼š Focusæ˜¯ä¸ºäº†æé€Ÿï¼Œå’ŒmAPæ— å…³ï¼Œå‡å°‘äº†è®¡ç®—é‡å’Œå‚æ•°é‡ã€‚\nThe YOLOv5 Focus layer replaces the first 3 YOLOv3 layers with a single layer:\n\nè¯¦è§ä½œè€…è§£ç­”\nCSPç»“æ„\nYolov5ä¸Yolov4ä¸åŒç‚¹åœ¨äºï¼ŒYolov4ä¸­åªæœ‰ä¸»å¹²ç½‘ç»œä½¿ç”¨äº†CSPç»“æ„ã€‚\nè€ŒYolov5ä¸­è®¾è®¡äº†ä¸¤ç§CSPç»“æ„ï¼Œä»¥Yolov5sç½‘ç»œä¸ºä¾‹ï¼ŒCSP1_Xç»“æ„åº”ç”¨äºBackboneä¸»å¹²ç½‘ç»œï¼Œå¦ä¸€ç§CSP2_Xç»“æ„åˆ™åº”ç”¨äºNeckä¸­ã€‚\n\nNeck\n\nYolov5ç°åœ¨çš„Neckå’ŒYolov4ä¸­ä¸€æ ·ï¼Œéƒ½é‡‡ç”¨FPN+PANçš„ç»“æ„.\nå¦‚CSPç»“æ„ä¸­è®²åˆ°ï¼ŒYolov5å’ŒYolov4çš„ä¸åŒç‚¹åœ¨äºï¼ŒYolov4çš„Neckç»“æ„ä¸­ï¼Œé‡‡ç”¨çš„éƒ½æ˜¯æ™®é€šçš„å·ç§¯æ“ä½œã€‚è€ŒYolov5çš„Neckç»“æ„ä¸­ï¼Œé‡‡ç”¨å€Ÿé‰´CSPnetè®¾è®¡çš„CSP2ç»“æ„ï¼ŒåŠ å¼ºç½‘ç»œç‰¹å¾èåˆçš„èƒ½åŠ›ã€‚\n\n\nPrediction\nBounding boxæŸå¤±å‡½æ•°\nYolov5: GIOU_Loss Yolov4: CIOU_Loss\nnmséæå¤§å€¼æŠ‘åˆ¶\nYolov4: DIOU_nms Yolov5: åŠ æƒnms\n\n\n\n\n\n\n\n\n\nWeighted NMSå‡ºç°äºICME Workshop 2017ã€ŠInception Single Shot MultiBox Detector for object detectionã€‹ä¸€æ–‡ä¸­ã€‚è®ºæ–‡è®¤ä¸ºTraditional NMSæ¯æ¬¡è¿­ä»£æ‰€é€‰å‡ºçš„æœ€å¤§å¾—åˆ†æ¡†æœªå¿…æ˜¯ç²¾ç¡®å®šä½çš„ï¼Œå†—ä½™æ¡†ä¹Ÿæœ‰å¯èƒ½æ˜¯å®šä½è‰¯å¥½çš„ã€‚é‚£ä¹ˆä¸ç›´æ¥å‰”é™¤æœºåˆ¶ä¸åŒï¼ŒWeighted NMSé¡¾åæ€ä¹‰æ˜¯å¯¹åæ ‡åŠ æƒå¹³å‡ï¼ŒåŠ æƒå¹³å‡çš„å¯¹è±¡åŒ…æ‹¬Mè‡ªèº«ä»¥åŠIoUâ‰¥NMSé˜ˆå€¼çš„ç›¸é‚»æ¡†ã€‚  åŠ æƒçš„æƒé‡ä¸ºÂ :  Â ï¼Œè¡¨ç¤ºå¾—åˆ†ä¸IoUçš„ä¹˜ç§¯ã€‚ ä¼˜ç‚¹ï¼š Weighted NMSé€šå¸¸èƒ½å¤Ÿè·å¾—æ›´é«˜çš„Precisionå’ŒRecallï¼Œåªè¦NMSé˜ˆå€¼é€‰å–å¾—å½“ï¼ŒWeighted NMSå‡èƒ½ç¨³å®šæé«˜APä¸ARï¼Œæ— è®ºæ˜¯AP50è¿˜æ˜¯AP75ï¼Œä¹Ÿä¸è®ºæ‰€ä½¿ç”¨çš„æ£€æµ‹æ¨¡å‹æ˜¯ä»€ä¹ˆã€‚ ç¼ºç‚¹ï¼š é¡ºåºå¤„ç†æ¨¡å¼ï¼Œä¸”è¿ç®—æ•ˆç‡æ¯”Traditional NMSæ›´ä½ã€‚åŠ æƒå› å­æ˜¯IoUä¸å¾—åˆ†ï¼Œå‰è€…åªè€ƒè™‘ä¸¤ä¸ªæ¡†çš„é‡å é¢ç§¯ï¼Œè¿™å¯¹æè¿°boxé‡å å…³ç³»æˆ–è®¸ä¸å¤Ÿå…¨é¢ï¼›è€Œåè€…å—åˆ°å®šä½ä¸å¾—åˆ†ä¸ä¸€è‡´é—®é¢˜çš„é™åˆ¶ã€‚\n","slug":"YOLO-V5å­¦ä¹ ç¬”è®°","date":"2021-09-09T07:42:37.000Z","categories_index":"","tags_index":"detection","author_index":"Hulk Wang"},{"id":"f45a749a54e27d0a1f22b1f23eadc80a","title":"Pixel-Level Domain Transferè®ºæ–‡å¤ç°","content":"Pixel-Level Domain Transferè®ºæ–‡å¤ç°\nåšå®¢è¿ç§»ï¼ŒåŸæ–‡é“¾æ¥\n\n\n\n\n\n\n\n\n\nAbstract.ï¼šWe present an image-conditional image generation model. The model transfers an input domain to a target domain in semantic level, and generates the target image in pixel level. To generate realistic target images, we employ the real/fake-discriminator as in Generative Adversarial Nets, but also introduce a novel domain-discriminator to make the generated image relevant to the input image. We verify our model through a challenging task of generating a piece of clothing from an input image of a dressed person. We present a high quality clothing dataset containing the two domains, and succeed in demonstrating decent results.\nè®ºæ–‡ç®€è¿°\næ•´ç¯‡è®ºæ–‡æ¯”è¾ƒå®¹æ˜“æ‡‚ï¼Œä¸»è¦å†…å®¹å°±æ˜¯æŠŠè¾“å…¥domainè½¬æ¢åˆ°ç›®æ ‡domainï¼Œè¾“å…¥ä¸€å¼ æ¨¡ç‰¹å›¾ç‰‡ï¼Œå¾—åˆ°ä¸Šè¡£å›¾ç‰‡ï¼Œå¦‚ä¸‹ï¼š\n\næ–‡ç« ä¸»è¦è´¡çŒ®ä¸»è¦åœ¨ä¸¤ä¸ªæ–¹é¢ï¼š\nLookBookæ•°æ®é›†\nä¸‹è½½åœ°å€ï¼ˆuj3jï¼‰\n\nåŸºäºGançš„è½¬æ¢æ¡†æ¶\nç½‘ç»œç»“æ„å¦‚ä¸‹ï¼š\n\nç”Ÿæˆç½‘ç»œæ˜¯encoder-decoderç»“æ„ï¼Œåˆ¤åˆ«ç½‘ç»œæœ‰ä¸¤ä¸ªï¼šDrå’ŒDaã€‚\nDrå°±æ˜¯ä¸€ä¸ªåŸºæœ¬çš„Gançš„åˆ¤åˆ«ç½‘ç»œï¼Œåˆ¤åˆ«fakeæˆ–realï¼›Daä¸»è¦ç”¨æ¥åˆ¤æ–­ç”Ÿæˆå›¾åƒä¸è¾“å…¥æ˜¯å¦é…å¯¹ï¼Œæ‰€ä»¥Drè¾“å…¥æ˜¯ç”Ÿæˆç½‘ç»œçš„è¾“å…¥å’Œè¾“å‡ºçš„concat.\næ•´ä¸ªè¿‡ç¨‹å¾ˆå®¹æ˜“æ‡‚ï¼Œç»†èŠ‚çœ‹åŸæ–‡å³å¯.\nè®ºæ–‡å¤ç°\nGeneratorï¼š\nè¾“å…¥64x64x3å›¾åƒï¼Œè¾“å‡º64x64x3ç”Ÿæˆå›¾åƒ\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n \n        def conv_block(in_channels, out_channels, kernel_size, stride&#x3D;1,\n                 padding&#x3D;0, bn&#x3D;True, a_func&#x3D;&#39;lrelu&#39;):\n \n            block &#x3D; nn.ModuleList()\n            block.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n            if bn:\n                block.append(nn.BatchNorm2d(out_channels))\n            if a_func &#x3D;&#x3D; &#39;lrelu&#39;:\n                block.append(nn.LeakyReLU(0.2))\n            elif a_func &#x3D;&#x3D; &#39;relu&#39;:\n                block.append(nn.ReLU())\n            else:\n                pass\n \n            return block\n \n        def convTranspose_block(in_channels, out_channels, kernel_size, stride&#x3D;2,\n                 padding&#x3D;0, output_padding&#x3D;0, bn&#x3D;True, a_func&#x3D;&#39;relu&#39;):\n            &#39;&#39;&#39;\n            H_out &#x3D; (H_in - 1) * stride - 2 * padding + kernel_size + output_padding\n            :param in_channels:\n            :param out_channels:\n            :param kernel_size:\n            :param stride:\n            :param padding:\n            :param output_padding:\n            :param bn:\n            :param a_func:\n            :return:\n            &#39;&#39;&#39;\n            block &#x3D; nn.ModuleList()\n            block.append(nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride,\n                 padding, output_padding))\n            if bn:\n                block.append(nn.BatchNorm2d(out_channels))\n            if a_func &#x3D;&#x3D; &#39;lrelu&#39;:\n                block.append(nn.LeakyReLU(0.2))\n            elif a_func &#x3D;&#x3D; &#39;relu&#39;:\n                block.append(nn.ReLU())\n            else:\n                pass\n \n            return block\n \n \n        def encoder():\n            conv_layer &#x3D; nn.ModuleList()\n            conv_layer +&#x3D; conv_block(3, 128, 5, 2, 2, False)    # 32x32x128\n            conv_layer +&#x3D; conv_block(128, 256, 5, 2, 2)        # 16x16x256\n            conv_layer +&#x3D; conv_block(256, 512, 5, 2, 2)         # 8x8x512\n            conv_layer +&#x3D; conv_block(512, 1024, 5, 2, 2)       # 4x4x1024\n            conv_layer +&#x3D; conv_block(1024, 64, 4, 1)          # 1x1x64\n            return conv_layer\n \n        def decoder():\n            conv_layer &#x3D; nn.ModuleList()\n            conv_layer +&#x3D; conv_block(64, 4 * 4 * 1024, 1, a_func&#x3D;&#39;relu&#39;)\n            conv_layer.append(Reshape((1024, 4, 4)))                            # 4x4x1024\n            conv_layer +&#x3D; convTranspose_block(1024, 512, 4, 2, 1)               # 8x8x512\n            conv_layer +&#x3D; convTranspose_block(512, 256, 4, 2, 1)                # 16x16x256\n            conv_layer +&#x3D; convTranspose_block(256, 128, 4, 2, 1)                # 32x32x128\n            conv_layer +&#x3D; convTranspose_block(128, 3, 4, 2, 1, bn&#x3D;False, a_func&#x3D;&#39;&#39;)     # 64x64x3\n            conv_layer.append(nn.Tanh())\n            return conv_layer\n \n        self.net &#x3D; nn.Sequential(\n            *encoder(),\n            *decoder(),\n        )\n \n    def forward(self, input):\n        out &#x3D; self.net(input)\n        return out\nDiscriminatorR\nè¾“å…¥64x64x3å›¾åƒï¼Œè¾“å‡ºreal or fakeï¼›\nclass DiscriminatorR(nn.Module):\n    def __init__(self):\n        super(DiscriminatorR, self).__init__()\n \n        def conv_block(in_channels, out_channels, kernel_size, stride&#x3D;1,\n                       padding&#x3D;0, bn&#x3D;True, a_func&#x3D;True):\n \n            block &#x3D; nn.ModuleList()\n            block.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n            if bn:\n                block.append(nn.BatchNorm2d(out_channels))\n            if a_func:\n                block.append(nn.LeakyReLU(0.2))\n \n            return block\n \n \n        self.net &#x3D; nn.Sequential(\n            *conv_block(3, 128, 5, 2, 2, False),                            # 32x32x128\n            *conv_block(128, 256, 5, 2, 2),                                 # 16x16x256\n            *conv_block(256, 512, 5, 2, 2),                                 # 8x8x512\n            *conv_block(512, 1024, 5, 2, 2),                                # 4x4x1024\n            *conv_block(1024, 1, 4, bn&#x3D;False, a_func&#x3D;False),                # 1x1x1\n            nn.Sigmoid(),\n        )\n \n    def forward(self, img):\n        out &#x3D; self.net(img)\n        return out\nDiscriminatorA\nè¾“å…¥64x64x6çš„concatå›¾åƒï¼Œè¾“å‡ºreal or fakeï¼›\nclass DiscriminatorA(nn.Module):\n    def __init__(self):\n        super(DiscriminatorA, self).__init__()\n \n        def conv_block(in_channels, out_channels, kernel_size, stride&#x3D;1,\n                       padding&#x3D;0, bn&#x3D;True, a_func&#x3D;True):\n \n            block &#x3D; nn.ModuleList()\n            block.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding))\n            if bn:\n                block.append(nn.BatchNorm2d(out_channels))\n            if a_func:\n                block.append(nn.LeakyReLU(0.2))\n \n            return block\n \n        self.net &#x3D; nn.Sequential(\n            *conv_block(6, 128, 5, 2, 2, False),                # 32x32x128\n            *conv_block(128, 256, 5, 2, 2),                     # 16x16x256\n            *conv_block(256, 512, 5, 2, 2),                     # 8x8x512\n            *conv_block(512, 1024, 5, 2, 2),                    # 4x4x1024\n            *conv_block(1024, 1, 4, bn&#x3D;False, a_func&#x3D;False),    # 1x1x1\n            nn.Sigmoid(),\n        )\n \n    def forward(self, img):\n        out &#x3D; self.net(img)\n        return out\nloss\nä¸åŸæ–‡ä¸åŒï¼Œåœ¨ç”ŸæˆæŸå¤±ä¸ŠåŠ äº†mse\ngen_loss_d &#x3D; self.adversarial_loss(torch.squeeze(gen_output), real_label)\ngen_loss_a &#x3D; self.adversarial_loss(torch.squeeze(gen_output_a), real_label)\nmse_loss &#x3D; self.mse_loss(gen_target_batch, target_batch)\nå®Œæ•´è®­ç»ƒæµ‹è¯•ä»£ç ï¼šGitHub\nç»“æœ\ntensorboard\n\nè®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–\n\néªŒè¯é›†\n\n","slug":"Pixel-Level-Domain-Transferè®ºæ–‡å¤ç°","date":"2021-09-06T11:51:46.000Z","categories_index":"","tags_index":"csdnè¿ç§»","author_index":"Hulk Wang"},{"id":"260edd383abab8c5258536a42ddb3e2a","title":"YOLO-V4å­¦ä¹ ç¬”è®°","content":"YOLO-V4å­¦ä¹ ç¬”è®°\n\n\n\n\n\n\n\n\n\nçŸ¥è¯†ç‚¹æ¥æºäºç½‘ç»œï¼Œä»…è®°å½•å­¦ä¹  æ¥æºï¼šhttps://zhuanlan.zhihu.com/p/143747206\nç½‘ç»œç»“æ„\n\n\nç½‘ç»œç»“æ„(æ¥æºè§æ°´å°)\n\näº”ä¸ªåŸºæœ¬ç»„ä»¶: 1. CBMï¼šYolov4ç½‘ç»œç»“æ„ä¸­çš„æœ€å°ç»„ä»¶ï¼Œç”±Conv+Bn+Mishæ¿€æ´»å‡½æ•°ä¸‰è€…ç»„æˆã€‚ 2. CBLï¼šç”±Conv+Bn+Leaky_reluæ¿€æ´»å‡½æ•°ä¸‰è€…ç»„æˆã€‚ 3. Res unitï¼šå€Ÿé‰´Resnetç½‘ç»œä¸­çš„æ®‹å·®ç»“æ„ï¼Œè®©ç½‘ç»œå¯ä»¥æ„å»ºçš„æ›´æ·±ã€‚ 4. CSPXï¼šå€Ÿé‰´CSPNetç½‘ç»œç»“æ„ï¼Œç”±å·ç§¯å±‚å’ŒXä¸ªRes unintæ¨¡å—Concateç»„æˆã€‚ 5. SPPï¼šé‡‡ç”¨1Ã—1ï¼Œ5Ã—5ï¼Œ9Ã—9ï¼Œ13Ã—13çš„æœ€å¤§æ± åŒ–çš„æ–¹å¼ï¼Œè¿›è¡Œå¤šå°ºåº¦èåˆã€‚\n\n\nObject detector\n\nå¦‚ä¸Šå›¾ï¼Œå¤§è‡´åˆ†ä¸ºå››ä¸ªé˜¶æ®µç†è§£yolov4ï¼Œåˆ†åˆ«ä¸ºè¾“å…¥ç«¯ã€backboneã€Neckä»¥åŠPredictionã€‚\nè¾“å…¥ç«¯\nMosaicæ•°æ®å¢å¼º\nYolov4ä¸­ä½¿ç”¨çš„Mosaicæ˜¯å‚è€ƒ2019å¹´åº•æå‡ºçš„CutMixæ•°æ®å¢å¼ºçš„æ–¹å¼ï¼Œä½†CutMixåªä½¿ç”¨äº†ä¸¤å¼ å›¾ç‰‡è¿›è¡Œæ‹¼æ¥ï¼Œè€ŒMosaicæ•°æ®å¢å¼ºåˆ™é‡‡ç”¨äº†4å¼ å›¾ç‰‡ï¼Œéšæœºç¼©æ”¾ã€éšæœºè£å‰ªã€éšæœºæ’å¸ƒçš„æ–¹å¼è¿›è¡Œæ‹¼æ¥ã€‚\n\nä¸ºä»€ä¹ˆè¦è¿›è¡ŒMosaicæ•°æ®å¢å¼º?\n\n\n\n\n\n\n\n\n\nåœ¨å¹³æ—¶é¡¹ç›®è®­ç»ƒæ—¶ï¼Œå°ç›®æ ‡çš„APä¸€èˆ¬æ¯”ä¸­ç›®æ ‡å’Œå¤§ç›®æ ‡ä½å¾ˆå¤šã€‚è€ŒCocoæ•°æ®é›†ä¸­ä¹ŸåŒ…å«å¤§é‡çš„å°ç›®æ ‡ï¼Œä½†æ¯”è¾ƒéº»çƒ¦çš„æ˜¯å°ç›®æ ‡çš„åˆ†å¸ƒå¹¶ä¸å‡åŒ€ã€‚\né¦–å…ˆçœ‹ä¸‹å°ã€ä¸­ã€å¤§ç›®æ ‡çš„å®šä¹‰ï¼š 2019å¹´å‘å¸ƒçš„è®ºæ–‡ã€ŠAugmentation for small object detectionã€‹å¯¹æ­¤è¿›è¡Œäº†åŒºåˆ†:\n\n\n\n\næœ€å°çŸ©å½¢åŒºåŸŸé¢ç§¯\næœ€å¤§çŸ©å½¢åŒºåŸŸé¢ç§¯\n\n\n\n\nå°ç›®æ ‡\n0 * 0\n32 * 32\n\n\nä¸­ç›®æ ‡\n32 * 32\n96 * 96\n\n\nå¤§ç›®æ ‡\n96 * 96\nâˆ * âˆ\n\n\n\n\n\n\n\n\n\n\n\n\nå¯ä»¥çœ‹åˆ°å°ç›®æ ‡çš„å®šä¹‰æ˜¯ç›®æ ‡æ¡†çš„é•¿å®½0Ã—0~32Ã—32ä¹‹é—´çš„ç‰©ä½“ã€‚\n\n\n\n\nå°\nä¸­\nå¤§\n\n\n\n\næ•°æ®é›†ä¸­å°ç›®æ ‡å æ¯”\n41.4%\n34.3%\n24.3%\n\n\næ•°æ®é›†å›¾ç‰‡åŒ…å«å æ¯”\n52.3%\n70.7%\n83.0%\n\n\n\nä½†åœ¨æ•´ä½“çš„æ•°æ®é›†ä¸­ï¼Œå°ã€ä¸­ã€å¤§ç›®æ ‡çš„å æ¯”å¹¶ä¸å‡è¡¡ã€‚ å¦‚ä¸Šè¡¨æ‰€ç¤ºï¼ŒCocoæ•°æ®é›†ä¸­å°ç›®æ ‡å æ¯”è¾¾åˆ°41.4%ï¼Œæ•°é‡æ¯”ä¸­ç›®æ ‡å’Œå¤§ç›®æ ‡éƒ½è¦å¤šã€‚\nä½†åœ¨æ‰€æœ‰çš„è®­ç»ƒé›†å›¾ç‰‡ä¸­ï¼Œåªæœ‰52.3%çš„å›¾ç‰‡æœ‰å°ç›®æ ‡ï¼Œè€Œä¸­ç›®æ ‡å’Œå¤§ç›®æ ‡çš„åˆ†å¸ƒç›¸å¯¹æ¥è¯´æ›´åŠ å‡åŒ€ä¸€äº›ã€‚\né’ˆå¯¹è¿™ç§çŠ¶å†µï¼ŒYolov4çš„ä½œè€…é‡‡ç”¨äº†Mosaicæ•°æ®å¢å¼ºçš„æ–¹å¼ã€‚\nä¸»è¦æœ‰å‡ ä¸ªä¼˜ç‚¹ï¼š\n\nä¸°å¯Œæ•°æ®é›†ï¼šéšæœºä½¿ç”¨4å¼ å›¾ç‰‡ï¼Œéšæœºç¼©æ”¾ï¼Œå†éšæœºåˆ†å¸ƒè¿›è¡Œæ‹¼æ¥ï¼Œä¸°å¯Œäº†å›¾ç‰‡çš„èƒŒæ™¯ï¼Œå¤§å¤§ä¸°å¯Œäº†æ£€æµ‹æ•°æ®é›†ï¼Œç‰¹åˆ«æ˜¯éšæœºç¼©æ”¾å¢åŠ äº†å¾ˆå¤šå°ç›®æ ‡ï¼Œè®©ç½‘ç»œçš„é²æ£’æ€§æ›´å¥½ã€‚\nå‡å°‘GPUï¼šå››å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€èµ·å˜ç›¸åœ°æé«˜äº†batch_sizeï¼Œåœ¨è¿›è¡Œbatch normalizationçš„æ—¶å€™ä¹Ÿä¼šè®¡ç®—å››å¼ å›¾ç‰‡ï¼Œæ‰€ä»¥å¯¹æœ¬èº«batch_sizeä¸æ˜¯å¾ˆä¾èµ–ï¼Œå•å—GPUå°±å¯ä»¥è®­ç»ƒYOLOV4ã€‚\n\n\n\n\n\n\n\n\n\n\næœ€åè¯´æ˜ä¸€ä¸‹å¯¹äºæ ‡ç­¾æ¡†çš„å¤„ç†ï¼Œå½“è¿›è¡Œè£å‰ªçš„æ—¶å€™ï¼Œå¦‚æœè£å‰ªäº†æ ·æœ¬å½“ä¸­çš„æ ‡ç­¾æ¡†çš„éƒ¨åˆ†åŒºåŸŸï¼Œåˆ™å°†å…¶èˆå¼ƒï¼Œä¿ç•™è£å‰ªä¹‹åè¿˜å®Œæ•´çš„æ ‡ç­¾æ¡†ã€‚\nå‚è€ƒ\nä¸å…¶ä»–å¢å¼ºæ–¹æ³•å¯¹æ¯”\n\nMixup:å°†éšæœºçš„ä¸¤å¼ æ ·æœ¬æŒ‰æ¯”ä¾‹æ··åˆï¼Œåˆ†ç±»çš„ç»“æœæŒ‰æ¯”ä¾‹åˆ†é…ï¼›\nCutout:éšæœºçš„å°†æ ·æœ¬ä¸­çš„éƒ¨åˆ†åŒºåŸŸcutæ‰ï¼Œå¹¶ä¸”å¡«å……0åƒç´ å€¼ï¼Œåˆ†ç±»çš„ç»“æœä¸å˜ï¼›\nCutMix:å°±æ˜¯å°†ä¸€éƒ¨åˆ†åŒºåŸŸcutæ‰ä½†ä¸å¡«å……0åƒç´ è€Œæ˜¯éšæœºå¡«å……è®­ç»ƒé›†ä¸­çš„å…¶ä»–æ•°æ®çš„åŒºåŸŸåƒç´ å€¼ï¼Œåˆ†ç±»ç»“æœæŒ‰ä¸€å®šçš„æ¯”ä¾‹åˆ†é…\n\n\nä¸Šè¿°ä¸‰ç§æ•°æ®å¢å¼ºçš„åŒºåˆ«ï¼š 1. cutoutå’Œcutmixå°±æ˜¯å¡«å……åŒºåŸŸåƒç´ å€¼çš„åŒºåˆ«; 2. mixupå’Œcutmixæ˜¯æ··åˆä¸¤ç§æ ·æœ¬æ–¹å¼ä¸Šçš„åŒºåˆ«; 3. mixupæ˜¯å°†ä¸¤å¼ å›¾æŒ‰æ¯”ä¾‹è¿›è¡Œæ’å€¼æ¥æ··åˆæ ·æœ¬ï¼Œcutmixæ˜¯é‡‡ç”¨cutéƒ¨åˆ†åŒºåŸŸå†è¡¥ä¸çš„å½¢å¼å»æ··åˆå›¾åƒï¼Œä¸ä¼šæœ‰å›¾åƒæ··åˆåä¸è‡ªç„¶çš„æƒ…å½¢ã€‚\nå‚è€ƒ\nBackBone\nCSPDarknet53\n\n\n\n\n\n\n\n\n\nCSPDarknet53æ˜¯åœ¨Yolov3ä¸»å¹²ç½‘ç»œDarknet53çš„åŸºç¡€ä¸Šï¼Œå€Ÿé‰´2019å¹´CSPNetçš„ç»éªŒï¼Œäº§ç”Ÿçš„Backboneç»“æ„ã€‚å› ä¸ºBackboneæœ‰5ä¸ªCSPæ¨¡å—ï¼ˆè§ç½‘ç»œç»“æ„ï¼‰ï¼Œè¾“å…¥å›¾åƒæ˜¯608 * 608ï¼Œæ‰€ä»¥ç‰¹å¾å›¾å˜åŒ–çš„è§„å¾‹æ˜¯ï¼š608-&gt;304-&gt;152-&gt;76-&gt;38-&gt;19ã€‚ç»è¿‡5æ¬¡CSPæ¨¡å—åå¾—åˆ°19*19å¤§å°çš„ç‰¹å¾å›¾ã€‚ è€Œä¸”ä½œè€…åªåœ¨Backboneä¸­é‡‡ç”¨äº†Mishæ¿€æ´»å‡½æ•°ï¼Œç½‘ç»œåé¢ä»ç„¶é‡‡ç”¨Leaky_reluæ¿€æ´»å‡½æ•°ã€‚\nCSPNet\nè®ºæ–‡åœ°å€\nCSPNetå…¨ç§°æ˜¯Cross Stage Paritial Networkï¼Œä¸»è¦ä»ç½‘ç»œç»“æ„è®¾è®¡çš„è§’åº¦è§£å†³æ¨ç†ä¸­ä»è®¡ç®—é‡å¾ˆå¤§çš„é—®é¢˜ã€‚\nè®¾è®¡CSPNetçš„ä¸»è¦ç›®çš„æ˜¯ä½¿è¯¥ä½“ç³»ç»“æ„èƒ½å¤Ÿå®ç°æ›´ä¸°å¯Œçš„æ¢¯åº¦ç»„åˆä¿¡æ¯ï¼ŒåŒæ—¶å‡å°‘è®¡ç®—é‡ã€‚ é€šè¿‡å°†åŸºç¡€å±‚çš„ç‰¹å¾å›¾åˆ’åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œç„¶åé€šè¿‡æå‡ºçš„è·¨é˜¶æ®µå±‚æ¬¡ç»“æ„å°†å®ƒä»¬åˆå¹¶ï¼Œå¯ä»¥å®ç°æ­¤ç›®æ ‡ã€‚\nCSPNetçš„ä½œè€…è®¤ä¸ºæ¨ç†è®¡ç®—è¿‡é«˜çš„é—®é¢˜æ˜¯ç”±äºç½‘ç»œä¼˜åŒ–ä¸­çš„æ¢¯åº¦ä¿¡æ¯é‡å¤å¯¼è‡´çš„ã€‚\nå› æ­¤é‡‡ç”¨CSPæ¨¡å—å…ˆå°†åŸºç¡€å±‚çš„ç‰¹å¾æ˜ å°„åˆ’åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œç„¶åé€šè¿‡è·¨é˜¶æ®µå±‚æ¬¡ç»“æ„å°†å®ƒä»¬åˆå¹¶ï¼Œåœ¨å‡å°‘äº†è®¡ç®—é‡çš„åŒæ—¶å¯ä»¥ä¿è¯å‡†ç¡®ç‡ã€‚\nå› æ­¤Yolov4åœ¨ä¸»å¹²ç½‘ç»œBackboneé‡‡ç”¨CSPDarknet53ç½‘ç»œç»“æ„ï¼Œä¸»è¦æœ‰ä¸‰ä¸ªæ–¹é¢çš„ä¼˜ç‚¹ï¼š\n\nå¢å¼ºCNNçš„å­¦ä¹ èƒ½åŠ›ï¼Œä½¿å¾—åœ¨è½»é‡åŒ–çš„åŒæ—¶ä¿æŒå‡†ç¡®æ€§\né™ä½è®¡ç®—ç“¶é¢ˆ\né™ä½å†…å­˜æˆæœ¬\n\nè®ºæ–‡æ–¹æ³•\n\nå¦‚ä¸Šå›¾(a), DenseNetçš„æ¯ä¸ªé˜¶æ®µå‡åŒ…å«ä¸€ä¸ªdense block(å¯†é›†è¿æ¥å±‚)å’Œtransition layer(è¿‡æ¸¡å±‚)ï¼ŒåŒæ—¶ï¼Œæ¯ä¸ªdense blockç”±Kä¸ªå¯†é›†å±‚è¿æ¥ã€‚ç¬¬ä¸ªå¯†é›†å±‚çš„è¾“å‡ºå°†ä¼šåŒç¬¬ä¸ªå¯†é›†å±‚çš„è¾“å…¥ç›¸è¿æ¥ï¼ŒåŒæ—¶æ‹¼æ¥åçš„è¾“å‡ºç»“æœä½œä¸ºä¸ªå¯†é›†å±‚çš„è¾“å…¥ï¼Œç­‰å¼è¡¨ç¤ºå¦‚ä¸‹æ‰€ç¤ºï¼š\n\nå¦‚æœä½¿ç”¨åå‘ä¼ æ’­ç®—æ³•æ›´æ–°æƒé‡ï¼Œåˆ™æƒé‡æ›´æ–°æ–¹ç¨‹å¯å†™ä¸ºï¼š\n\nå…¶ä¸­fæ˜¯æƒé‡æ›´æ–°çš„å‡½æ•°ï¼Œè¡¨ç¤ºä¼ æ’­åˆ°ç¬¬ä¸ªå¯†é›†å±‚çš„æ¢¯åº¦ã€‚ ä½œè€…å‘ç°å¤§é‡é‡å¤çš„æ¢¯åº¦ä¿¡æ¯è¢«ç”¨æ¥æ›´æ–°ä¸åŒå¯†é›†å±‚çš„æƒé‡ã€‚ è¿™å°†å¯¼è‡´ä¸åŒçš„å¯†é›†å±‚é‡å¤å­¦ä¹ å¤åˆ¶çš„æ¢¯åº¦ä¿¡æ¯ã€‚\nå¦‚ä¸Šå›¾(b),æ”¹è¿›ç‚¹åœ¨äºCSPNetå°†æµ…å±‚ç‰¹å¾æ˜ å°„ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ç»è¿‡Denseæ¨¡å—ï¼ˆå›¾ä¸­çš„Partial Dense Blockï¼‰,å¦ä¸€éƒ¨åˆ†ç›´æ¥ä¸Partial Dense Blockè¾“å‡ºè¿›è¡Œconcateã€‚CSPDenseNetçš„å‰é¦ˆä¼ é€’å’Œæƒé‡æ›´æ–°çš„æ–¹ç¨‹å¼åˆ†åˆ«æ˜¾ç¤ºå¦‚ä¸‹ï¼š\n\n\næ€»ä½“è€Œè¨€ï¼ŒCSPDenseNetä¿ç•™äº†DenseNetçš„ç‰¹å¾é‡ç”¨ç‰¹æ€§çš„ä¼˜ç‚¹ï¼Œä½†åŒæ—¶é€šè¿‡æˆªæ–­æ¢¯åº¦æµï¼Œé˜²æ­¢äº†è¿‡å¤šçš„æ¢¯åº¦ä¿¡æ¯é‡å¤ã€‚ é€šè¿‡è®¾è®¡åˆ†å±‚ç‰¹å¾èåˆç­–ç•¥æ¥å®ç°æ­¤æ€æƒ³ï¼Œå¹¶å°†å…¶ç”¨äºéƒ¨åˆ†è¿‡æ¸¡å±‚ã€‚\nä½œè€…ä¹Ÿè®¾è®¡äº†å‡ ç§ç‰¹å¾èåˆçš„ç­–ç•¥ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š \nFustion Firstçš„æ–¹å¼æ˜¯å¯¹ä¸¤ä¸ªåˆ†æ”¯çš„feature mapå…ˆè¿›è¡Œconcatenationæ“ä½œï¼Œè¿™æ ·æ¢¯åº¦ä¿¡æ¯å¯ä»¥è¢«é‡ç”¨ã€‚ Fusion Lastçš„æ–¹å¼æ˜¯å¯¹Dense Blockæ‰€åœ¨åˆ†æ”¯å…ˆè¿›æ€§transitionæ“ä½œï¼Œç„¶åå†è¿›è¡Œconcatenationï¼Œ æ¢¯åº¦ä¿¡æ¯å°†è¢«æˆªæ–­ï¼Œå› æ­¤ä¸ä¼šé‡å¤ä½¿ç”¨æ¢¯åº¦ä¿¡æ¯ ã€‚\n\n\n\n\n\n\n\n\n\næ‰€ä»¥CSP-DarkNetåˆ°åº•æ˜¯æ€ä¹ˆå€Ÿé‰´CSPNetçš„ï¼Ÿ å¦‚æœæŒ‰ç…§CSPNetçš„æ€æƒ³ï¼Œé‚£ç‰¹å¾è¾“å…¥åº”è¯¥æŒ‰ä¸€å®šæ¯”ä¾‹åˆ†ä¸ºä¸¤è·¯ï¼Œåˆ†åˆ«ç»è¿‡Part1å’ŒPart2åconcatï¼Œæ¯”å¦‚ä¸‹å›¾è¿™æ ·ï¼š\n\n\næ¥æºè§æ°´å°\n\n\n\n\n\n\n\n\n\n\nä½†å®é™…CSP-DarkNetæ²¡æœ‰åšsplitæ“ä½œï¼ŒPart1å’ŒPart2è¾“å…¥çš„æ˜¯å…¨éƒ¨ç‰¹å¾ï¼Œå¦‚ä¸‹å›¾ï¼š\n\n\næ¥æºè§æ°´å°\n\n\n\n\n\n\n\n\n\n\nç›´æ¥ç”¨ä¸¤è·¯çš„1x1å·ç§¯å°†è¾“å…¥ç‰¹å¾è¿›è¡Œå˜æ¢ã€‚ å¯ä»¥ç†è§£çš„æ˜¯ï¼Œå°†å…¨éƒ¨çš„è¾“å…¥ç‰¹å¾åˆ©ç”¨ä¸¤è·¯1x1è¿›è¡Œtransitionï¼Œæ¯”ç›´æ¥åˆ’åˆ†é€šé“èƒ½å¤Ÿè¿›ä¸€æ­¥æé«˜ç‰¹å¾çš„é‡ç”¨æ€§ï¼Œå¹¶ä¸”åœ¨è¾“å…¥åˆ°resiudal blockä¹‹å‰ä¹Ÿç¡®å®é€šé“å‡åŠï¼Œå‡å°‘äº†è®¡ç®—é‡ã€‚\nå‚è€ƒæ¥æº ##### Mishæ¿€æ´»å‡½æ•°\nè®ºæ–‡åœ°å€\n\n\nMishæ›²çº¿\n\ny = x * tanh(ln(1+exp(x)))\n\n\n\n\n\n\n\n\n\nä¸€ç§è‡ªæ­£åˆ™çš„éå•è°ƒç¥ç»æ¿€æ´»å‡½æ•°ï¼Œå¹³æ»‘çš„æ¿€æ´»å‡½æ•°å…è®¸æ›´å¥½çš„ä¿¡æ¯æ·±å…¥ç¥ç»ç½‘ç»œï¼Œä»è€Œå¾—åˆ°æ›´å¥½çš„å‡†ç¡®æ€§å’Œæ³›åŒ–ã€‚è®ºæ–‡ä¸­æå‡ºï¼Œç›¸æ¯”Swishæœ‰0.494%çš„æå‡ï¼Œç›¸æ¯”ReLUæœ‰1.671%çš„æå‡ã€‚\n\n\n\n\n\n\n\n\n\nYolov4çš„Backboneä¸­éƒ½ä½¿ç”¨äº†Mishæ¿€æ´»å‡½æ•°ï¼Œè€Œåé¢çš„ç½‘ç»œåˆ™è¿˜æ˜¯ä½¿ç”¨leaky_reluå‡½æ•°ã€‚\nä¼˜ç‚¹ï¼š\n\nä»¥ä¸Šæ— è¾¹ç•Œ(å³æ­£å€¼å¯ä»¥è¾¾åˆ°ä»»ä½•é«˜åº¦)é¿å…äº†ç”±äºå°é¡¶è€Œå¯¼è‡´çš„é¥±å’Œã€‚2. ç†è®ºä¸Šå¯¹è´Ÿå€¼çš„è½»å¾®å…è®¸å¯ä»¥äº§ç”Ÿæ›´å¥½çš„æ¢¯åº¦æµï¼Œè€Œä¸æ˜¯åƒReLUä¸­é‚£æ ·çš„ç¡¬é›¶è¾¹ç•Œã€‚\nå¹³æ»‘çš„æ¿€æ´»å‡½æ•°å…è®¸æ›´å¥½çš„ä¿¡æ¯æ·±å…¥ç¥ç»ç½‘ç»œï¼Œä»è€Œå¾—åˆ°æ›´å¥½çš„å‡†ç¡®æ€§å’Œæ³›åŒ–ã€‚\n\næ›´å¹³æ»‘çš„æ¿€æ´»å‡½æ•°å…è®¸ä¿¡æ¯æ›´æ·±å…¥åœ°æµåŠ¨\nç¼ºç‚¹ï¼š\n\nè®¡ç®—é‡è‚¯å®šæ¯”reluå¤§ï¼Œå ç”¨çš„å†…å­˜ä¹Ÿå¤šäº†ä¸å°‘ï¼›\n\npytorchå®ç°\n\nDropblock\nè®ºæ–‡åœ°å€\n\n\n\n\n\n\n\n\n\nYolov4ä¸­ä½¿ç”¨çš„Dropblockï¼Œå…¶å®å’Œå¸¸è§ç½‘ç»œä¸­çš„DropoutåŠŸèƒ½ç±»ä¼¼ï¼Œä¹Ÿæ˜¯ç¼“è§£è¿‡æ‹Ÿåˆçš„ä¸€ç§æ­£åˆ™åŒ–æ–¹å¼ã€‚\ndropoutæ–¹æ³•å¤šæ˜¯ä½œç”¨åœ¨å…¨è¿æ¥å±‚ä¸Šï¼Œåœ¨å·ç§¯å±‚åº”ç”¨dropoutæ–¹æ³•æ„ä¹‰ä¸å¤§ã€‚æ–‡ç« è®¤ä¸ºæ˜¯å› ä¸ºæ¯ä¸ªfeature mapçš„ä½ç½®éƒ½æœ‰ä¸€ä¸ªæ„Ÿå—é‡èŒƒå›´ï¼Œä»…ä»…å¯¹å•ä¸ªåƒç´ ä½ç½®è¿›è¡Œdropoutå¹¶ä¸èƒ½é™ä½feature mapå­¦ä¹ çš„ç‰¹å¾èŒƒå›´ï¼Œä¹Ÿå°±æ˜¯è¯´ç½‘ç»œä»å¯ä»¥é€šè¿‡è¯¥ä½ç½®çš„ç›¸é‚»ä½ç½®å…ƒç´ å»å­¦ä¹ å¯¹åº”çš„è¯­ä¹‰ä¿¡æ¯ï¼Œä¹Ÿå°±ä¸ä¼šä¿ƒä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ã€‚ æ—¢ç„¶å•ç‹¬çš„å¯¹æ¯ä¸ªä½ç½®è¿›è¡Œdropoutå¹¶ä¸èƒ½æé«˜ç½‘ç»œçš„æ³›åŒ–èƒ½åŠ›ï¼Œé‚£ä¹ˆå¾ˆè‡ªç„¶çš„ï¼Œå¦‚æœæˆ‘ä»¬æŒ‰ç…§ä¸€å—ä¸€å—çš„å»dropoutï¼Œå°±è‡ªç„¶å¯ä»¥ä¿ƒä½¿ç½‘ç»œå»å­¦ä¹ æ›´åŠ é²æ£’çš„ç‰¹å¾ã€‚æ€è·¯å¾ˆç®€å•ï¼Œå°±æ˜¯åœ¨feature mapä¸Šå»ä¸€å—ä¸€å—çš„æ‰¾ï¼Œè¿›è¡Œå½’é›¶æ“ä½œï¼Œç±»ä¼¼äºdropoutï¼Œå«åšdropblockã€‚\n\n\nç»¿è‰²é˜´å½±åŒºåŸŸæ˜¯è¯­ä¹‰ç‰¹å¾ï¼Œbå›¾æ˜¯æ¨¡æ‹Ÿdropoutçš„åšæ³•ï¼Œéšæœºä¸¢å¼ƒä¸€äº›ä½ç½®çš„ç‰¹å¾,(c)æ˜¯dropblock\n\n\ndropblockæœ‰ä¸‰ä¸ªæ¯”è¾ƒé‡è¦çš„å‚æ•°ï¼Œä¸€ä¸ªæ˜¯block_sizeï¼Œç”¨æ¥æ§åˆ¶è¿›è¡Œå½’é›¶çš„blockå¤§å°ï¼›ä¸€ä¸ªæ˜¯Î³ï¼Œç”¨æ¥æ§åˆ¶æ¯ä¸ªå·ç§¯ç»“æœä¸­ï¼Œåˆ°åº•æœ‰å¤šå°‘ä¸ªchannelè¦è¿›è¡Œdropblockï¼›æœ€åä¸€ä¸ªæ˜¯keep_probï¼Œä½œç”¨å’Œdropouté‡Œçš„å‚æ•°ä¸€æ ·ã€‚\nMå¤§å°å’Œè¾“å‡ºç‰¹å¾å›¾å¤§å°ä¸€è‡´ï¼Œé0å³1ï¼Œä¸ºäº†ä¿è¯è®­ç»ƒå’Œæµ‹è¯•ä¸€è‡´ï¼Œéœ€è¦å’Œdropoutä¸€æ ·ï¼Œè¿›è¡Œrescaleã€‚\nä¸Šè¿°æ˜¯ç†è®ºåˆ†æï¼Œåœ¨åšå®éªŒæ—¶å€™å‘ç°ï¼Œ**block_sizeæ§åˆ¶ä¸º7*7æ•ˆæœæœ€å¥½**ï¼Œå¯¹äºæ‰€æœ‰çš„feature mapéƒ½ä¸€æ ·ï¼ŒÎ³é€šè¿‡ä¸€ä¸ªå…¬å¼æ¥æ§åˆ¶ï¼Œkeep_probåˆ™æ˜¯ä¸€ä¸ªçº¿æ€§è¡°å‡è¿‡ç¨‹ï¼Œä»æœ€åˆçš„1åˆ°è®¾å®šçš„é˜ˆå€¼(å…·ä½“å®ç°æ˜¯dropoutç‡ä»0å¢åŠ åˆ°æŒ‡å®šå€¼ä¸ºæ­¢)ï¼Œè®ºæ–‡é€šè¿‡å®éªŒè¡¨æ˜è¿™ç§æ–¹æ³•æ•ˆæœæœ€å¥½ã€‚å¦‚æœå›ºå®šprobæ•ˆæœå¥½åƒä¸å¥½ã€‚ å®è·µä¸­ï¼Œå¹¶æ²¡æœ‰æ˜¾å¼çš„è®¾ç½®Î³çš„å€¼ï¼Œè€Œæ˜¯æ ¹æ®keep_prob(å…·ä½“å®ç°æ˜¯åçš„ï¼Œæ˜¯ä¸¢å¼ƒæ¦‚ç‡)æ¥è°ƒæ•´ã€‚\nNeck\n\n\n\n\n\n\n\n\n\nåœ¨ç›®æ ‡æ£€æµ‹é¢†åŸŸï¼Œä¸ºäº†æ›´å¥½çš„æå–èåˆç‰¹å¾ï¼Œé€šå¸¸åœ¨Backboneå’Œè¾“å‡ºå±‚ï¼Œä¼šæ’å…¥ä¸€äº›å±‚ï¼Œè¿™ä¸ªéƒ¨åˆ†ç§°ä¸ºNeckã€‚ç›¸å½“äºç›®æ ‡æ£€æµ‹ç½‘ç»œçš„é¢ˆéƒ¨ï¼Œä¹Ÿæ˜¯éå¸¸å…³é”®çš„ã€‚\nYolov4çš„Neckç»“æ„ä¸»è¦é‡‡ç”¨äº†SPPæ¨¡å—ã€FPN+PANçš„æ–¹å¼ã€‚\nSPPæ¨¡å—\n\nä½œè€…åœ¨SPPæ¨¡å—ä¸­ï¼Œä½¿ç”¨k={1 * 1,5 * 5,9 * 9,13 * 13}çš„æœ€å¤§æ± åŒ–çš„æ–¹å¼ï¼Œå†å°†ä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾è¿›è¡ŒConcatæ“ä½œã€‚\n\n\n\n\n\n\n\n\n\né‡‡ç”¨SPPæ¨¡å—çš„æ–¹å¼ï¼Œæ¯”å•çº¯çš„ä½¿ç”¨k*kæœ€å¤§æ± åŒ–çš„æ–¹å¼ï¼Œæ›´æœ‰æ•ˆçš„å¢åŠ ä¸»å¹²ç‰¹å¾çš„æ¥æ”¶èŒƒå›´ï¼Œæ˜¾è‘—çš„åˆ†ç¦»äº†æœ€é‡è¦çš„ä¸Šä¸‹æ–‡ç‰¹å¾\nFPN+PAN\nè®ºæ–‡åœ°å€\n\n\n\n\n\n\n\n\n\nPath Aggregation Network(PANet)ï¼Œæ—¨åœ¨æå‡åŸºäºä¾¯é€‰åŒºåŸŸçš„å®ä¾‹åˆ†å‰²æ¡†æ¶å†…çš„ä¿¡æ¯æµä¼ æ’­ã€‚å…·ä½“æ¥è®²ï¼Œé€šè¿‡è‡ªä¸‹å‘ä¸Š(bottom-up)çš„è·¯å¾„å¢å¼ºåœ¨è¾ƒä½å±‚(lower layer)ä¸­å‡†ç¡®çš„å®šä½ä¿¡æ¯æµï¼Œå»ºç«‹åº•å±‚ç‰¹å¾å’Œé«˜å±‚ç‰¹å¾ä¹‹é—´çš„ä¿¡æ¯è·¯å¾„ï¼Œä»è€Œå¢å¼ºæ•´ä¸ªç‰¹å¾å±‚æ¬¡æ¶æ„ã€‚\nyolo-v3ä¸­ä½¿ç”¨FPNå…·ä½“å¦‚ä¸‹ï¼š\n\n\næ¥æºè§æ°´å°\n\nFPNæ˜¯è‡ªé¡¶å‘ä¸‹çš„ï¼Œå°†é«˜å±‚çš„ç‰¹å¾ä¿¡æ¯é€šè¿‡ä¸Šé‡‡æ ·çš„æ–¹å¼è¿›è¡Œä¼ é€’èåˆï¼Œå¾—åˆ°è¿›è¡Œé¢„æµ‹çš„ç‰¹å¾å›¾ã€‚\nåœ¨yolo_v4ä¸­ï¼Œåœ¨FPNçš„åŸºç¡€ä¸Šå¢åŠ PANï¼Œå…·ä½“ç»“æ„å¦‚ä¸‹ï¼š\n\n\næ¥æºè§æ°´å°\n\nå¦‚ä¸Šå›¾ï¼Œç´«è‰²ç®­å¤´å¤„åˆ†åˆ«æ˜¯ä¸‰ä¸ªä¸­é—´feature mapï¼Œåˆ†è¾¨ç‡ä¸º76 * 76ã€38 * 38ã€19 * 19\n\n\næ¥æºè§æ°´å°\n\nè¿™æ ·ç»“åˆæ“ä½œï¼ŒFPNå±‚è‡ªé¡¶å‘ä¸‹ä¼ è¾¾å¼ºè¯­ä¹‰ç‰¹å¾ï¼Œè€Œç‰¹å¾é‡‘å­—å¡”åˆ™è‡ªåº•å‘ä¸Šä¼ è¾¾å¼ºå®šä½ç‰¹å¾ï¼Œä¸¤ä¸¤è”æ‰‹ï¼Œä»ä¸åŒçš„ä¸»å¹²å±‚å¯¹ä¸åŒçš„æ£€æµ‹å±‚è¿›è¡Œå‚æ•°èšåˆã€‚\n\n\nyolo_v4ä¸­ä½¿ç”¨çš„æ˜¯ä¿®æ”¹çš„PAN\n\nPrediction\nç›®æ ‡æ£€æµ‹ä»»åŠ¡çš„æŸå¤±å‡½æ•°ä¸€èˆ¬ç”±Classificition Lossï¼ˆåˆ†ç±»æŸå¤±å‡½æ•°ï¼‰å’ŒBounding Box Regeression Lossï¼ˆå›å½’æŸå¤±å‡½æ•°ï¼‰ä¸¤éƒ¨åˆ†æ„æˆã€‚\nBounding Box Regeressionçš„Lossè¿‘äº›å¹´çš„å‘å±•è¿‡ç¨‹æ˜¯ï¼šSmooth L1 Loss-&gt; IoU Lossï¼ˆ2016ï¼‰-&gt; GIoU Lossï¼ˆ2019ï¼‰-&gt; DIoU Lossï¼ˆ2020ï¼‰-&gt;CIoU Lossï¼ˆ2020ï¼‰\næˆ‘ä»¬ä»æœ€å¸¸ç”¨çš„IOU_Losså¼€å§‹ï¼Œè¿›è¡Œå¯¹æ¯”æ‹†è§£åˆ†æï¼Œçœ‹ä¸‹Yolov4ä¸ºå•¥è¦é€‰æ‹©CIOU_Lossã€‚\n\n\n\n\n\n\n\n\n\nè®°ä½ä¸€ç‚¹ï¼šå¥½çš„ç›®æ ‡æ¡†å›å½’å‡½æ•°åº”è¯¥è€ƒè™‘ä¸‰ä¸ªé‡è¦å‡ ä½•å› ç´ ï¼šé‡å é¢ç§¯ã€ä¸­å¿ƒç‚¹è·ç¦»ï¼Œé•¿å®½æ¯”ã€‚\nIOU_Loss\n\nIOUçš„losså…¶å®å¾ˆç®€å•ï¼Œä¸»è¦æ˜¯äº¤é›†/å¹¶é›†ï¼Œä½†å…¶å®ä¹Ÿå­˜åœ¨ä¸¤ä¸ªé—®é¢˜ã€‚\n\n\nå³çŠ¶æ€1çš„æƒ…å†µï¼Œå½“é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†ä¸ç›¸äº¤æ—¶ï¼ŒIOU=0ï¼Œæ— æ³•ååº”ä¸¤ä¸ªæ¡†è·ç¦»çš„è¿œè¿‘ï¼Œæ­¤æ—¶æŸå¤±å‡½æ•°ä¸å¯å¯¼ï¼ŒIOU_Lossæ— æ³•ä¼˜åŒ–ä¸¤ä¸ªæ¡†ä¸ç›¸äº¤çš„æƒ…å†µã€‚\nå³çŠ¶æ€2å’ŒçŠ¶æ€3çš„æƒ…å†µï¼Œå½“ä¸¤ä¸ªé¢„æµ‹æ¡†å¤§å°ç›¸åŒï¼Œä¸¤ä¸ªIOUä¹Ÿç›¸åŒï¼ŒIOU_Lossæ— æ³•åŒºåˆ†ä¸¤è€…ç›¸äº¤æƒ…å†µçš„ä¸åŒã€‚\n\nå› æ­¤2019å¹´å‡ºç°äº†GIOU_Lossæ¥è¿›è¡Œæ”¹è¿›ã€‚\nGIOU_Loss\n\nå¯ä»¥çœ‹åˆ°ä¸Šå›¾GIOU_Lossä¸­ï¼Œå¢åŠ äº†ç›¸äº¤å°ºåº¦çš„è¡¡é‡æ–¹å¼ï¼Œç¼“è§£äº†å•çº¯IOU_Lossæ—¶çš„å°´å°¬ã€‚ ä½†è¿˜æœ‰ä¸€ç§ä¸è¶³ï¼Œå¦‚ä¸‹ï¼š\n\né—®é¢˜ï¼šçŠ¶æ€1ã€2ã€3éƒ½æ˜¯é¢„æµ‹æ¡†åœ¨ç›®æ ‡æ¡†å†…éƒ¨ä¸”é¢„æµ‹æ¡†å¤§å°ä¸€è‡´çš„æƒ…å†µï¼Œè¿™æ—¶é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†çš„å·®é›†éƒ½æ˜¯ç›¸åŒçš„ï¼Œå› æ­¤è¿™ä¸‰ç§çŠ¶æ€çš„GIOUå€¼ä¹Ÿéƒ½æ˜¯ç›¸åŒçš„ï¼Œè¿™æ—¶GIOUé€€åŒ–æˆäº†IOUï¼Œæ— æ³•åŒºåˆ†ç›¸å¯¹ä½ç½®å…³ç³»ã€‚ åŸºäºè¿™ä¸ªé—®é¢˜ï¼Œ2020å¹´çš„AAAIåˆæå‡ºäº†DIOU_Lossã€‚\nDIOU_Loss\nå¥½çš„ç›®æ ‡æ¡†å›å½’å‡½æ•°åº”è¯¥è€ƒè™‘ä¸‰ä¸ªé‡è¦å‡ ä½•å› ç´ ï¼šé‡å é¢ç§¯ã€ä¸­å¿ƒç‚¹è·ç¦»ï¼Œé•¿å®½æ¯”ã€‚\né’ˆå¯¹IOUå’ŒGIOUå­˜åœ¨çš„é—®é¢˜ï¼Œä½œè€…ä»ä¸¤ä¸ªæ–¹é¢è¿›è¡Œè€ƒè™‘\nä¸€ï¼šå¦‚ä½•æœ€å°åŒ–é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†ä¹‹é—´çš„å½’ä¸€åŒ–è·ç¦»ï¼Ÿ äºŒï¼šå¦‚ä½•åœ¨é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†é‡å æ—¶ï¼Œå›å½’çš„æ›´å‡†ç¡®ï¼Ÿ\né’ˆå¯¹ç¬¬ä¸€ä¸ªé—®é¢˜ï¼Œæå‡ºäº†DIOU_Lossï¼ˆDistance_IOU_Lossï¼‰\n\nDIOU_Lossè€ƒè™‘äº†é‡å é¢ç§¯å’Œä¸­å¿ƒç‚¹è·ç¦»ï¼Œå½“ç›®æ ‡æ¡†åŒ…è£¹é¢„æµ‹æ¡†çš„æ—¶å€™ï¼Œç›´æ¥åº¦é‡2ä¸ªæ¡†çš„è·ç¦»ï¼Œå› æ­¤DIOU_Lossæ”¶æ•›çš„æ›´å¿«ã€‚ ä½†å°±åƒå‰é¢å¥½çš„ç›®æ ‡æ¡†å›å½’å‡½æ•°æ‰€è¯´çš„ï¼Œæ²¡æœ‰è€ƒè™‘åˆ°é•¿å®½æ¯”ã€‚\n\næ¯”å¦‚ä¸Šé¢ä¸‰ç§æƒ…å†µï¼Œç›®æ ‡æ¡†åŒ…è£¹é¢„æµ‹æ¡†ï¼Œæœ¬æ¥DIOU_Losså¯ä»¥èµ·ä½œç”¨ã€‚ ä½†é¢„æµ‹æ¡†çš„ä¸­å¿ƒç‚¹çš„ä½ç½®éƒ½æ˜¯ä¸€æ ·çš„ï¼Œå› æ­¤æŒ‰ç…§DIOU_Lossçš„è®¡ç®—å…¬å¼ï¼Œä¸‰è€…çš„å€¼éƒ½æ˜¯ç›¸åŒçš„ã€‚\nCIOU_Loss\nCIOU_Losså’ŒDIOU_Losså‰é¢çš„å…¬å¼éƒ½æ˜¯ä¸€æ ·çš„ï¼Œä¸è¿‡åœ¨æ­¤åŸºç¡€ä¸Šè¿˜å¢åŠ äº†ä¸€ä¸ªå½±å“å› å­ï¼Œå°†é¢„æµ‹æ¡†å’Œç›®æ ‡æ¡†çš„é•¿å®½æ¯”éƒ½è€ƒè™‘äº†è¿›å»ã€‚\n\nå…¶ä¸­væ˜¯è¡¡é‡é•¿å®½æ¯”ä¸€è‡´æ€§çš„å‚æ•°ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥å®šä¹‰ä¸ºï¼š\n\nè¿™æ ·CIOU_Losså°±å°†ç›®æ ‡æ¡†å›å½’å‡½æ•°åº”è¯¥è€ƒè™‘ä¸‰ä¸ªé‡è¦å‡ ä½•å› ç´ ï¼šé‡å é¢ç§¯ã€ä¸­å¿ƒç‚¹è·ç¦»ï¼Œé•¿å®½æ¯”å…¨éƒ½è€ƒè™‘è¿›å»äº†ã€‚\nå¯¹æ¯”\nå†æ¥ç»¼åˆçš„çœ‹ä¸‹å„ä¸ªLosså‡½æ•°çš„ä¸åŒç‚¹ï¼š\nIOU_Lossï¼šä¸»è¦è€ƒè™‘æ£€æµ‹æ¡†å’Œç›®æ ‡æ¡†é‡å é¢ç§¯ã€‚ GIOU_Lossï¼šåœ¨IOUçš„åŸºç¡€ä¸Šï¼Œè§£å†³è¾¹ç•Œæ¡†ä¸é‡åˆæ—¶çš„é—®é¢˜ã€‚ DIOU_Lossï¼šåœ¨IOUå’ŒGIOUçš„åŸºç¡€ä¸Šï¼Œè€ƒè™‘è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹è·ç¦»çš„ä¿¡æ¯ã€‚ CIOU_Lossï¼šåœ¨DIOUçš„åŸºç¡€ä¸Šï¼Œè€ƒè™‘è¾¹ç•Œæ¡†å®½é«˜æ¯”çš„å°ºåº¦ä¿¡æ¯ã€‚\nYolov4ä¸­é‡‡ç”¨äº†CIOU_Lossçš„å›å½’æ–¹å¼ï¼Œä½¿å¾—é¢„æµ‹æ¡†å›å½’çš„é€Ÿåº¦å’Œç²¾åº¦æ›´é«˜ä¸€äº›ã€‚\nDIOU_nms\nDIoUç”¨ä½œ NMS çš„ä¸€ä¸ªå› å­ã€‚è¯¥æ–¹æ³•åœ¨æŠ‘åˆ¶å†—ä½™çš„è¾¹ç•Œæ¡†æ—¶ä¼šä½¿ç”¨ IoU å’Œä¸¤ä¸ªè¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ä¹‹é—´çš„è·ç¦»ã€‚è¿™èƒ½ä½¿å¾—æ¨¡å‹èƒ½æ›´åŠ ç¨³å¥åœ°åº”å¯¹æœ‰é®æŒ¡çš„æƒ…å†µã€‚ åœ¨ä¼ ç»ŸNMSä¸­ï¼ŒIoUæŒ‡æ ‡å¸¸ç”¨äºæŠ‘åˆ¶å†—ä½™bboxï¼Œå…¶ä¸­é‡å åŒºåŸŸæ˜¯å”¯ä¸€å› ç´ ï¼Œå¯¹äºé®æŒ¡æƒ…å†µç»å¸¸äº§ç”Ÿé”™è¯¯æŠ‘åˆ¶ã€‚ DIoU-NMSå°†DIoUä½œä¸ºNMSçš„å‡†åˆ™ï¼Œå› ä¸ºåœ¨æŠ‘åˆ¶å‡†åˆ™ä¸­ä¸ä»…åº”è€ƒè™‘é‡å åŒºåŸŸï¼Œè€Œä¸”è¿˜åº”è€ƒè™‘ä¸¤ä¸ªboxä¹‹é—´çš„ä¸­å¿ƒç‚¹è·ç¦»ï¼Œè€ŒDIoUå°±æ˜¯åŒæ—¶è€ƒè™‘äº†é‡å åŒºåŸŸå’Œä¸¤ä¸ªboxçš„ä¸­å¿ƒè·ç¦»ã€‚\nDIoU-NMSå»ºè®®ä¸¤ä¸ªä¸­å¿ƒç‚¹è¾ƒè¿œçš„boxå¯èƒ½ä½äºä¸åŒçš„å¯¹è±¡ä¸Šï¼Œä¸åº”å°†å…¶åˆ é™¤(è¿™å°±æ˜¯DIoU-NMSçš„ä¸NMSçš„æœ€å¤§ä¸åŒä¹‹å¤„)ã€‚\n\nåœ¨ä¸Šå›¾é‡å çš„æ‘©æ‰˜è½¦æ£€æµ‹ä¸­ï¼Œä¸­é—´çš„æ‘©æ‰˜è½¦å› ä¸ºè€ƒè™‘è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„ä½ç½®ä¿¡æ¯ï¼Œä¹Ÿå¯ä»¥å›å½’å‡ºæ¥ã€‚\nå› æ­¤åœ¨é‡å ç›®æ ‡çš„æ£€æµ‹ä¸­ï¼ŒDIOU_nmsçš„æ•ˆæœä¼˜äºä¼ ç»Ÿçš„nmsã€‚\n\n\n\n\n\n\n\n\n\nè¿™é‡Œä¸ºä»€ä¹ˆä¸ç”¨CIOU_nmsï¼Œè€Œç”¨DIOU_nms?\nç­”ï¼šå› ä¸ºå‰é¢è®²åˆ°çš„CIOU_lossï¼Œæ˜¯åœ¨DIOU_lossçš„åŸºç¡€ä¸Šï¼Œæ·»åŠ çš„å½±å“å› å­ï¼ŒåŒ…å«groundtruthæ ‡æ³¨æ¡†çš„ä¿¡æ¯ï¼Œåœ¨è®­ç»ƒæ—¶ç”¨äºå›å½’ã€‚ ä½†åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œå¹¶æ²¡æœ‰groundtruthçš„ä¿¡æ¯ï¼Œä¸ç”¨è€ƒè™‘å½±å“å› å­ï¼Œå› æ­¤ç›´æ¥ç”¨DIOU_nmså³å¯ã€‚\n","slug":"YOLO-V4å­¦ä¹ ç¬”è®°","date":"2021-09-06T10:10:36.000Z","categories_index":"","tags_index":"detection","author_index":"Hulk Wang"},{"id":"82f698705681b0bacc9c6cad3db6d88e","title":"YOLO-V3å­¦ä¹ ç¬”è®°","content":"YOLO-V3å­¦ä¹ ç¬”è®°\n\n\n\n\n\n\n\n\n\nçŸ¥è¯†ç‚¹æ¥æºäºè®ºæ–‡å’Œç½‘ç»œï¼Œä»…è®°å½•å­¦ä¹ \nç½‘ç»œç»“æ„\nBackbone\n\næ•´ä¸ªv3ç»“æ„æ²¡æœ‰æ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚\nè¾“å‡ºç‰¹å¾å›¾ç¼©å°åˆ°è¾“å…¥çš„1/32ã€‚æ‰€ä»¥ï¼Œé€šå¸¸éƒ½è¦æ±‚è¾“å…¥å›¾ç‰‡æ˜¯32çš„å€æ•°\n\n\nDBL:ä»£ç ä¸­çš„Darknetconv2d_BN_Leakyï¼Œæ˜¯yolo_v3çš„åŸºæœ¬ç»„ä»¶ã€‚å°±æ˜¯å·ç§¯+BN+Leaky reluã€‚ resn:nä»£è¡¨æ•°å­—ï¼Œæœ‰res1ï¼Œres2, â€¦ ,res8ç­‰ç­‰ï¼Œè¡¨ç¤ºè¿™ä¸ªres_blocké‡Œå«æœ‰å¤šå°‘ä¸ªres_unitã€‚ concat:å¼ é‡æ‹¼æ¥ã€‚å°†darknetä¸­é—´å±‚å’Œåé¢çš„æŸä¸€å±‚çš„ä¸Šé‡‡æ ·è¿›è¡Œæ‹¼æ¥ã€‚æ‹¼æ¥çš„æ“ä½œå’Œæ®‹å·®å±‚addçš„æ“ä½œæ˜¯ä¸ä¸€æ ·çš„ï¼Œæ‹¼æ¥ä¼šæ‰©å……å¼ é‡çš„ç»´åº¦ï¼Œè€Œaddåªæ˜¯ç›´æ¥ç›¸åŠ ä¸ä¼šå¯¼è‡´å¼ é‡ç»´åº¦çš„æ”¹å˜ã€‚\nOutput\nyolo v3è¾“å‡ºäº†3ä¸ªä¸åŒå°ºåº¦çš„feature mapï¼Œå¦‚ä¸Šå›¾æ‰€ç¤ºçš„y1, y2, y3ã€‚å€Ÿé‰´äº†FPN(feature pyramid networks)ï¼Œé‡‡ç”¨å¤šå°ºåº¦æ¥å¯¹ä¸åŒsizeçš„ç›®æ ‡è¿›è¡Œæ£€æµ‹ï¼Œè¶Šç²¾ç»†çš„grid cellå°±å¯ä»¥æ£€æµ‹å‡ºè¶Šç²¾ç»†çš„ç‰©ä½“(å¤§åˆ†è¾¨ç‡y3æ›´èƒ½æ£€æµ‹å°ç‰©ä½“ï¼Œå°åˆ†è¾¨ç‡y1æ›´èƒ½æ£€æµ‹å¤§ç‰©ä½“)ã€‚\ny1,y2å’Œy3çš„æ·±åº¦éƒ½æ˜¯255ï¼Œè¾¹é•¿åˆ†åˆ«ä¸º13:26:52ã€‚ å¯¹äºCOCOç±»åˆ«è€Œè¨€ï¼Œæœ‰80ä¸ªç§ç±»ï¼Œæ‰€ä»¥æ¯ä¸ªboxåº”è¯¥å¯¹æ¯ä¸ªç§ç±»éƒ½è¾“å‡ºä¸€ä¸ªæ¦‚ç‡ã€‚\nyolo v3è®¾å®šçš„æ˜¯æ¯ä¸ªç½‘æ ¼å•å…ƒé¢„æµ‹3ä¸ªboxï¼Œæ‰€ä»¥æ¯ä¸ªboxéœ€è¦æœ‰(x, y, w, h, confidence)äº”ä¸ªåŸºæœ¬å‚æ•°ï¼Œç„¶åè¿˜è¦æœ‰80ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚æ‰€ä»¥3*(5 + 80) = 255ã€‚è¿™ä¸ª255å°±æ˜¯è¿™ä¹ˆæ¥çš„ã€‚ v3ç”¨ä¸Šé‡‡æ ·çš„æ–¹æ³•æ¥å®ç°è¿™ç§å¤šå°ºåº¦çš„feature mapï¼Œconcatè¿æ¥çš„ä¸¤ä¸ªå¼ é‡æ˜¯å…·æœ‰ä¸€æ ·å°ºåº¦çš„(ä¸¤å¤„æ‹¼æ¥åˆ†åˆ«æ˜¯26x26å°ºåº¦æ‹¼æ¥å’Œ52x52å°ºåº¦æ‹¼æ¥ï¼Œé€šè¿‡(2, 2)ä¸Šé‡‡æ ·æ¥ä¿è¯concatæ‹¼æ¥çš„å¼ é‡å°ºåº¦ç›¸åŒ)ã€‚ä½œè€…å¹¶æ²¡æœ‰åƒSSDé‚£æ ·ç›´æ¥é‡‡ç”¨backboneä¸­é—´å±‚çš„å¤„ç†ç»“æœä½œä¸ºfeature mapçš„è¾“å‡ºï¼Œè€Œæ˜¯å’Œåé¢ç½‘ç»œå±‚çš„ä¸Šé‡‡æ ·ç»“æœè¿›è¡Œä¸€ä¸ªæ‹¼æ¥ä¹‹åçš„å¤„ç†ç»“æœä½œä¸ºfeature mapã€‚\nBounding Box\nåœ¨Yolov1ä¸­ï¼Œç½‘ç»œç›´æ¥å›å½’æ£€æµ‹æ¡†çš„å®½ã€é«˜ï¼Œè¿™æ ·æ•ˆæœæœ‰é™ã€‚æ‰€ä»¥åœ¨Yolov2ä¸­ï¼Œæ”¹ä¸ºäº†å›å½’åŸºäºå…ˆéªŒæ¡†çš„å˜åŒ–å€¼ï¼Œè¿™æ ·ç½‘ç»œçš„å­¦ä¹ éš¾åº¦é™ä½ï¼Œæ•´ä½“ç²¾åº¦æå‡ä¸å°ã€‚Yolov3æ²¿ç”¨äº†Yolov2ä¸­å…³äºå…ˆéªŒæ¡†çš„æŠ€å·§ï¼Œå¹¶ä¸”ä½¿ç”¨k-meanså¯¹æ•°æ®é›†ä¸­çš„æ ‡ç­¾æ¡†è¿›è¡Œèšç±»ï¼Œå¾—åˆ°ç±»åˆ«ä¸­å¿ƒç‚¹çš„9ä¸ªæ¡†ï¼Œä½œä¸ºå…ˆéªŒæ¡†ã€‚åœ¨COCOæ•°æ®é›†ä¸­ï¼ˆåŸå§‹å›¾ç‰‡å…¨éƒ¨resizeä¸º416 Ã— 416ï¼‰ï¼Œä¹ä¸ªæ¡†åˆ†åˆ«æ˜¯ (10Ã—13)ï¼Œ(16Ã—30)ï¼Œ(33Ã—23)ï¼Œ(30Ã—61)ï¼Œ(62Ã—45)ï¼Œ(59Ã— 119)ï¼Œ (116 Ã— 90)ï¼Œ (156 Ã— 198)ï¼Œ(373 Ã— 326) ï¼Œé¡ºåºä¸ºw Ã— hã€‚\nfeature mapä¸­çš„æ¯ä¸€ä¸ªcelléƒ½ä¼šé¢„æµ‹3ä¸ªè¾¹ç•Œæ¡†ï¼ˆbounding boxï¼‰ ï¼Œæ¯ä¸ªbounding boxéƒ½ä¼šé¢„æµ‹ä¸‰ä¸ªä¸œè¥¿ï¼š 1. æ¯ä¸ªæ¡†çš„ä½ç½®ï¼ˆ4ä¸ªå€¼ï¼Œä¸­å¿ƒåæ ‡txå’Œtyï¼Œæ¡†çš„é«˜åº¦bhå’Œå®½åº¦bwï¼‰ 2. ä¸€ä¸ªobjectness prediction 3. Nä¸ªç±»åˆ«\nä¸‰ä¸ªoutputï¼Œæ¯ä¸ªå¯¹åº”çš„æ„Ÿå—é‡ä¸åŒï¼Œ32å€é™é‡‡æ ·çš„æ„Ÿå—é‡æœ€å¤§ï¼Œé€‚åˆæ£€æµ‹å¤§çš„ç›®æ ‡ï¼Œæ‰€ä»¥åœ¨è¾“å…¥ä¸º416Ã—416æ—¶ï¼Œæ¯ä¸ªcellçš„ä¸‰ä¸ªanchor boxä¸º(116 ,90); (156 ,198); (373 ,326)ã€‚16å€é€‚åˆä¸€èˆ¬å¤§å°çš„ç‰©ä½“ï¼Œanchor boxä¸º(30,61); (62,45); (59,119)ã€‚8å€çš„æ„Ÿå—é‡æœ€å°ï¼Œé€‚åˆæ£€æµ‹å°ç›®æ ‡ï¼Œå› æ­¤anchor boxä¸º(10,13); (16,30); (33,23)ã€‚æ‰€ä»¥å½“è¾“å…¥ä¸º416Ã—416æ—¶ï¼Œå®é™…æ€»å…±æœ‰ï¼ˆ52Ã—52+26Ã—26+13Ã—13ï¼‰Ã—3=10647ä¸ªproposal boxã€‚\n\n\n\n\n\n\n\n\n\nç‰¹å¾å›¾\n13x13\n26x26\n52x52\n\n\n\n\næ„Ÿå—é‡\nå¤§\nä¸­\nå°\n\n\nå…ˆéªŒæ¡†\n(116 ,90)(156 ,198)(373 ,326)\n(30,61) (62,45)(59,119)\n(10,13)(16,30)(33,23)\n\n\n\n\n9ç§å°ºå¯¸çš„å…ˆéªŒæ¡†ï¼Œå›¾ä¸­è“è‰²æ¡†ä¸ºèšç±»å¾—åˆ°çš„å…ˆéªŒæ¡†ã€‚é»„è‰²æ¡†å¼ground truthï¼Œçº¢æ¡†æ˜¯å¯¹è±¡ä¸­å¿ƒç‚¹æ‰€åœ¨çš„ç½‘æ ¼(æ¥æºè§æ°´å°)\n\n\n\n\n\n\n\n\n\n\nè¿™é‡Œæ³¨æ„bounding box ä¸anchor boxçš„åŒºåˆ«ï¼š Bounding boxå®ƒè¾“å‡ºçš„æ˜¯æ¡†çš„ä½ç½®ï¼ˆä¸­å¿ƒåæ ‡ä¸å®½é«˜ï¼‰ï¼Œconfidenceä»¥åŠNä¸ªç±»åˆ«ã€‚anchor boxåªæ˜¯ä¸€ä¸ªå°ºåº¦å³åªæœ‰å®½é«˜ã€‚\nOutput Decode\nBounding box decode\nå¦‚ä¸Šä¸€èŠ‚æ‰€è¯´ï¼Œv2å¼€å§‹ï¼Œå›å½’åŸºäºå…ˆéªŒæ¡†çš„å˜åŒ–å€¼ï¼Œå› æ­¤å¯ä»¥é€šè¿‡ä»¥ä¸‹å…¬å¼è§£ç æ£€æµ‹æ¡†çš„xï¼Œyï¼Œwï¼Œh.\n\nå¦‚ä¸‹å›¾ï¼Œ\\(\\sigma(t_x)\\)ã€\\(\\sigma(t_y)\\)æ˜¯åŸºäºçŸ©å½¢æ¡†ä¸­å¿ƒç‚¹å·¦ä¸Šè§’æ ¼ç‚¹åæ ‡çš„åç§»é‡, \\(\\sigma\\)æ˜¯æ¿€æ´»å‡½æ•°ï¼Œè®ºæ–‡ä¸­ä½œè€…ä½¿ç”¨sigmoid, \\(p_w, p_h\\)æ˜¯å…ˆéªŒæ¡†çš„å®½ã€é«˜ï¼Œé€šè¿‡ä¸Šè¿°å…¬å¼ï¼Œè®¡ç®—å‡ºå®é™…é¢„æµ‹æ¡†çš„å®½é«˜ \\(b_w, b_h\\).\n\n\n\n\n\n\n\n\n\n\nå¾—åˆ°å¯¹åº”çš„\\(b_w, b_h\\)å, è¿˜éœ€è¦ä¹˜ä»¥ç‰¹å¾å›¾å¯¹åº”çš„çš„é‡‡æ ·ç‡(32,16,8)ï¼Œå¾—åˆ°çœŸå®çš„æ£€æµ‹æ¡†x,y\nobjectness score decode\nç‰©ä½“çš„æ£€æµ‹ç½®ä¿¡åº¦ï¼Œåœ¨Yoloè®¾è®¡ä¸­éå¸¸é‡è¦ï¼Œå…³ç³»åˆ°ç®—æ³•çš„æ£€æµ‹æ­£ç¡®ç‡ä¸å¬å›ç‡ã€‚ ç½®ä¿¡åº¦åœ¨è¾“å‡º85ç»´ä¸­å å›ºå®šä¸€ä½ï¼Œç”±sigmoidå‡½æ•°è§£ç å³å¯ï¼Œè§£ç ä¹‹åæ•°å€¼åŒºé—´åœ¨[0ï¼Œ1]ä¸­ã€‚\nlogisticå›å½’ç”¨äºå¯¹anchoråŒ…å›´çš„éƒ¨åˆ†è¿›è¡Œä¸€ä¸ªç›®æ ‡æ€§è¯„åˆ†(objectness score)ï¼Œå³è¿™å—ä½ç½®æ˜¯ç›®æ ‡çš„å¯èƒ½æ€§æœ‰å¤šå¤§ã€‚è¿™ä¸€æ­¥æ˜¯åœ¨predictä¹‹å‰è¿›è¡Œçš„ï¼Œå¯ä»¥å»æ‰ä¸å¿…è¦anchorï¼Œå¯ä»¥å‡å°‘è®¡ç®—é‡ã€‚ä½œè€…åœ¨è®ºæ–‡ç§çš„æè¿°å¦‚ä¸‹:\n\n\n\n\n\n\n\n\n\nIf the bounding box prior is not the best but does overlap a ground truth object by more than some threshold we ignore the prediction, following[17]. We use the threshold of 0.5. Unlike [17] our system only assigns one bounding box prior for each ground truth object.\nå¦‚æœæ¨¡æ¿æ¡†ä¸æ˜¯æœ€ä½³çš„å³ä½¿å®ƒè¶…è¿‡æˆ‘ä»¬è®¾å®šçš„é˜ˆå€¼ï¼Œæˆ‘ä»¬è¿˜æ˜¯ä¸ä¼šå¯¹å®ƒè¿›è¡Œpredictã€‚ä¸åŒäºfaster R-CNNçš„æ˜¯ï¼Œyolo_v3åªä¼šå¯¹1ä¸ªpriorè¿›è¡Œæ“ä½œï¼Œä¹Ÿå°±æ˜¯é‚£ä¸ªæœ€ä½³priorã€‚è€Œlogisticå›å½’å°±æ˜¯ç”¨æ¥ä»9ä¸ªanchor priorsä¸­æ‰¾åˆ°objectness score(ç›®æ ‡å­˜åœ¨å¯èƒ½æ€§å¾—åˆ†)æœ€é«˜çš„é‚£ä¸€ä¸ªã€‚logisticå›å½’å°±æ˜¯ç”¨æ›²çº¿å¯¹priorç›¸å¯¹äº objectness scoreæ˜ å°„å…³ç³»çš„çº¿æ€§å»ºæ¨¡ã€‚\nClass Prediction decode\nCOCOæ•°æ®é›†æœ‰80ä¸ªç±»åˆ«ï¼Œæ‰€ä»¥ç±»åˆ«æ•°åœ¨85ç»´è¾“å‡ºä¸­å äº†80ç»´ï¼Œæ¯ä¸€ç»´ç‹¬ç«‹ä»£è¡¨ä¸€ä¸ªç±»åˆ«çš„ç½®ä¿¡åº¦ã€‚ä½¿ç”¨sigmoidæ¿€æ´»å‡½æ•°æ›¿ä»£äº†Yolov2ä¸­çš„softmaxï¼Œå–æ¶ˆäº†ç±»åˆ«ä¹‹é—´çš„äº’æ–¥ï¼Œå¯ä»¥ä½¿ç½‘ç»œæ›´åŠ çµæ´»ã€‚\næ€»ç»“\n\n9ä¸ªanchorä¼šè¢«ä¸‰ä¸ªè¾“å‡ºå¼ é‡å¹³åˆ†çš„ã€‚æ ¹æ®å¤§ä¸­å°ä¸‰ç§sizeå„è‡ªå–è‡ªå·±çš„anchorã€‚\nä½œè€…ä½¿ç”¨äº†logisticå›å½’æ¥å¯¹æ¯ä¸ªanchoråŒ…å›´çš„å†…å®¹è¿›è¡Œäº†ä¸€ä¸ªç›®æ ‡æ€§è¯„åˆ†(objectness score)ã€‚ æ ¹æ®ç›®æ ‡æ€§è¯„åˆ†æ¥é€‰æ‹©anchor priorè¿›è¡Œpredictï¼Œè€Œä¸æ˜¯æ‰€æœ‰anchor prioréƒ½ä¼šæœ‰è¾“å‡ºã€‚\n\nè®­ç»ƒç­–ç•¥\n\n\n\n\n\n\n\n\n\nYOLOv3 predicts an objectness score for each bounding box using logistic regression. This should be 1 if the bounding box prior overlaps a ground truth object by more than any other bounding box prior. If the bounding box prior is not the best but does overlap a ground truth object by more than some threshold we ignore the prediction, following [17]. We use the threshold of .5. Unlike [17] our system only assigns one bounding box prior for each ground truth object. If a bounding box prior is not assigned to a ground truth object it incurs no loss for coordinate or class predictions, only objectness.\né¢„æµ‹æ¡†ä¸€å…±åˆ†ä¸ºä¸‰ç§æƒ…å†µï¼šæ­£ä¾‹ï¼ˆpositiveï¼‰ã€è´Ÿä¾‹ï¼ˆnegativeï¼‰ã€å¿½ç•¥æ ·ä¾‹ï¼ˆignoreï¼‰ã€‚\næ­£ä¾‹ï¼šä»»å–ä¸€ä¸ªground truthï¼Œä¸4032ä¸ªæ¡†å…¨éƒ¨è®¡ç®—IOUï¼ŒIOUæœ€å¤§çš„é¢„æµ‹æ¡†ï¼Œå³ä¸ºæ­£ä¾‹ã€‚å¹¶ä¸”ä¸€ä¸ªé¢„æµ‹æ¡†ï¼Œåªèƒ½åˆ†é…ç»™ä¸€ä¸ªground truthã€‚ä¾‹å¦‚ç¬¬ä¸€ä¸ªground truthå·²ç»åŒ¹é…äº†ä¸€ä¸ªæ­£ä¾‹æ£€æµ‹æ¡†ï¼Œé‚£ä¹ˆä¸‹ä¸€ä¸ªground truthï¼Œå°±åœ¨ä½™ä¸‹çš„4031ä¸ªæ£€æµ‹æ¡†ä¸­ï¼Œå¯»æ‰¾IOUæœ€å¤§çš„æ£€æµ‹æ¡†ä½œä¸ºæ­£ä¾‹ã€‚ground truthçš„å…ˆåé¡ºåºå¯å¿½ç•¥ã€‚æ­£ä¾‹äº§ç”Ÿç½®ä¿¡åº¦lossã€æ£€æµ‹æ¡†lossã€ç±»åˆ«lossã€‚é¢„æµ‹æ¡†ä¸ºå¯¹åº”çš„ground truth boxæ ‡ç­¾ï¼ˆéœ€è¦åå‘ç¼–ç ï¼Œä½¿ç”¨çœŸå®çš„xã€yã€wã€hè®¡ç®—å‡º ï¼‰ï¼›ç±»åˆ«æ ‡ç­¾å¯¹åº”ç±»åˆ«ä¸º1ï¼Œå…¶ä½™ä¸º0ï¼›ç½®ä¿¡åº¦æ ‡ç­¾ä¸º1ã€‚\nå¿½ç•¥æ ·ä¾‹ï¼šæ­£ä¾‹é™¤å¤–ï¼Œä¸ä»»æ„ä¸€ä¸ªground truthçš„IOUå¤§äºé˜ˆå€¼ï¼ˆè®ºæ–‡ä¸­ä½¿ç”¨0.5ï¼‰ï¼Œåˆ™ä¸ºå¿½ç•¥æ ·ä¾‹ã€‚å¿½ç•¥æ ·ä¾‹ä¸äº§ç”Ÿä»»ä½•lossã€‚\nè´Ÿä¾‹ï¼šæ­£ä¾‹é™¤å¤–ï¼ˆä¸ground truthè®¡ç®—åIOUæœ€å¤§çš„æ£€æµ‹æ¡†ï¼Œä½†æ˜¯IOUå°äºé˜ˆå€¼ï¼Œä»ä¸ºæ­£ä¾‹ï¼‰ï¼Œä¸å…¨éƒ¨ground truthçš„IOUéƒ½å°äºé˜ˆå€¼ï¼ˆ0.5ï¼‰ï¼Œåˆ™ä¸ºè´Ÿä¾‹ã€‚è´Ÿä¾‹åªæœ‰ç½®ä¿¡åº¦äº§ç”Ÿlossï¼Œç½®ä¿¡åº¦æ ‡ç­¾ä¸º0ã€‚\nLoss\nYolov3 Lossä¸ºä¸‰ä¸ªç‰¹å¾å›¾Lossä¹‹å’Œï¼š\n\\(Loss = Loss_n1 + Loss_n2 + Loss_n3\\)\n\n\n\\(\\lambda\\)ä¸ºæƒé‡å¸¸æ•°ï¼Œæ§åˆ¶æ£€æµ‹æ¡†Lossã€objç½®ä¿¡åº¦Lossã€noobjç½®ä¿¡åº¦Lossä¹‹é—´çš„æ¯”ä¾‹ï¼Œé€šå¸¸è´Ÿä¾‹çš„ä¸ªæ•°æ˜¯æ­£ä¾‹çš„å‡ åå€ä»¥ä¸Šï¼Œå¯ä»¥é€šè¿‡æƒé‡è¶…å‚æ§åˆ¶æ£€æµ‹æ•ˆæœ;\n\\(1^{obj}_{ij}\\) è‹¥æ˜¯æ­£ä¾‹åˆ™è¾“å‡º1ï¼Œå¦åˆ™ä¸º0ï¼›\\(1^{noobj}_{ij}\\) ,è‹¥æ˜¯è´Ÿä¾‹åˆ™è¾“å‡º1ï¼Œå¦åˆ™ä¸º0ï¼›å¿½ç•¥æ ·ä¾‹éƒ½è¾“å‡º0;\nxã€yã€wã€hä½¿ç”¨MSEä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨smooth L1 lossï¼ˆå‡ºè‡ªFaster R-CNNï¼‰ä½œä¸ºæŸå¤±å‡½æ•°ã€‚smooth L1å¯ä»¥ä½¿è®­ç»ƒæ›´åŠ å¹³æ»‘ã€‚ç½®ä¿¡åº¦ã€ç±»åˆ«æ ‡ç­¾ç”±äºæ˜¯0ï¼Œ1äºŒåˆ†ç±»ï¼Œæ‰€ä»¥ä½¿ç”¨äº¤å‰ç†µä½œä¸ºæŸå¤±å‡½æ•°ã€‚\n\nå…¶ä»–\n\nground truthä¸ºä»€ä¹ˆä¸æŒ‰ç…§ä¸­å¿ƒç‚¹åˆ†é…å¯¹åº”çš„é¢„æµ‹boxï¼Ÿ &gt;åœ¨Yolov3çš„è®­ç»ƒç­–ç•¥ä¸­ï¼Œä¸å†åƒYolov1é‚£æ ·ï¼Œæ¯ä¸ªcellè´Ÿè´£ä¸­å¿ƒè½åœ¨è¯¥cellä¸­çš„ground truthã€‚åŸå› æ˜¯Yolov3ä¸€å…±äº§ç”Ÿ3ä¸ªç‰¹å¾å›¾ï¼Œ3ä¸ªç‰¹å¾å›¾ä¸Šçš„cellï¼Œä¸­å¿ƒæ˜¯æœ‰é‡åˆçš„ã€‚è®­ç»ƒæ—¶ï¼Œå¯èƒ½æœ€å¥‘åˆçš„æ˜¯ç‰¹å¾å›¾1çš„ç¬¬3ä¸ªboxï¼Œä½†æ˜¯æ¨ç†çš„æ—¶å€™ç‰¹å¾å›¾2çš„ç¬¬1ä¸ªboxç½®ä¿¡åº¦æœ€é«˜ã€‚æ‰€ä»¥Yolov3çš„è®­ç»ƒï¼Œä¸å†æŒ‰ç…§ground truthä¸­å¿ƒç‚¹ï¼Œä¸¥æ ¼åˆ†é…æŒ‡å®šcellï¼Œè€Œæ˜¯æ ¹æ®é¢„æµ‹å€¼å¯»æ‰¾IOUæœ€å¤§çš„é¢„æµ‹æ¡†ä½œä¸ºæ­£ä¾‹ã€‚\nä¸ºä»€ä¹ˆæœ‰å¿½ç•¥æ ·ä¾‹ï¼Ÿ\n\nå¿½ç•¥æ ·ä¾‹æ˜¯Yolov3ä¸­çš„ç‚¹ç›ä¹‹ç¬”ã€‚ç”±äºYolov3ä½¿ç”¨äº†å¤šå°ºåº¦ç‰¹å¾å›¾ï¼Œä¸åŒå°ºåº¦çš„ç‰¹å¾å›¾ä¹‹é—´ä¼šæœ‰é‡åˆæ£€æµ‹éƒ¨åˆ†ã€‚æ¯”å¦‚æœ‰ä¸€ä¸ªçœŸå®ç‰©ä½“ï¼Œåœ¨è®­ç»ƒæ—¶è¢«åˆ†é…åˆ°çš„æ£€æµ‹æ¡†æ˜¯ç‰¹å¾å›¾1çš„ç¬¬ä¸‰ä¸ªboxï¼ŒIOUè¾¾0.98ï¼Œæ­¤æ—¶æ°å¥½ç‰¹å¾å›¾2çš„ç¬¬ä¸€ä¸ªboxä¸è¯¥ground truthçš„IOUè¾¾0.95ï¼Œä¹Ÿæ£€æµ‹åˆ°äº†è¯¥ground truthï¼Œå¦‚æœæ­¤æ—¶ç»™å…¶ç½®ä¿¡åº¦å¼ºè¡Œæ‰“0çš„æ ‡ç­¾ï¼Œç½‘ç»œå­¦ä¹ æ•ˆæœä¼šä¸ç†æƒ³ã€‚\næœ¬èº«æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹å°±ä¸å‡è¡¡ï¼ˆè´Ÿä¾‹&gt;æ­£ä¾‹ï¼‰ï¼Œå¦‚æœå¼ºè¡Œæ ‡ä¸º0ï¼Œä¼šä½¿ä¸å‡è¡¡æ›´ä¸¥é‡ã€‚\n\n\n","slug":"YOLO-V3å­¦ä¹ ç¬”è®°","date":"2021-08-30T11:59:09.000Z","categories_index":"","tags_index":"detection","author_index":"Hulk Wang"},{"id":"2a4b32b81021e06bffb6e540079ceefc","title":"hexo+github æ­å»ºä¸ªäººåšå®¢","content":"hexo+githubæ­å»ºä¸ªäººåšå®¢\n\n\n\n\n\n\n\n\n\næ­å»ºç¯å¢ƒ:macOs 11.4 ç¯å¢ƒä¾èµ–:\n&gt; * git\n&gt; * npm\n&gt; * node\n&gt; * hexo\nhexoå®‰è£…\n\nå®‰è£…node brew install node\nå®‰è£…hexo npm install -g hexo-cli\næŸ¥çœ‹hexoç‰ˆæœ¬ hexo -v \n\nå»ºç«™\n\n\n\n\n\n\n\n\n\nå®‰è£… Hexo å®Œæˆåï¼Œè¯·æ‰§è¡Œä¸‹åˆ—å‘½ä»¤ï¼ŒHexo å°†ä¼šåœ¨æŒ‡å®šæ–‡ä»¶å¤¹ä¸­æ–°å»ºæ‰€éœ€è¦çš„æ–‡ä»¶\n\nåˆå§‹åŒ–hexoæ¡†æ¶ hexo init &lt;folder&gt;\nç§»åŠ¨åˆ°ç›®æ ‡ç›®å½• cd &lt;folder&gt;\nå®‰è£…ä¾èµ–ç»„ä»¶ npm install\nç”Ÿæˆé™æ€æ–‡ä»¶ hexo g\nå¼€å¯æœ¬åœ°æœåŠ¡å™¨ hexo s\n\n\n\n\n\n\n\n\n\n\nåœ¨æµè§ˆå™¨ä¸­è¾“å…¥ http://localhost:4000 å›è½¦å°±å¯ä»¥é¢„è§ˆæ•ˆæœäº†\næ›´æ¢ä¸»é¢˜\n\n\n\n\n\n\n\n\n\næ­¤æ—¶åšå®¢æ˜¯hexoé»˜è®¤ä¸»é¢˜ï¼Œæ¯”è¾ƒæ™®é€šï¼Œè¿™é‡Œæ¨èä¸€ä¸ªä¸»é¢˜ï¼šAurora\nå®‰è£…æ•™ç¨‹\næ•ˆæœé¢„è§ˆ\né…ç½®github\n\nå»ºç«‹respository repositoryåç§°ä¸ºusername.github.io\nä¿®æ”¹é…ç½®æ–‡ä»¶ &gt; _config.ymlæ–‡ä»¶\n\ndeploy:  \n\ttype: git \n\trepository: https:&#x2F;&#x2F;github.com&#x2F;username&#x2F;username.github.io.git\n\tbranch: master\n\nå®‰è£…ä¸€ä¸ªéƒ¨ç½²æ’ä»¶ npm install hexo-deployer-git --save\né‡æ–°ç”Ÿæˆéƒ¨ç½² hexo g -d\n\n\n\n\n\n\n\n\n\n\næ­¤æ—¶å¯é€šè¿‡ https://username.github.io è®¿é—®åšå®¢\né…ç½®ä¸ªæ€§åŸŸå\n\n\n\n\n\n\n\n\n\nè¿™é‡Œæˆ‘è´­ä¹°äº†è…¾è®¯äº‘çš„åŸŸå: hulk.show\n\né…ç½®åŸŸå &gt; è¿›å…¥åŸŸåç®¡ç†ç•Œé¢ï¼Œé€‰æ‹©è§£æï¼Œæ·»åŠ ä¸¤æ¡è§£æï¼š \né…ç½®git &gt; ä½ çš„é¡¹ç›®-&gt;Setting-&gt;Pages-&gt;Custom domain,æ·»åŠ ä½ çš„åŸŸåï¼š \n\n\n\n\n\n\n\n\n\n\nå¯èƒ½éœ€è¦ç­‰å‡ åˆ†é’Ÿ,å³å¯é€šè¿‡è´­ä¹°çš„åŸŸåè®¿é—®åšå®¢ï¼š www.hulk.show\n","slug":"hexo-github-æ­å»ºä¸ªäººåšå®¢","date":"2021-08-29T10:50:28.000Z","categories_index":"","tags_index":"config","author_index":"Hulk Wang"}]